<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>文本生成模型的对抗攻击</title>
    <url>/2024/07/11/AI-Security1/</url>
    <content><![CDATA[<p>对抗攻击（也称为对抗样本生成）是智能算法安全的子领域，最初是针对图像所提出，在计算机视觉领域取得了丰硕的研究成果，提出了很多实用的攻击算法。近几年，研究人员在不断寻找新的应用场景，积极探索对抗攻击在其他领域的应用，针对文本的对抗攻击已取得一些进展。</p>
<h1 id="基本概念">基本概念</h1>
<h2 id="对抗样本">对抗样本</h2>
<p>对抗样本的概念最初是在2014年提出的，指的是一类人为构造的样本，通过对原始的样本数据添加针对性的微小扰动所得到，其不会影响人类的感知，但会使深度学习模型产生错误的判断[1]。对抗攻击即指构造对抗样本的过程。</p>
<p>举个例子:</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/11/AI-Security1/p1.png" class title="p1">
<p>语句（1）为原始样本，语句（2）为经过几个字符变换后得到的对抗样本。深度学习模型能正确地将原始样本判为正面评论，而将对抗样本误判为负面评论。而显然，这种微小扰动并不会影响人类的判断。</p>
<p>关于对抗样本存在的原因，有学者认为是由于模型的<strong>高度非线性</strong>和<strong>过拟合</strong>，有学者认为是由于<strong>特征维度过高</strong>和<strong>模型的线性性质</strong>，至今还未达成共识，研究人员一般都会根据自己的研究成果来进行解释，每个人提出的观点往往仅适用于局部现象。但不管是线性解释还是非线性解释，究其<strong>本质是由于模型没有学到完美的判别规则，模型的判断边界与真实的决策边界不一致</strong>。深度学习模型由于能够自动学习特征的能力而得到广泛应用，但是这种由数据出发进行自主学习，所得到的特征并不一定就是我们所希望的特征，模型对数据的理解与人的理解有着很大的差异。因而模型学习到的特征，极有可能并非是人理解事物的特征，即对抗样本的存在是深度学习模型的固有缺陷。</p>
<h2 id="文本对抗和图像对抗">文本对抗和图像对抗</h2>
<p>文本数据与图像数据的不同，为文本领域的对抗攻击研究带来了巨大挑战。[2]</p>
<ol>
<li><strong>离散VS连续</strong>（Discrete VS Continucous）</li>
</ol>
<p>图像数据是连续的，易编码为数值向量，预处理操作线性、可微，通常使用lp范数来度量原始样本与对抗样本间的距离；而文本数据是符号化的数据，是<strong>离散</strong>的，预处理操作<strong>非线性、不可微</strong>，很难定义文本上的扰动及度量文本序列改变前后的差异。</p>
<ol start="2">
<li><strong>易感知VS不易感知</strong>（Preceivable VS Unperceivable）</li>
</ol>
<p>人类通常不容易察觉到图像像素的微小变化，因此图像的对抗样本不会改变人类的判断力，只会影响深度学习模型的判别结果；而文本上的变化则很<strong>容易影响文本可读性</strong>，在将文本数据输入DNN模型之前通过拼写检查和语法检查来识别或纠正更改，极有可能导致攻击失败。</p>
<ol start="3">
<li><strong>富有语义VS无语义</strong>（Semanic VS Semanic-less）</li>
</ol>
<p>像素的微小变化不会改变图像的语义，但对文本的扰动<strong>可轻易改变单词和句子的语义</strong>。例如，干扰单个像素不会将图像从猫变为另一种动物，而删除否定词将改变句子的情感。更改样本的语义有悖于对抗样本的定义，文本领域的对抗样本应在使深度学习模型发生误判的同时保持数据样本的真实标签不变。</p>
<h2 id="算法分类">算法分类</h2>
<h3 id="模型访问权限">模型访问权限</h3>
<p>根据模型访问权限可以分为白盒攻击和黑盒攻击，白盒攻击需要获取模型的结构和参数等详细信息；而黑盒攻击不需要模型知识，只需访问模型获取输入的对应输出即可。</p>
<h3 id="攻击目标">攻击目标</h3>
<p>根据攻击目标设定可以分为有目标攻击和无目标攻击，无目标攻击旨在使模型的输出为偏离正确结果的任意错误预测；而有目标攻击旨在使模型的输出为某一特定结果。</p>
<h2 id="添加扰动的粒度">添加扰动的粒度</h2>
<p>根据添加扰动时所操作的文本粒度可以分为字符级、单词级和语句级攻击。字符级攻击通过插入、删除或替换字符，以及交换字符顺序实现；单词级攻击主要通过替换单词实现，基于近义词、形近词、错误拼写等建立候选词库；语句级攻击主要通过文本复述或插入句子实现。</p>
<h2 id="攻击策略">攻击策略</h2>
<p>根据攻击策略可以分为<strong>Image-to-Text</strong>（借鉴图像领域的经典算法）、<strong>基于优化</strong>的攻击、<strong>基于重要性</strong>的攻击以及<strong>基于神经网络</strong>的攻击。</p>
<ul>
<li>部分学者通过<strong>将文本数据映射到连续空间</strong>，然后借鉴图像领域的一些经典算法如FGSM、JSMA等，生成对抗样本；</li>
<li>基于优化的攻击将对抗攻击表述为<strong>带约束的优化问题</strong>，利用现有的优化技术求解，如梯度优化、遗传算法优化；</li>
<li>基于重要性的攻击通常首先利用梯度或文本特性设计评分函数<strong>锁定关键词</strong>，然后通过<strong>文本编辑</strong>添加扰动；</li>
<li>基于神经网络的攻击训练神经网络模型<strong>自动学习对抗样本的特征</strong>，从而实现对抗样本的自动化生成。</li>
</ul>
<h1 id="代表性算法">代表性算法</h1>
<p>文本领域的常见任务有文本分类、情感分析、机器翻译、阅读理解、问答系统、对话生成、文本蕴含等，其中文本分类与情感分析任务使用分类器模型，其他任务使用seq2seq模型。针对分类任务的研究较多，下文介绍几种代表性算法。</p>
<table>
<thead>
<tr>
<th>算法</th>
<th>访问权限</th>
<th>攻击形式</th>
<th>操作粒度</th>
<th>策略</th>
<th>应用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Papernot et al.</td>
<td>白盒</td>
<td>无目标攻击</td>
<td>单词</td>
<td>JSMA-based, FGSM-based</td>
<td>文本分类</td>
</tr>
<tr>
<td>TextFool</td>
<td>白盒/黑盒</td>
<td>有目标攻击</td>
<td>单词</td>
<td>FGSM-based</td>
<td>文本分类</td>
</tr>
<tr>
<td>HotFlip</td>
<td>白盒</td>
<td>无目标攻击</td>
<td>字符</td>
<td>Gradient-Optimization</td>
<td>文本分类</td>
</tr>
<tr>
<td>Alzantot et al.</td>
<td>黑盒</td>
<td>有目标攻击</td>
<td>单词</td>
<td>GA-Optimization</td>
<td>情感分析</td>
</tr>
<tr>
<td>DeepWordBug</td>
<td>黑盒</td>
<td>无目标攻击</td>
<td>字符</td>
<td>Importance-based</td>
<td>文本分类</td>
</tr>
<tr>
<td>TextBugger</td>
<td>白盒/黑盒</td>
<td>字符/单词</td>
<td>字符</td>
<td>Importance-based</td>
<td>情感分析</td>
</tr>
<tr>
<td>DISPTFLIP</td>
<td>白盒</td>
<td>无目标攻击</td>
<td>字符</td>
<td>Neural Network</td>
<td>文本分类</td>
</tr>
<tr>
<td>Zhao et al.</td>
<td>黑盒</td>
<td>无目标攻击</td>
<td>单词</td>
<td>GAN-based</td>
<td>文本分类/机器翻译</td>
</tr>
</tbody>
</table>
<p>Papernot等人[3]最先研究了文本领域的对抗样本问题，提出了<strong>生成对抗性输入序列</strong>的概念。作者将图像对抗领域的JSMA算法迁移到文本领域，利用计算图展开技术来评估与单词序列的嵌入输入有关的前向导数，构建雅可比矩阵，并借鉴<strong>FGSM</strong>的思想计算对抗性扰动。由于词向量不能取任意实数值，作者建立了一个特定的词典来选择单词以替换原始序列中的随机词。</p>
<p>Liang等人[4]提出了TextFool方法，首先针对白盒模型和黑盒模型使用不同的策略<strong>识别出对分类具有重要贡献的文本项</strong>（HTP、HSP），然后对这些重要的文本项通过单一或混合使用插入、修改和删除三种<strong>扰动</strong>策略，生成对抗样本。对于白盒模型，作者借鉴FGSM的思想来估算文本项的重要度，但是通过<strong>损失函数的梯度大小</strong>而不是梯度符号来度量；对于黑盒模型，通过<strong>遮挡文本</strong>的策略来识别重要文本项。</p>
<p>Ebrahimi 等人[5]提出了HotFlip方法，<strong>基于one-hot表示的梯度来有效估计单个操作所造成的最大损失的变化</strong>，通过原子翻转操作（将一个字符替换为另一个字符）生成对抗样本，并通过一系列的字符翻转来支持插入和删除操作。考虑到梯度优化的局限性，Alzantot等人[6]提出使用最优化技术中的遗传算法（Genetic Algorithm, GA）来生成与原始样本具有相似语义和语法的对抗样本。</p>
<p>Gao等人[7]提出了DeepWordBug方法，将对抗样本的生成分为两个阶段。首先使用针对文本数据特性设计的评分函数来<strong>识别关键的Token</strong>，根据重要性进行排名；然后对排名最高的m个Token通过简单的<strong>字符级操作</strong>（交换、替换、删除和插入）进行扰动，改变分类结果。</p>
<p>Li等人[8]提出了TextBugger方法，首先针对白盒和黑盒模型通过不同策略<strong>识别影响模型分类结果的重要词</strong>，然后采取插入、删除、字符交换、字符替换、单词替换等五种扰动策略分别生成扰动从中选择一个最优扰动。在白盒场景下，通过计算分类器的雅可比矩阵来找到重要词；在黑盒场景下，首先根据分类置信度找到重要的句子，然后使用评分函数来找到重要单词。</p>
<p>Gil 等人[9]提出了HotFlip的派生方法DISTFLIP，该算法<strong>提取HotFlip优化过程中的知识训练神经网络模型</strong>来模拟攻击从而生成对抗样本，极大地节省了运行时间，并可以迁移到黑盒场景下进行攻击。</p>
<p>Zhao等人[10]设计的用于生成对抗样本的模型，首先使用一个逆变器<strong>将原始数据映射到向量空间</strong>，在数据对应的<strong>稠密向量空间</strong>中进行搜索<strong>添加扰动</strong>得到对抗样本；然后使用GAN作为生成器将向量空间中得到的对抗样本<strong>映射回原始数据类型</strong>。</p>
<h1 id="参考文献">参考文献</h1>
<p>[1]Szegedy C, Zaremba W, Sutskever I, et al. Intriguing Properties of Neural Networks[C] // Proceedings of the 2th International Conference on Learning Representations, 2014.<br>
[2]Zhang W E, Sheng Q Z, Alhazmi A, et al. Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey[J]. ACM Transactions on Intelligent Systems and Technology (TIST). 2020, 11(3): 1-41.<br>
[3]Papernot N, McDaniel P, Swami A, et al. Crafting Adversarial Input Sequences for Recurrent Neural Networks[C]// Proceedings of MILCOM 2016-2016 IEEE Military Communications Conference. IEEE, 2016: 49-54.<br>
[4]Liang B, Li H, Su M, et al. Deep Text Classification Can be Fooled[C]// Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence(IJCAI). 2018: 4208-4215.<br>
[5]Ebrahimi J, Rao A, Lowd D, et al. HotFlip: White-Box Adversarial Examples for Text Classification[C]//Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 2018: 31-36.<br>
[6]Alzantot M, Sharma Y, Elgohary A, et al. Generating Natural Language Adversarial Examples[C]//Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. 2018: 2890-2896.<br>
[7]Gao J, Lanchantin J, Soffa M L, et al. Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers[C]// Proceedings of 2018 IEEE Security and Privacy Workshops (SPW). IEEE, 2018: 50-56.<br>
[8]Li J, Ji S, Du T, et al. TextBugger: Generating Adversarial Text Against Real-world Applications[C]// Proceedings of the 26th Annual Network and Distributed System Security Symposium. 2019.<br>
[9]Gil Y, Chai Y, Gorodissky O, et al. White-to-Black: Efficient Distillation of Black-Box Adversarial Attacks[C]//Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 2019: 1373-1379.<br>
[10]Zhao Z, Dua D, Singh S. Generating Natural Adversarial Examples[C]// Proceedings of the International Conference on Learning Representations. 2018.<br>
参考博客: <a href="https://www.secrss.com/articles/25644">https://www.secrss.com/articles/25644</a></p>
<!-- <img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/11/AI-Security1/p1.png" class="" title="p1"> -->
<!-- <img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="p1.png"  style="zoom:60%;" /> -->]]></content>
      <categories>
        <category>智能算法安全</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>智能算法安全</tag>
        <tag>生成式人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>人工智能概述</title>
    <url>/2022/09/01/AdvancedAI-LearningNotes1/</url>
    <content><![CDATA[<blockquote>
<p>三节课讲述的东西太多，这里仅记录相对来说稍重要的部分。</p>
</blockquote>
<h1 id="图灵测试">图灵测试</h1>
<h2 id="什么是图灵测试">什么是图灵测试</h2>
<p>测试者与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）向被测试者随意提问。进行多次测试后，如果机器让平均每个参与者做出超过30%的误判，那么这台机器就通过了测试，并被认为具有人类智能。</p>
<blockquote>
<p>图灵问题：Can Machine Think？（思考）</p>
</blockquote>
<h2 id="质疑">质疑</h2>
<ul>
<li>图灵测试是不可构造的：“完全不接触”环境难以构建</li>
<li>图灵测试不可重现的：问题是开放的，答案正确性判断是主观的</li>
<li>图灵测试无法进行数学分析：只是一种操作式测试，缺少形式化描述</li>
</ul>
<h1 id="人工智能三大学派">人工智能三大学派</h1>
<h2 id="符号主义">符号主义</h2>
<ul>
<li>认为“人的认知基元是符号（语言文字），认知过程即符号操作过程”</li>
<li>认为人工智能的<strong>核心是知识表示、知识推理和知识运用</strong></li>
<li>衍生出：逻辑、专家系统、知识库、<strong>知识图谱</strong></li>
</ul>
<h2 id="联结主义">联结主义</h2>
<ul>
<li>又称<strong>仿生</strong>学派或生理学派</li>
<li>认为人的思维基元是神经元，而不是符号处理过程</li>
<li>原理：神经网络及神经网络间的连接机制和学习算法</li>
<li>衍生出：<strong>人工神经网络</strong>，认知科学、类脑计算</li>
</ul>
<h2 id="行为主义">行为主义</h2>
<ul>
<li>又称进化主义或<strong>控制论学派</strong></li>
<li>主张<strong>利用机器对环境作用后的响应或反馈为原型</strong>来实现智能化</li>
<li>衍生出：动态规划、<strong>强化学习</strong>、多智能体</li>
</ul>
<h1 id="课程蓝图">课程蓝图</h1>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/AdvancedAI-LearningNotes1/p.png" class title="p">
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>高级人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>搜索算法</title>
    <url>/2022/10/02/AdvancedAI-LearningNotes2/</url>
    <content><![CDATA[<blockquote>
<p>内容杂且多，老师讲的也一言难尽，用的吴恩达的PPT，也没有用全，跳着讲，公式也不解释清楚变量，推导也不推，照着ppt念，太难了QAQ<br>
这里仅记录较为重要的部分</p>
</blockquote>
<h1 id="一些概念">一些概念</h1>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/02/AdvancedAI-LearningNotes2/p1.png" class title="p1"> 
<h1 id="无信息搜索">无信息搜索</h1>
<p>无信息搜索也被称为盲目搜索，意味着该搜索策略没有超出问题定义提供的状态之外的附加信息。所有能做的就是生成后继节点。</p>
<h2 id="深度优先搜索dfs">深度优先搜索DFS</h2>
<p><strong>描述</strong>：每一次将深度最深的那个节点进行优先探索，若不是终点，则将其拓展并将它的子节点纳入边缘空间，若是边缘空间中所有的节点都是同一个深度，那么就探索最左边的那个节点<br>
<strong>优点</strong>：机器每次只需要探索最深的那个点，而且边缘空间中的节点也不会太多，不会占用太多的内存<br>
<strong>缺点</strong>：无法保证完备性和最优性，比较耗费时间</p>
<h2 id="广度优先搜索bfs">广度优先搜索BFS</h2>
<p><strong>描述</strong>：与深度搜索不同的是它每次拓展的是边缘空间节点中最浅的那个节点，都是同一个深度的话就拓展最左边的那个节点<br>
<strong>优点</strong>：具备完备性<br>
<strong>缺点</strong>：占用内存，而且也不具备最优性</p>
<h2 id="dfs和bfs比较">DFS和BFS比较</h2>
<h2 id="迭代深入搜索">迭代深入搜索</h2>
<p><strong>特点</strong>：同时结合深度优先于广度优先的优点<br>
<strong>描述</strong>：预先设定一个探索的层数，然后在这个层数以内采用深度优先算法，当在这个层数里面都没有找到终点的话，然后就对这个层数进行拓展，允许进行更深一层的探索<br>
<strong>优点</strong>：结合FDFS空间优势+BFS时间优势<br>
<strong>缺点</strong>：可能会造成一定的浪费冗余</p>
<h2 id="代价敏感搜索">代价敏感搜索</h2>
<p><strong>特点</strong>：算法开始关注了路程中的代价问题，两个节点之间的代价不再等效处理</p>
<h2 id="代价一致搜索">代价一致搜索</h2>
<p><strong>特点</strong>：代价敏感搜索的一种，一致代价搜索总是扩展路径消耗最小的节点N。N点的路径消耗等于前一节点N-1的路径消耗加上N-1到N节点的路径消耗</p>
<h1 id="启发式搜索">启发式搜索</h1>
<p>启发式：对每个状态估计到最近目标的距离</p>
<h2 id="贪婪搜索">贪婪搜索</h2>
<p><strong>策略</strong>：扩展你认为最接近目标状态的节点，只使用启发函数来评价节点<br>
<strong>缺点</strong>：只考虑了后半段的距离而没有考虑前面的距离，不能满足最优性</p>
<h2 id="a-算法-重要">A*算法（重要）</h2>
<h2 id="算法介绍">算法介绍</h2>
<p><strong>特点</strong>：结合贪婪搜索与代价一致搜索<br>
<strong>策略</strong>：将代价函数g(n)与启发函数h(n)简单相加，得到一个新的函数f(n)，这个函数就是A*算法判断路径的标准<br>
<strong>估价函数</strong>：f(n)=g(n)+h(n)，其中：g(n)是到达n节点已花费的代价；f(n)是当前节点到目标节点最小代价路径的估计值（greedy）<br>
<strong>存在问题</strong>：当启发函数h大于实际耗散时，启发函数失效</p>
<h3 id="可采纳性">可采纳性</h3>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 ≤ h(n)≤ h*(n)</span><br></pre></td></tr></table></figure>
<p>其中：h*(n) 是从 n 结点到目标结点的最优路径的真实代价，当启发式函数 h(n) 满足以上不等式的时候，我们称该 h(n) 是可采纳的 (admissible) ，即：没有过高估计某点到目标点的花费。</p>
<h3 id="mark-证明a-树搜索的最优性-重要-mark"><mark>证明A* 树搜索的最优性（重要）</mark></h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/02/AdvancedAI-LearningNotes2/p2.png" class title="p2"> 
<h3 id="a-算法其他性质">A*算法其他性质</h3>
<p>Open表中任一具有f(n)&lt;=f*(S0)的节点n，都被A*算法作为扩展节点</p>
<h3 id="最优条件">最优条件</h3>
<ul>
<li>树A*算法最优条件：可采纳性（h(n)&lt;=h*(n)）</li>
<li>图A*算法最优条件：一致性（f(n)沿着路径非递减）</li>
</ul>
<h2 id="a-图搜索">A*图搜索</h2>
<h3 id="主要思想">主要思想</h3>
<p>可采纳性：h(A)&lt;=h*(A)真实<br>
一致性：沿路径的节点f(n)值单调递增   h(A)&lt;=cost(A to C)+h©</p>
<h3 id="最优性">最优性</h3>
<h4 id="条件">条件</h4>
<p>一致性：</p>
<ul>
<li>A*算法扩展节点，f值单调增</li>
<li>对于每个状态S，到达S最优的节点先于次优的节点扩展</li>
</ul>
<h4 id="证明">证明</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/02/AdvancedAI-LearningNotes2/p3.png" class title="p3"> 
<h2 id="mark-传教士和野人问题的a-搜索-mark"><mark>传教士和野人问题的A*搜索</mark></h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/02/AdvancedAI-LearningNotes2/p4.png" class title="p4">
<p><strong>变量解释</strong>：<br>
M-左岸传教士数目<br>
C-左岸野人数目<br>
B-左岸是否有船<br>
Pcm-有c个传教士，m个野人从左岸到右岸<br>
Qcm-有c个传教士，m个野人从右岸到左岸</p>
<p><strong>问题有解所必须的特性</strong></p>
<ul>
<li>M&gt;=C且（3-M)&gt;=(3-C)&lt;==&gt;M=C</li>
<li>或者M=0,M=3</li>
</ul>
<p><strong>安全状态(以左岸为例)</strong>：</p>
<ul>
<li>传教士与野人的数目相等；</li>
<li>传教士都在左岸；</li>
<li>传教士都不在左岸。</li>
</ul>
<p><strong>完全状态图</strong>：<br>
（不满足约束的不在图内）</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/02/AdvancedAI-LearningNotes2/p5.png" class title="p5">
<blockquote>
<p>参考: <a href="https://blog.csdn.net/qq_41296039/article/details/122442921?spm=1001.2014.3001.5501">https://blog.csdn.net/qq_41296039/article/details/122442921?spm=1001.2014.3001.5501</a></p>
</blockquote>
<h1 id="局部搜索">局部搜索</h1>
<ul>
<li>爬山法：任意位置开始，可能是局部最优解；</li>
<li>模拟退火搜索：引入随机因素，避免局部极大；</li>
<li>遗传算法：适应度函数，每步保留N个最好状态。</li>
</ul>
<h1 id="其他">其他</h1>
<ul>
<li>未知梯度时，用蚁群算法/粒子群算法；</li>
<li>贪婪最优搜索不是完备的。</li>
</ul>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>高级人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>人工神经网络</title>
    <url>/2022/10/03/AdvancedAI-LearningNotes3/</url>
    <content><![CDATA[<h1 id="人工神经网络ann">人工神经网络ANN</h1>
<h2 id="结构">结构</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes3/p1.png" class title="p1">
<h2 id="学习规则">学习规则</h2>
<ul>
<li>能量最小（ENERGY MINIMIZATION）</li>
<li>对人工神经网络，需要确定合适的能量定义；可以使用数学上的优化技术来发现如何改变神经元间的联接权重。</li>
</ul>
<h1 id="多层感知机">多层感知机</h1>
<p>多层感知机是ANN的一种。指具有至少三层节点，输入层，一些中间层和输出层的神经网络。给定层中的每个节点都连接到相邻层中的每个节点。输入层接收数据，中间层计算数据，输出层输出结果。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes3/p2.png" class title="p2">
<h2 id="特点">特点</h2>
<p>多层感知机特性：</p>
<ul>
<li>多层感知机层间神经元全连接；</li>
<li>Can represent AND, OR, NOT, etc., but not XOR；</li>
<li>若训练数据集是线性可分的，则感知机模型收敛。</li>
</ul>
<h2 id="感知机存在的问题">感知机存在的问题</h2>
<ul>
<li>噪声（线性不可分）</li>
<li>泛化性</li>
</ul>
<h3 id="单层感知机不可解决异或问题">单层感知机不可解决异或问题</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes3/p4.png" class title="p4">
<blockquote>
<p>传送门[<a href="https://blog.csdn.net/buracag_mc/article/details/89254808?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-2.nonecase">https://blog.csdn.net/buracag_mc/article/details/89254808?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-2.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromMachineLearnPai2~default-2.nonecase</a>]</p>
</blockquote>
<h1 id="权重学习算法：bp算法">权重学习算法：BP算法</h1>
<h2 id="介绍">介绍</h2>
<p>BP算法全称叫作误差反向传播(error Back Propagation，或者也叫作误差逆传播)算法。其算法基本思想为：将输出误差以某种形式反传给各层所有的单元，各层按本层误差修<br>
正各单元连接权值。【有监督学习，采用梯度下降法调参】</p>
<h3 id="特点">特点</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes3/p3.png" class title="p3">
<h2 id="bp遇到的困难-为什么会出现梯度消失">BP遇到的困难，为什么会出现梯度消失</h2>
<h3 id="困难">困难</h3>
<ul>
<li>梯度消失，梯度爆炸</li>
<li>局部极小</li>
<li>只能用于标注数据</li>
</ul>
<h3 id="why梯度消失">why梯度消失</h3>
<p>因为BP算法采用链式法则，从后层向前层传递信息时，若每层神经元对上一层神经元偏导乘以w均小于1，多次链式法则,多级导数权值相乘结果会越来越小，导致loss传递到越前方越小。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>高级人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习</title>
    <url>/2022/10/03/AdvancedAI-LearningNotes4/</url>
    <content><![CDATA[<h1 id="一-玻尔兹曼机系列">一、玻尔兹曼机系列</h1>
<h2 id="hopfield">Hopfield</h2>
<p>Hopfield网络是反馈类型，其神经元的结构功能在网络中的地位是一样的。其学习是基于灌输式学习，即网络的权值不是通过训练出来的，而是按照一定规则计算出来的，<strong>将求解的问题转换成优化问题的能量函数，网络的稳定状态是优化问题的解，其权值一旦确定就不再改变了</strong>。</p>
<p>简单的来讲就是，Hopfield网络的主要功能是联想记忆。既然如此，首先应该让网络实现“记忆”，我们需要一些数据，然后训练网络，训完练完成之后，可以得到一组可用的权值信息，形成网络的“记忆”功能。当输入数据不完整时，根据训练得到的权重去运算，得到一个稳定的输出状态，这就是联想功能。</p>
<p>【BM与Hopfield有一定共性，看一下有助理解。】</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p1.png" class title="p1">
<h2 id="bm-玻尔兹曼机">BM（玻尔兹曼机）</h2>
<p>离散Hopfield神经网络+模拟退火+隐单元=Boltzman机</p>
<p>Boltzmann机结合多层前馈神经网络和离散Hopfield网络在网络结构、学习算法和动态运行机制方面的优点。它是建立在离散Hopfield网基础上的，具有学习能力，它在神经元状态变化中引入了统计概率，网络的平衡状态服从Boltzmann分布，能够通过一个模拟退火过程寻求最优解。不过，其训练时间比BP网络要长。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p3.png" class title="p3">
<p>原理：<br>
1.上文提到Hopfield神经元的结构功能在网络中的地位是一样的,BM中一部分神经元与外部相连接，可以起到网络的输入输出作用，或者严格的说可以受到外部条件的约束，另一部分神经元不与外部相连，因而属于隐单元（相对于外部）。<br>
2.每个神经元只有1/0两个状态：状态为1代表神经元处于激活(连接)状态，0表示非激活（断开）状态。</p>
<h2 id="rbm-受限玻尔兹曼机">RBM（受限玻尔兹曼机）</h2>
<p>RBM是BM的一个变体，层间全连接，层内无连接，网络中的神经元是随机神经元。限定模型必须为二分图，学习的目标是极大似然。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p2.png" class title="p2">
<h2 id="dbn-深度置信网络">DBN（深度置信网络）</h2>
<p>DBN模型由若干个RBM堆叠而成，通过非监督的预学习和监督微调训练参数。<br>
训练时通过从底到高逐层训练这些RBM来实现：</p>
<p>1.底部RBM以原始输入数据训练；<br>
2.将底部RBM抽取的特征作为顶部RBM的输入训练；<br>
3.过程（1）和（2）可以重复训练所需的尽可能多的参数。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p4.png" class title="p4">
<h1 id="cnn卷积神经网络">CNN卷积神经网络</h1>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p5.png" class title="p5">
<h2 id="特点">特点</h2>
<p><strong>主要特点</strong>：局部链接、参数共享、空间或时间上的子采样、（非逐层贪婪训练）。这些特性使得卷积神经网络具有一定程度上的平移、缩放和扭曲不变性。</p>
<p><strong>解释</strong>：CNN神经元之间的连接是非全链接，同一层中神经元之间的链接权重是共享的——减少了权值的数量，降低了网络模型的复杂度。CNN的一个卷积层中，一般包含若干个特征平面，每个特征平面由一些矩阵形排列的神经元组成，同一特征平面神经元共享权值。<br>
每个卷积层之后，通常立即会有一个非线性层（激活层），目的是给一个卷积层中刚经过线性计算操作的系统引入非线性特征。</p>
<h2 id="各层介绍">各层介绍</h2>
<ul>
<li>池化层pooling：逐渐降低数据空间尺寸，有效减少网络中参数；</li>
<li>卷积层cov：通过卷积操作对输入图像进行降维和特征抽取；</li>
<li>全连接层：整个网络中分类器的作用；</li>
<li>Relu：1.采用Sigmoid计算量较大，而Relu激活函数可以减少计算过程计算量；2.防止梯度消失；3.Relu会使一部分神经元输出为0，造成网络稀疏性，从而减小参数相互依赖关系，缓解过拟合。</li>
</ul>
<h2 id="附：卷积运算">附：卷积运算</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p10.png" class title="p10">
<p>本质上是一种加权求和运算，举例：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p9.png" class title="p9">
<h1 id="rnn及其变种">RNN及其变种</h1>
<h2 id="rnn">RNN</h2>
<p><strong>核心思想</strong>：<br>
RNN对前面信息进行记忆并且应用于当前输出计算中，隐藏层节点之间存在链接，并且隐藏层输入不仅包含输入层输出还包含上一层隐含层的输入。（可以看成是权值共享的多层前向网络）</p>
<p><strong>特点</strong>：</p>
<ul>
<li>分布式隐藏状态，可以有效存储过去大量信息；</li>
<li>以非线性动态方式更新隐藏状态。</li>
</ul>
<p><strong>参数学习算法BPTT</strong>（Backpropagation through time）：<br>
（实现权值一致）</p>
<ul>
<li>前向传递：每个时间步长各单元的输出入栈；</li>
<li>后向传递：状态出栈，计算每个时间步长误差函数的导数；</li>
<li>将每个权重的所有时刻导数加和。（所有时刻的损失相加 = 总损失）</li>
</ul>
<p><strong>存在问题</strong>：</p>
<ul>
<li>梯度消失/爆炸问题；</li>
<li>长期依赖问题：距当前节点越远的节点对当前节点处理影响越小，无法建模长时间的依赖。</li>
</ul>
<p>——&gt;内部单元改进及变形：LSTM、GRU</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p6.png" class title="p6">
<h2 id="lstm">LSTM</h2>
<p>LSTM通过门结构来除去和增加“细胞状态”的信息，实现了对重要内容的保留或对不重要内容的去除（长期记忆）。通过sigmoid层输入0到1之间概率值，描述有多少信息通过。<br>
门结构包括：遗忘门、信息增加门（输入门）和输出门。【长期记忆】</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p7.png" class title="p7">
<h2 id="gru">GRU</h2>
<p>2门控（重置门、更新门）<br>
GRU是LSTM的变体，相比LSTM有更简单的结构。GRU包括了重置门和更新门（输入门+遗忘门）。【计算速度快、远距离传递、更容易训练、容易创建较大的网络】</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p8.png" class title="p8">
<h2 id="brnn">BRNN</h2>
<p>每个时刻都有一个正向输入的隐层和一个反向输入隐层，两个隐层分别可以表示一个词的上文信息和下文信息。即：每个词对应一个输出，同时用到了同一个词前后的信息。<br>
缺点：需要完整的数据序列，你才能预测任意位置。</p>
<h2 id="drnns">DRNNs</h2>
<p>深度双向RNN采用多个隐层，每个隐层向后一层传递序列信息。</p>
<h1 id="gan对抗网络">GAN对抗网络</h1>
<h2 id="核心思想">核心思想</h2>
<p>GAN的核心思想来源于博弈论的<strong>纳什均衡</strong>——对抗达到平衡（共同进步）：</p>
<ul>
<li>生成器（生成一个数据，会被判别结果优化）：生成器的目的是尽量去学习真实的数据分布。把噪声数据z（也就是我们说的假数据）通过生成模型G，伪装成了真实数据x；</li>
<li>判别器（判断是否是生成器生成的）：判别器的目的是尽量正确判别输入数据是来自真实数据还是来自生成器。<br>
各自提高自己的生成能力和判别能力，这个学习优化过程就是寻找二者之间的一个纳什均衡。</li>
</ul>
<p><strong>基本原理</strong>：有一个判别器和一个生成器，生成器生成图片让判别器判别，生成器提升自己让判别器无法判别，判别器则提升自己努力识别出生成器生成的图片/序列，双方对抗达到平衡。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p11.png" class title="p11">
<h2 id="学习算法">学习算法</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p12.png" class title="p12">
<p>1.固定生成器G0，训练判别器，提升判别器的判别能力得到D1；【G*=arg min max V(G,D)】<br>
2.固定判别器D1，训练生成器，提升生成器的生成能力，目标让判别器无法识别，得到G1；【D*=arg max V(G,D)】<br>
3.再回到1中用G1训练判别器得到D2，……，依次迭代，直至两者平衡。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/03/AdvancedAI-LearningNotes4/p13.png" class title="p13">
<p>解释：<br>
第一步训练D，D希望V(G、D)越大越好，所以需要加上梯度。（我希望我判断能力越来越好）。<br>
第二步训练G，G希望V(G，D)越小越好，所以要减去梯度。（希望让判别模糊，我希望自己的欺骗能力越来越好。<br>
整个训练过程由上面两步交替进行。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>高级人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络（课程）导图</title>
    <url>/2022/09/03/ComputerNet-LearningNotes1/</url>
    <content><![CDATA[<blockquote>
<p>概念性的东西，暂时只做导图</p>
</blockquote>
<h1 id="网络-课程-概述">网络（课程）概述</h1>
<p>如图：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/03/ComputerNet-LearningNotes1/p1.png" class title="p1">
<h1 id="网络基础：网络模型与直连网络">网络基础：网络模型与直连网络</h1>
<p>如图：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/03/ComputerNet-LearningNotes1/p2.png" class title="p2">
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>雅思写作Task1</title>
    <url>/2021/02/12/IELTS1/</url>
    <content><![CDATA[<h2 id="小作文基本了解">小作文基本了解</h2>
<h3 id="得分-时间-要求">得分+时间+要求</h3>
<p>小作文得分占比1/3，时间约20分钟，要求不少于150字<br>
<a href="https://pic1.zhimg.com/v2-e947841f5b3f71e49f8e315fdc1841c6_r.jpg?source=172ae18bhttps://pic1.zhimg.com/v2-e947841f5b3f71e49f8e315fdc1841c6_r.jpg?source=172ae18b">https://pic1.zhimg.com/v2-e947841f5b3f71e49f8e315fdc1841c6_r.jpg?source=172ae18bhttps://pic1.zhimg.com/v2-e947841f5b3f71e49f8e315fdc1841c6_r.jpg?source=172ae18b</a></p>
<h3 id="类型">类型</h3>
<ol>
<li>
<p>按整体</p>
<ul>
<li>动态图</li>
<li>静态图</li>
</ul>
</li>
<li>
<p>按图形</p>
<ul>
<li>线形图（Line Graph）</li>
<li>柱状图（Bar Chart）</li>
<li>饼状图（Pie Chart）</li>
<li>表格（Table）</li>
<li>流程图（Diagran）</li>
<li>地图题（Map）</li>
</ul>
</li>
</ol>
<h2 id="动态图">动态图</h2>
<h3 id="写作思路">写作思路</h3>
<h4 id="开头改写">开头改写</h4>
<ul>
<li>show 的同义替换 （give information about/illustrate/demonstrate）</li>
<li>between and 与 from to 的替换</li>
<li>抽象与具体的互换：three kinds of books</li>
<li>名词与句子的互换：show how sth changed</li>
</ul>
<h4 id="中间段思路">中间段思路</h4>
<p>1.多条线，找趋势</p>
<ul>
<li>趋势相同放在一起 also （but much less significantly/much more significantly）
<ul>
<li>Likewise, such a pattern could be found in xxx.</li>
</ul>
</li>
<li>趋势不同用转折 however</li>
<li>两条线相交 overtake/outnumber<br>
2.单条线，找主要数据（最高点、最低点、起点、终点、拐点），不需要所有的数据都写，写单条线要追求语法的多样性</li>
<li>有拐点的可以用 before，after 句型</li>
<li>描述的对象做主语
<ul>
<li>The number of the rabbits increased.</li>
</ul>
</li>
<li>时间做主语 witness
<ul>
<li>The four year period witnessed an upward trend in the number of rabbits.</li>
</ul>
</li>
<li>趋势做主语 occur
<ul>
<li>An upward trend occurred in the number of rabbits</li>
</ul>
</li>
<li>there be 做主语
<ul>
<li>There was an increase in the number of rabbits</li>
</ul>
</li>
</ul>
<h4 id="结尾段">结尾段</h4>
<p>总结特征+特殊点，特殊点可以用以下句式连接</p>
<ul>
<li>it is interesting/incredible to find that</li>
<li>interestingly/noticeably</li>
</ul>
<h3 id="举个栗子">举个栗子</h3>
<p>**题：**The line graph shows the sales of children’s book, adults’ fiction and educational book between 2002 and 2006 in one country.</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/12/IELTS1/eg1.png" class title="eg1">
<p><strong>答：</strong></p>
<blockquote>
<p>开头改写</p>
</blockquote>
<p>The line graph compares how three different books were sold in one country from 2002 to 2006.</p>
<blockquote>
<p>中间段1：描写单条线（整体趋势——》最高点/起点——》下降趋势——》拐点）</p>
</blockquote>
<p>During the years, a downward trend occurred in the sale of adults’ fiction. In 2002, among all these books, the figure for adults’ fiction was the largest(45 million dollars). However, it dropped to almost 35 million dollars in 2003. After increasing to 40 million dollars in 2004, the figure decreased to 30 million dollars in 2006.</p>
<blockquote>
<p>中间段2：描写两条趋势相同的线（与上文对比——》figure1整体趋势——》figure2相同——》figure2不同）</p>
</blockquote>
<p>By contrast, the sale of children’s book experienced an opposite trend. It increased from 32 to 55 million dollars from 2002 to 2006. Likewise, the four-year period also witnessed an upward trend in the sale of educational books, but much less significantly. The figure increased from 25 to 31 million dollars from 2002 to 2003. After declining to 25 million dollars again, the sale climbed to 32million dollars.</p>
<blockquote>
<p>结尾（整体——》特殊点）</p>
</blockquote>
<p>Overall, the sales of these three books changed a lot. It is interesting to note that, in 2002, adults’ fiction was the most popular book. However, by the end of 2006, it had been the least popular one.</p>
<h3 id="有将来的变化">有将来的变化</h3>
<ul>
<li>be expected to</li>
<li>be predicted to</li>
</ul>
<h2 id="静态图">静态图</h2>
<h3 id="中间段思路">中间段思路</h3>
<ol>
<li>顺序
<ul>
<li>数据从大写到小（逻辑连接词可以用 largest——》in addition——》however）</li>
<li>或者数据先写最大，再写最小，最后写其他（逻辑连接词 largest——》however——》in addition）</li>
</ul>
</li>
<li>相同的数据进行组合（with the former occupying a slightly higher proportion than the latter）</li>
</ol>
<h3 id="举个栗子">举个栗子</h3>
<p>**题：**International students 的构成: Chinese (60%), Koreans (16%), Japanese (14%), Indians (7%), Vietnamese (3%).</p>
<p><strong>答：</strong><br>
Chinese students boast the <strong>largest</strong> share, accounting for 60 %. <strong>However</strong>, only a few international students are from India and Vietnam, and they only make up 7 % and 3 % respectively. <strong>In addition</strong> Koreans and Japanese together take up 30 %, <strong>with the former (16 %) occupying a marginally higher proportion than the latter (14 %)</strong>.</p>
<blockquote>
<p><strong>积累词汇：</strong></p>
<ul>
<li>xx boast the largest share （xx最多）</li>
<li>account for/make up/take up/occupy （表示占了多少份额）</li>
<li>,with the former (16 %) occupying a marginally higher proportion than the latter (14 %) （比较）</li>
</ul>
</blockquote>
<h2 id="线形图-line-graph-柱状图-bar-chart-表格-table">线形图（Line Graph）+ 柱状图（Bar Chart）+ 表格（Table）</h2>
<h3 id="数据描述">数据描述</h3>
<p>线形图里最基本的特征有升高和降低，可以用“<strong>动词+副词</strong>”或“<strong>形容词+名词</strong>”这两种表达，他们可以相互转化。</p>
<ol>
<li>动词+副词</li>
</ol>
<ul>
<li>动词
<ul>
<li>上升：increase，rise，grow，climb</li>
<li>下降：decrease，drop，fall</li>
</ul>
</li>
<li>副词
<ul>
<li>显著、大幅度：sharply，rapidly，dramatically，abruptly</li>
<li>持续、稳步：gradually，steadily，consistently</li>
<li>轻微、小幅：slightly，marginally，minimally</li>
</ul>
</li>
</ul>
<ol start="2">
<li>形容词+名词</li>
</ol>
<ul>
<li>形容词</li>
<li>显著、大幅度：sharp，rapid，dramatical</li>
<li>持续、稳步：gradual，steadi，consistent</li>
<li>轻微、小幅：slight，marginal，minimal，unnoticeable</li>
<li>名词
<ul>
<li>上升：increase，rise，growth</li>
<li>下降：decrease，drop，fall</li>
</ul>
</li>
</ul>
<p>另外，还有线形图常出现的波动、保持平稳、到达最高或最低点，这样的表达每一类能记住两个就可以了。</p>
<ul>
<li>波动
<ul>
<li>fluctuate</li>
<li>experience fluctuation</li>
</ul>
</li>
<li>保持平稳
<ul>
<li>remain stable</li>
<li>stay constant</li>
</ul>
</li>
<li>到达最高点
<ul>
<li>peak at</li>
<li>reach the highest point of</li>
</ul>
</li>
<li>到达最低点
<ul>
<li>reach the lowest point</li>
<li>hit a low of</li>
<li>bottom up at</li>
</ul>
</li>
<li>超过
<ul>
<li>overtake</li>
<li>outnumber</li>
</ul>
</li>
</ul>
<h3 id="描述线形图的句型">描述线形图的句型</h3>
<ul>
<li>句型一：X（描述对象）+ 趋势动词 + 副词</li>
<li>句型二：There was a + 形容词 + 趋势名词 + in X（描述对象）</li>
<li>句型三：时间 + saw/ experienced/ witnessed a + 形容词 + 趋势名词</li>
<li>句型四：A + 形容词 + 趋势名词 + took place/ occurred.</li>
<li>句型五：X（描述对象）+ showed/ took +an upward/ downward trend.</li>
</ul>
<p>举个栗子：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/12/IELTS1/eg2.png" class title="eg2">
<ul>
<li>句型一：The price of textbooks fell sharply in 2019.</li>
<li>句型二：There was a rapid decrease in the price of textbooks in 2019.</li>
<li>句型三：The year 2019 witnessed a dramatic drop in the price of textbooks.</li>
<li>句型四：A sharp fall in the price of textbooks took place in 2019.</li>
<li>句型五：The price of textbooks showed a downward trend in 2019.</li>
</ul>
<h3 id="多点数据连接">多点数据连接</h3>
<ul>
<li>连接方式一：现在分词作状语：starting at, beginning from，通常可以在描述数据的开头时使用</li>
</ul>
<blockquote>
<p><strong>Starting at</strong> 30, X fluctuated around this level in the first decade.（句型一）</p>
</blockquote>
<ul>
<li>连接方式二：表示时间的连词：before, after，后面接完整句子或者动词的进行式</li>
</ul>
<blockquote>
<p>X had fluctuated around this level in the first decade <strong>before</strong> it dropped abruptly to 23 in 1970.<br>
如果把第一个句子也加上的话，就会变成：<br>
<strong>Starting at</strong> 30, X had fluctuated around this level in the first decade <strong>before</strong> dropping abruptly to 23 in 1970.（上一节里句型一的合并）</p>
</blockquote>
<ul>
<li>连接方式三：表示并列或转折的连词：but, however, and, in addition</li>
</ul>
<blockquote>
<p><strong>However</strong>, the 1970s witnessed a considerable rise（句型三）, <strong>and then</strong> a peak of 60 took place in 1980.（句型四）</p>
</blockquote>
<ul>
<li>连接方式四：过去分词作状语：followed by（紧接着…），后面接名词性的短语</li>
</ul>
<blockquote>
<p><strong>However</strong>, the 1970s witnessed a considerable rise, <strong>and then</strong> a peak of 60 took place in 1980, <strong>followed by a sharp fall over the next ten-year period.</strong></p>
</blockquote>
<ul>
<li>连接方式五：时间定语从句：在表示时间的词后用when引出一个非限制性定语从句</li>
</ul>
<blockquote>
<p>Yet, there had been a stable pattern at 8 until 2000（句型二）, <strong>when</strong> it began to increase slowly.</p>
</blockquote>
<ul>
<li>连接方式六：表示时间的副词：after this, following this period, thereafter</li>
</ul>
<blockquote>
<p><strong>Nonetheless</strong>, X is expected to show a downward trend between 2018 and 2022（句型五）, <strong>and after that</strong>, it will probably show unnoticeable rise and fall.</p>
</blockquote>
<h2 id="饼状图-pie-chart">饼状图（Pie Chart）</h2>
<h3 id="占比-数据的描写">“占比”数据的描写</h3>
<ul>
<li>句型一：大比例或小比例 + 主语 + 谓语，with + 数字</li>
<li>句型二：主语 +（表示“组成”的动词）+ 数字</li>
<li>句型三：单位 of 主语 + which/ who… + is + 数字</li>
<li>句型四：数字 + 主语 + 谓语</li>
<li>句型五：There be + 数字 + 主语 + which/ who…</li>
<li>句型六：For + 主题，数字 + 主语 + 谓语</li>
</ul>
<h3 id="举个栗子">举个栗子</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/12/IELTS1/eg3.png" class title="eg3">
<ul>
<li>句型一：The majority of sales in Bob’s store <strong>come from</strong> DVDs, <strong>with exactly</strong> 60%.</li>
<li>句型二：DVDs <strong>account for</strong> three fifths of the total sales.</li>
<li>句型三：<strong>The percentage</strong> of PC games sold <strong>is exactly</strong> 20%.</li>
<li>句型四：Fifteen percent of items sold in the store are CDs.</li>
<li>句型五：<strong>There is</strong> merely 5% of the total revenue <strong>generated by</strong> selling posters.</li>
<li>句型六：<strong>For</strong> the sales of posters, only 5% <strong>contributes to</strong> the turnover（营业额）.</li>
</ul>
<h3 id="顺序">顺序</h3>
<p>遇到单一个饼图的话，应该把它独立成一个主体段，段里按照不同元素的占比，从大到小按顺序写（静态图）</p>
<blockquote>
<p>It is clear from the pie chart that（开头句式，引出第一个数据） a majority of sales in Bob’s store come from DVDs, with exactly 60%. Sales are spread over other goods. (引出其余四项数据) Specifically（具体来说）, the percentage of PC games sold is exactly 20%, whereas（表示对比）fifteen percent of items sold in the store are CDs. Lastly（引出最后一个元素）, for the sales of posters, only 5% contributes to the turnover.</p>
</blockquote>
<h2 id="流程图-diagran">流程图（Diagran）</h2>
<h3 id="思路">思路</h3>
<ol>
<li>看箭头，找主要步骤</li>
<li>找名词，添加细节</li>
</ol>
<h3 id="举个栗子">举个栗子</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/12/IELTS1/eg4.png" class title="eg4">
<blockquote>
<p>总起说明</p>
</blockquote>
<p>The diagram gives information about how a hydroelectric power station generates electricity by means of the flow of water.</p>
<blockquote>
<p>主要流程（白天）</p>
</blockquote>
<p>In the daytime, water, coming from the river and kept in the high-level reservoir, flows through the intake which is under the dam and is only open during the day time. Then the water comes to the power station where the flow of water produces electricity through a generator which is operated by reversible turbines. Finally, the electricity goes from power lines to the national grid.</p>
<blockquote>
<p>特殊情况（夜晚）</p>
</blockquote>
<p>However, when it gets dark, the power station works in a reversed but easier way. Water kept in the low level reservoir is pumped by reversible turbines and finally it comes to the high level reservoir.</p>
<blockquote>
<p>总结（different——》比较）</p>
</blockquote>
<p>Overall, based on working time, the process could be divided into two different parts. In the day time, the process is far more complicated while in the night time, it is much easier.</p>
<h2 id="地图题-map">地图题（Map）</h2>
<h3 id="思路">思路</h3>
<ol>
<li>找出两幅图的变化</li>
<li>按照方位，依次写出建筑物的特征。第一幅图不写变化，第二幅图些变化</li>
</ol>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/12/IELTS1/eg5.png" class title="eg5">
<h3 id="举个栗子">举个栗子</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/12/IELTS1/eg6.png" class title="eg6">
<blockquote>
<p>总起说明</p>
</blockquote>
<p>The two maps give information about how a village park has changed over ten years.</p>
<blockquote>
<p>描述之前（第一幅图）</p>
</blockquote>
<p>Ten years ago, there was a large football pitch in the center. To its south was a small pond, and in the southeastern corner stood woods, whose area was much larger than pond and slightly smaller than football pitch. In the north, near the border were two tennis courts. Between these two sport areas sat a car park in the west which could house 20 cars and a children’s play area in the east.</p>
<blockquote>
<p>说明变化（第二幅图）</p>
</blockquote>
<p>The football pitch now is still located in the center but occupies a marginally smaller area. In the south, the pond is used for boating now; the woods have been cleared and are replaced by a cafe. Besides, in the southwestern corner lies a new picnic area.On the northern side, the number of tennis courts has doubled and the car park has been enlarged, which means it could house 50 people currently. children’s play area has been divided into Children’s park and Children’s soft play area. In addition to changes inside the park, there is also a new cycle path around the whole area.</p>
<blockquote>
<p>总结（整体的变化）</p>
</blockquote>
<p>Overall, there are more sports facilities and parking space, and the natural spots in the south have been transformed to places for recreational activities.</p>
]]></content>
      <categories>
        <category>雅思</category>
      </categories>
      <tags>
        <tag>雅思写作</tag>
        <tag>英语</tag>
      </tags>
  </entry>
  <entry>
    <title>雅思写作Task2</title>
    <url>/2022/08/27/IELTS2/</url>
    <content><![CDATA[<h2 id="大作文基本了解">大作文基本了解</h2>
<h3 id="得分-时间-要求">得分+时间+要求</h3>
<p>大作文得分占比2/3，时间约40分钟，要求250字上下</p>
<h3 id="类型">类型</h3>
<ul>
<li>优缺点</li>
<li>同意不同意</li>
<li>双边观点</li>
<li>报告类</li>
</ul>
<h2 id="结构layout">结构layout</h2>
<h3 id="开头">开头</h3>
<p>开头句由两部分构成：<strong>背景句</strong>+<strong>观点句</strong></p>
<ol>
<li>
<p>背景句改写</p>
<ul>
<li>换词</li>
<li>换主语</li>
<li>传统现在对比法（也要追求词语和主语的多样性）
<ul>
<li>传统：Traditionally/It is traditional that…</li>
<li>现在：
<ul>
<li>But now this situation has changed with… - But now it has been suggested that…</li>
<li>But now it has been encouraged that…</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>注意：题目中有两个对比的对象时，可以选择对比法，没有对比的对象时，直接换词、换主语。</p>
</blockquote>
</li>
<li>
<p>观点句写法</p>
<ul>
<li>优缺点，同意不同意：用 although 表明观点</li>
<li>双边观点：观点 A 和观点 B 矛盾，用 although；不矛盾，用 both and</li>
<li>报告类：直接回答题目（原因＋措施；原因＋结果；措施＋结果）</li>
</ul>
</li>
</ol>
<h3 id="中间段">中间段</h3>
<p>（后面详细讲）</p>
<h3 id="结尾">结尾</h3>
<p>（与开头对应）</p>
<h2 id="开头结尾举例">开头结尾举例</h2>
<h3 id="优缺点类开头结尾">优缺点类开头结尾</h3>
<p>In some countries, more and more adults choose to live with their parents after they graduate and find jobs. Do the advantages of this outweigh the disadvantages?</p>
<h4 id="利弊相等">利弊相等</h4>
<p>开头：Living with parents has become an increasingly popular choice among young adults who have already graduated and been employed. <u><strong>In my opinion</strong>, this practice has <strong>both</strong> positive <strong>and</strong> negative outcomes. </u></p>
<p>结尾 ：<strong>Overall</strong>, staying with parents is beneficial to these graduates. <u><strong>However</strong>, it may also lead to some problems that should not be overlooked.</u></p>
<h4 id="利大于弊">利大于弊</h4>
<p>开头：Living with parents has become an increasingly popular choice among young adults who have already graduated and been employed. <u><strong>In my opinion</strong>, this practice <strong>has some benefits</strong>, <strong>although</strong> there are some problems that should not be overlooked.</u></p>
<p>结尾：Overall，staying with parents should be encouraged. <u><strong>While</strong> such a practice may lead to problems, the negative outcomes can be reduced to a minimum by means of effective methods.</u></p>
<blockquote>
<p>总之，xxx是应该被鼓励的，虽然xxx会导致一些问题，但是这些后果可以通过一些措施被减轻到最小（the negative outcomes can be reduced to a minimum by means of effective methods）。</p>
</blockquote>
<h4 id="弊大于利">弊大于利</h4>
<p>开头：Living with parents has become an increasingly popular choice among young adults who have already graduated and been employed.<u> <strong>Although</strong> this practice has some benefits, <strong>it may lead to some problems</strong>. </u></p>
<p>结尾：<u><strong>Overall</strong>，<strong>while</strong> there are some advantages in advocating such a practice, it is not practical for these graduates to stay with their parents.</u></p>
<h3 id="同意不同意开头结尾">同意不同意开头结尾</h3>
<p>Schools should stop teaching children with books which students think boring, and use films, TV, video games and computer instead. To what extent do you agree or disagree?（2018.8.18）</p>
<h4 id="偏向同意">偏向同意</h4>
<p>开头：<strong>Traditionally</strong>, students are taught through written books. <strong>Nowadays</strong>, different teaching methods like films, video games are suggested to replace the boring books. <u><strong>In my opinion</strong>, I generally agree with the practice, <strong>although</strong> it <strong>may lead to some problems</strong>.</u></p>
<p>结尾：<u><strong>In conclusion</strong>, replacing paper-based teaching method with media-based one should be encouraged, <strong>although</strong> this practice may have some drawbacks.</u></p>
<h4 id="偏向不同意">偏向不同意</h4>
<p>开头：Traditionally, students are taught through written books. Nowadays, different teaching methods like films, video games are suggested to replace the boring books. <u><strong>In my opinion</strong>, I <strong>generally disagree with</strong> the practice, although it has some benefits. </u></p>
<p>结尾：<u><strong>In conclusion</strong>, <strong>although</strong> replacing paper-based teaching method with media-based one has some benefits, this practice has some drawbacks and should not be encouraged.</u></p>
<h3 id="双边观点">双边观点</h3>
<h4 id="两观点矛盾-a-or-b">两观点矛盾（A or B）</h4>
<p>Some people think that younger people are not suitable for important positions in governments of countries, while others think that it is a good idea for younger people to take these positions. Discuss both views and give your own opinion.（2017.10.21）</p>
<p>开头：Leaders or directors in governments are important positions. <strong>People have different views on</strong> whether young people are qualified to such posts. <u><strong>In my opinion</strong>, <strong>Although</strong> this group may have problems in taking these posts, I <strong>would argue that</strong> it is a good choice for them to do so. </u></p>
<p>结尾：<u><strong>In conclusion</strong>, these young people should be given the equal access to the important positions in governments. <strong>Although</strong> they may be less experienced, this can be addressed effectively by means of related measures.</u></p>
<h4 id="两观点不矛盾-a-and-b">两观点不矛盾（A and B）</h4>
<p>People have different views on how governments reduce traffic congestion. Some think it can be solved by building more trains and subway lines, while others think building more roads and widening existing roads will reduce traffic congestion. Discuss both views and give your own opinion.（2018.7.7）</p>
<p>开头：In contemporary society, the traffic congestion is becoming increasingly serious. <strong>People have different views on</strong> how to tackle such a pressing problem.<u> <strong>In my opinion</strong>, <strong>both</strong> the development of public transport <strong>and</strong> the construction of roads <strong>are equally important</strong>. </u></p>
<p>结尾： <u><strong>In conclusion</strong>, <strong>the above mentioned two measures are not mutually exclusive</strong>. They <strong>both</strong> play an significant part in alleviating traffic jam.</u></p>
<h3 id="报告类">报告类</h3>
<p>The natural resources such as oil, forests and water are being consumed at an alarming rate. What problems does it cause and how can we solve the problems?（2015.8.1）</p>
<p>开头：<strong>In recent years</strong>, the depletion of natural resources has become increasingly rapid. <strong>This may lead to serious consequences and it is high time that related measures should be adopted.</strong></p>
<p>结尾：<strong>Overall</strong>, <strong>the problems are alarmingly pressing</strong>. <strong>However</strong>, <strong>If the above mentioned measures are taken effectively and efficiently, the negative outcomes can be reduced to a minimum.</strong></p>
<h2 id="中间段结构">中间段结构</h2>
<h3 id="优缺点-advantage-or-disadvantage">优缺点 Advantage or disadvantage</h3>
<h4 id="偏向于好处">偏向于好处</h4>
<p><strong>偏向于好处</strong>用<strong>起立驳尾</strong></p>
<h5 id="起"><strong>起</strong></h5>
<p>Although there may be a problem, I think such a practice is beneficial/should be encouraged.</p>
<h5 id="立"><strong>立</strong></h5>
<p>（写一个优点或两个优点都可以）</p>
<ol>
<li>优点 1：</li>
</ol>
<ul>
<li>方法一：The obvious argument in favor of sth（sth 是根据题目来，比 如可以是 doing unpaid community service/learning art classes） is that ＋完整的句子（优点 1）
<ul>
<li>Eg：The obvious argument in favor of doing unpaid community service is that students could develop interpersonal skills（优点具体）</li>
</ul>
</li>
<li>方法二：It is true that ＋完整的句子(优点 1)
<ul>
<li>Eg：It is true that doing unpaid community service tends to have a favorable effect on students.（优点抽象）</li>
</ul>
</li>
</ul>
<ol>
<li>优点 2：<br>
Apart from that，another reason for advocating sth （sth 根据题目来, 比 如可以是 voluntary projects）is that ＋完整的句子（优点 2）</li>
</ol>
<ul>
<li>Eg：Apart from that, another reason for advocating voluntary projects is that students can adapt to the society easily.</li>
</ul>
<h5 id="驳"><strong>驳</strong></h5>
<p>（坏处可以被解决） However, it may be argued that sth is bad for sb. Specifically, ＋缺点. Fortunately, this alarmingly pressing problem could be reduced to a minimum if ＋措施</p>
<h5 id="尾"><strong>尾</strong></h5>
<p>In conclusion，sth is beneficial to sb. Although it may have a problem, it could be solved effectively and efficiently by means of related measure.(注意 measure，problem 的单复数)</p>
<h4 id="偏向于坏处">偏向于坏处</h4>
<p><strong>偏向于坏处</strong>用<strong>起承转合</strong></p>
<h5 id="起">起</h5>
<p>Although it may be beneficial, the problems should not be overlooked.</p>
<h5 id="承">承</h5>
<p>The obvious argument in favor of sth（sth 是根据题目来，比如可以是 doing unpaid community service/learning art classes） is that ＋完整的 句子（优点）</p>
<h5 id="转">转</h5>
<p>However, the problems arising from this practice are far more pressing. The first shortcoming is that＋完整的句子（缺点 1 ）Another drawback is that＋完整的句子（缺点 2）</p>
<h5 id="合">合</h5>
<p>In conclusion，sth should not be encouraged，although it is good for sb.</p>
<h3 id="同意不同意agree-or-disagree">同意不同意Agree or disagree</h3>
<p>同样可以用到<strong>起立驳尾</strong>和<strong>起承转合</strong>的结构</p>
<h4 id="起立驳尾">起立驳尾</h4>
<p>（把同意的原因立起来，再说不同意，随后反驳不同意）</p>
<ul>
<li>Eg：Some people believe that it is a good idea to continue to work at their old age. Do you agree or disagree?
<ul>
<li>起：同意老人持续工作</li>
<li>立：同意的原因（有经验，对公司好）</li>
<li>驳：不同意的原因，随后反驳（身体较差，但只要公司合理安排时间，保证老人有足够的休息，坏处就可以避免）</li>
<li>尾：同意老人持续工作</li>
</ul>
</li>
</ul>
<h4 id="起承转合">起承转合</h4>
<p>（先承认同意的原因，再转向不同意）</p>
<ul>
<li>Eg: Some said the teachers’ main role is to transmit the information. Nowadays students are exposed to different information, so the role of the teacher will not work in modern education. Do you agree or disagree with this opinion?
<ul>
<li>起：不同意老师会消失</li>
<li>承：同意的原因（学生可以自学，不需要老师）</li>
<li>转：不同意的原因（但学生不能辨别网上信息的真假，老师的存在， 可以让老师和学生互动，可以向学生提供帮助）</li>
<li>合：不同意老师会消失</li>
</ul>
</li>
</ul>
<h3 id="双边观点-both-views">双边观点 Both views</h3>
<ol>
<li>两观点矛盾，用 A or B 结构</li>
</ol>
<ul>
<li><strong>Introduction</strong>： Although B…, I think A…（偏向于 A）</li>
<li><strong>Body1</strong>： Some people think that 观点 A 的合理性</li>
<li><strong>Body2</strong>： However, opponents may make it clear that 先说观点 B 的合理性，再 说观点 B 的不合理性</li>
<li><strong>Conclusion</strong>：偏向观点 A</li>
</ul>
<ol start="2">
<li>两观点不矛盾，用 A and B 的结构</li>
</ol>
<ul>
<li><strong>Introduction</strong>： Both A and B</li>
<li><strong>Body1</strong>： Some people think that 观点 A 的合理性</li>
<li><strong>Body2</strong>： However, opponents may make it clear that 观点 B 的合理性。</li>
<li><strong>Conclusion</strong>： Both A and B</li>
</ul>
<h3 id="报告类结构">报告类结构</h3>
<p>Consumption of the world’s resources(such as oil,fresh water,etc) is increasing at a dangerous rate. What are the causes of this increased consumption? What can people do to reduce it?</p>
<p><strong>Introduction：</strong><br>
In recent years, people deplete natural resources rapidly. From my perspective, there are several reasons accountable for this phenomenon and it is high time that related measures should be adopted.</p>
<p><strong>Body1：</strong><br>
First of all, sth is the primary reason.(原因 1)＋Another cause is that（原因 2）</p>
<p><strong>Body2:</strong><br>
Serious as the phenomenon is, there are some effective and efficient measures. One possible method is to（措施 1）. Another solution is to （措施 2）</p>
<p><strong>Conclusion:</strong><br>
Overall the consumption of the world’s resources is undergoing a dangerous rate, however, it is still not too late to settle the problem. With population control and the improvement of the awareness of saving resources, the problem can be effectively addressed.</p>
<h2 id="论证方法总结">论证方法总结</h2>
<ol>
<li>原因：this is because, as, since</li>
<li>结果: as a result, as a consequence, consequently</li>
<li>假设：when</li>
<li>抽象到具体：like, such as</li>
<li>反面论证: by contrast (最多用一次）</li>
</ol>
<p>Eg：The participation in community services helps develop students’ interpersonal skills. This is because they would meet different peers coming from different background. When asked to finish some tasks, like cleaning a library or taking good care of old people, such teenagers may be encountered with some problems. In this case, they are more likely to cooperate with each other with the aim of successfully and effectively solving the problems. As a result, these adolescents could have a better understanding of the importance of team spirit, which helps them to adjust to a wider community easily. By contrast, those who stay away from such free services may find it hard to adapt to the society where cooperation is of great significance.</p>
]]></content>
      <categories>
        <category>雅思</category>
      </categories>
      <tags>
        <tag>雅思写作</tag>
        <tag>英语</tag>
      </tags>
  </entry>
  <entry>
    <title>LC旋转数组</title>
    <url>/2021/05/20/LC%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<h1 id="旋转数组">旋转数组</h1>
<p>给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。</p>
<blockquote>
<p><strong>示例 1:</strong></p>
<ul>
<li>输入: nums = [1,2,3,4,5,6,7], k = 3</li>
<li>输出: [5,6,7,1,2,3,4]</li>
<li>解释:
<ul>
<li>向右旋转 1 步: [7,1,2,3,4,5,6]</li>
<li>向右旋转 2 步: [6,7,1,2,3,4,5]</li>
<li>向右旋转 3 步: [5,6,7,1,2,3,4]</li>
</ul>
</li>
</ul>
</blockquote>
<blockquote>
<p><strong>示例 2:</strong></p>
<ul>
<li>输入：nums = [-1,-100,3,99], k = 2</li>
<li>输出：[3,99,-1,-100]</li>
<li>解释:
<ul>
<li>向右旋转 1 步: [99,-1,-100,3]</li>
<li>向右旋转 2 步: [3,99,-1,-100]</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="方法一：傻瓜方法">方法一：傻瓜方法</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rotate</span><span class="params">(<span class="keyword">int</span>* nums, <span class="keyword">int</span> numsSize, <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> length = numsSize;</span><br><span class="line">    <span class="keyword">int</span> <span class="built_in">list</span>[length];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;length;i++)&#123;</span><br><span class="line">        <span class="built_in">list</span>[i]=nums[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;length;j++)&#123;</span><br><span class="line">        nums[(j+k)%length]=<span class="built_in">list</span>[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="方法二：旋转旋转旋转">方法二：旋转旋转旋转</h2>
<p>举个例子：</p>
<blockquote>
<p>nums = [1,2,3,4,5,6,7], k = 3</p>
<ol>
<li>[7,6,5,4,3,2,1] (整个数组旋转)</li>
<li>[[5,6,7],[1,2,3,4]]</li>
</ol>
</blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rotate</span><span class="params">(<span class="keyword">int</span>* nums, <span class="keyword">int</span> numsSize, <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">    <span class="comment">//先旋转整个数组-》旋转前一部分-》旋转后一部分</span></span><br><span class="line">    k=k%numsSize;</span><br><span class="line">    reverse(nums,<span class="number">0</span>,numsSize<span class="number">-1</span>);</span><br><span class="line">    reverse(nums,<span class="number">0</span>,k<span class="number">-1</span>);</span><br><span class="line">    reverse(nums,k,numsSize<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reverse</span><span class="params">(<span class="keyword">int</span>* nums, <span class="keyword">int</span> start, <span class="keyword">int</span> end)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(start&lt;end)&#123;</span><br><span class="line">        <span class="keyword">int</span> tmp = nums[start];</span><br><span class="line">        nums[start++]=nums[end];</span><br><span class="line">        nums[end--]=tmp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>刷题</category>
      </categories>
      <tags>
        <tag>LC</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG 应知必会</title>
    <url>/2024/04/08/LLM-Learning1/</url>
    <content><![CDATA[<blockquote>
<p>参考：<a href="https://arxiv.org/abs/2312.10997">Retrieval-Augmented Generation for Large Language Models: A Survey</a></p>
</blockquote>
<h1 id="rag的发展">RAG的发展</h1>
<p>RAG技术的发展可以从技术范式的角度分为几个阶段，主要包括：</p>
<ul>
<li><strong>朴素RAG(Naive RAG)</strong>:这是RAG技术的基出形式，包括三个基本步骤：索引(将文档库分割成较短的Chunk并通过编码器构建向量索引)、检索(根据问题和chunks的相似度检索相关文档片段)、生成(以检索到的上下文为条件，生成问题的回答)。</li>
<li><strong>进阶的RAG(Advanced RAG)</strong>:为了解决Naive RAG在检索质量、响应生成质量以及增强过程中的挑战，Advanced RAG:范式被提出。它在数据索引、检索前和检索后都进行了额外处理，如更精细的数据清洗、设计文档结构和添加元数据等，以提升文本的<br>
一致性、准确性和检索效率。</li>
<li><strong>模块化RAG(Modular RAG)</strong>:随着RAG技术的进一步发展，模块化RAG概念被提出。它在结构上更加自由和灵活，引入了更多的具体功能模块，例如查询搜索引擎、融合多个回答。技术上将检索与微调分开，提供了更高的自定义性和灵活性。</li>
</ul>
<p>三个阶段之间是继承与发展的关系：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/04/08/LLM-Learning1/p1.png" class title="p1">
<h1 id="如何评价rag">如何评价RAG</h1>
<blockquote>
<p>🚩 <big><strong>评估指标</strong></big>：</p>
<ol>
<li>上下文相关性一一检索的上下文是否相关</li>
<li>上下文回溯一评估检索到的上下文是否包含了问题的所有必要信息</li>
<li>忠实度一一生成的答案是否与检索的内容一致，是否保留了原始信息</li>
<li>答案相关性一一评估生成的答案是否与问题相关，以及是否提供了有用的信息</li>
</ol>
</blockquote>
<h2 id="评估角度">评估角度</h2>
<h3 id="rag三元组">RAG三元组</h3>
<ul>
<li><strong>Context Relevance</strong>：衡量召回的Context能够支持Query的程度。如果该得分低，反应出了召回了太多与Qury问题无关的内容，这些错误的召回知识会对LLM的最终回答造成一定影响。</li>
<li><strong>Groundedness</strong>：衡量LLM的Response遵从召回的Context的程度。如果该得分低，反应出了LLM的回答不遵从召回的知识，那么回答出现幻觉的可能就越大。</li>
<li><strong>Answer Relevance</strong>：衡量最终的Response回答对Query提问的相关度。如果该得分低，反应出了可能答不对题。</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/04/08/LLM-Learning1/p2.png" class title="p2">
<h3 id="基于ground-truth的指标">基于Ground-truth的指标</h3>
<ul>
<li>Ground-truth是回答，那就可以<u>直接比较RAG应用的回答和ground-truth之间的相关性</u>，来端到端地进行衡量。</li>
<li>让LLM生成评估测试集，来生成query和ground-truth,比如，在ragas的 <a href="https://docs.ragas.io/en/latest/concepts/testset_generation.html">Synthetic Test Data generation</a> 和 <a href="https://docs.llamaindex.ai/en/stable/examples/evaluation/QuestionGeneration.html">llama-index QuestionGeneration</a> 中都有一些集成好的方法，可以直接方便地使用。</li>
<li>Ground-truth是知识文档中的chunks，对比ground-truth doc chunks和召回的contexts之间的相关性。</li>
</ul>
<h3 id="基于llm的定量评估">基于LLM的定量评估</h3>
<ul>
<li>有了GPT-4后，其可行性就提高了。我们只需设计好prompt,将要打分的一些文字放入prompt,访问GPT-4,就可以得到一个想要的得分结果。</li>
</ul>
<h2 id="评估工具">评估工具</h2>
<ol>
<li>RAGAs:<a href="https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html">https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html</a></li>
<li>TruLens:<a href="https://www.trulens.org/trulens_eval/install/">https://www.trulens.org/trulens_eval/install/</a></li>
<li>Llama-Index:<a href="https://docs.llamaindex.ai/en/stable/optimizing/evaluation/evaluation.html">https://docs.llamaindex.ai/en/stable/optimizing/evaluation/evaluation.html</a></li>
<li>Phoenix:<a href="https://docs.arize.com/phoenix/">https://docs.arize.com/phoenix/</a></li>
<li>DeepEval:<a href="https://github.com/confident-ai/deepeval">https://github.com/confident-ai/deepeval</a></li>
<li>LangSmith:<a href="https://docs.smith.langchain.com/evaluation/evaluator-implementations">https://docs.smith.langchain.com/evaluation/evaluator-implementations</a></li>
<li>OpenAI Evals:<a href="https://github.com/openai/evals">https://github.com/openai/evals</a></li>
</ol>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/04/08/LLM-Learning1/p3.png" class title="p3">
<h1 id="rag未来发展方向">RAG未来发展方向</h1>
<h2 id="rag的垂直优化">RAG的垂直优化</h2>
<ul>
<li>长下文长度
<ul>
<li>检索内容过多，超过窗口限制怎么办？</li>
<li>如果LLMs的上下文窗口不再受限制，RAG应该如何改进？</li>
</ul>
</li>
<li>鲁棒性
<ul>
<li>检索到错误内容怎么处理？</li>
<li>怎么对检索出来内容进行过滤和验证？</li>
<li>怎么提高模型抗毒、抗噪声的能力。</li>
</ul>
</li>
<li>与微调协同
<ul>
<li>如何同时发挥RAG和FT的效果，两者怎么协同，怎么组织，是串行、交替还是端到端？</li>
</ul>
</li>
<li>Scaling-Law
<ul>
<li>RAG模型是否满足Scaling Law?</li>
<li>RAG是否会，或是在什么场景下会出现Inverse Scaling Law的现象？</li>
</ul>
</li>
<li>LLM的角色
<ul>
<li>LLMs可以用于检索(用LLMs的生成代替检索或检索LLMs记忆)、用于生成、用于评估。如何进一步挖掘LLMs在RAG中的潜力？</li>
</ul>
</li>
</ul>
<h2 id="工程实践">工程实践</h2>
<ul>
<li>如何降低超大规模语料的检索时延？</li>
<li>如何保证检索出来内容不被大模型泄露？</li>
</ul>
<h2 id="rag的多模态的拓展">RAG的多模态的拓展</h2>
<ul>
<li>如何将RAG不断发展的技术和思想拓展到图片、音频、视频或代码等其他模态的数据中？</li>
<li>一方面可以增强单一模态的任务，另一方面可以通过RAG的思想将多模态进行融合。</li>
</ul>
<h2 id="rag的生态">RAG的生态</h2>
<ul>
<li>RAG的应用已经不仅仅局限于问答系统，其影响力正在扩展到更多领域。现在，推荐系统、信息抽取和报告生成等多种任务都开始受益于RAG技术的应用。</li>
<li>与此同时，RAG技术栈也在井喷。除了已知的Langchain和LlamaIndex等工具，市场上涌现出更多针对性的RAG工具，例如：用途定制化，满足更加聚焦场景的需求；使用简易化，进一步降低上手门槛的；功能专业化，逐渐面向生产环境。</li>
</ul>
]]></content>
      <categories>
        <category>大模型</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>RAG开发的痛点以及解决方案</title>
    <url>/2024/04/10/LLM-Learning2/</url>
    <content><![CDATA[<div class="hide-toggle" style="border: 1px solid bg"><div class="hide-button toggle-title" style="background-color: bg;color: color"><i class="fas fa-caret-right fa-fw"></i><span>参考</span></div>
    <div class="hide-content"><ul>
<li><a href="https://towardsdatascience.com/12-rag-pain-points-and-proposed-solutions-43709939a28c">12 RAG Pain Points and Proposed Solutions</a></li>
<li><a href="https://baoyu.io/translations/rag/12-rag-pain-points-and-proposed-solutions">https://baoyu.io/translations/rag/12-rag-pain-points-and-proposed-solutions</a></li>
</ul>
</div></div>
<h1 id="引言">引言</h1>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/04/10/LLM-Learning2/p1.webp" class title="p1">
<p>图源自 Barnett 等人的研究 <a href="https://baoyu.io/translations/ai-paper/2401.05856v1-seven-failure-points-when-engineering-a-retrieval-augmented-generation-system">工程化检索增强生成系统时的七大挑战</a>。后面会介绍上述7大挑战，并且补充5个额外的挑战，以及它们的解决方案：</p>
<ul>
<li>痛点 1：缺失内容</li>
<li>痛点 2：关键文档被遗漏</li>
<li>痛点 3：文档整合的长度限制 —— 超出上下文</li>
<li>痛点 4：提取困难</li>
<li>痛点 5：格式错误</li>
<li>痛点 6：缺乏具体细节</li>
<li>痛点 7：回答不全面</li>
<li>痛点 8：数据摄入的可扩展性问题</li>
<li>痛点 9：结构化数据的问答</li>
<li>痛点 10：从复杂 PDF 文档提取数据</li>
<li>痛点 11：备用模型策略</li>
<li>痛点 12：大语言模型的安全性</li>
</ul>
<h1 id="痛点1：缺失内容">痛点1：缺失内容</h1>
<p><strong>具体描述</strong>：当提出的问题无法从可用文档中找到答案时，RAG系统可能会回答&quot;对不起，我不知道”，但如果问题与内容相关却没有答案，系统可能会被误导提供错误的回答。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>数据清洗，构建高质量的数据</p>
</li>
<li>
<p>prompt优化</p>
<ul>
<li>例如，通过设置提示：“如果你对答案不确定，就告诉我你不知道”，可以鼓励模型承认其局限性，并更透明地表达不确定性。虽然无法保证百分百的准确率，但在数据清洗之后，设计恰当的提示是提高回答质量的有效手段之一。</li>
</ul>
</li>
</ul>
<h1 id="痛点2：关键文档被遗漏">痛点2：关键文档被遗漏</h1>
<p><strong>具体描述</strong>：问题的答案在文档中，但排名没有足够高以返回给用户。（理论上所有文档都会被排名并用于下一步，但实际上只返回排名最高的K个文档）。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>通过调整<code>chunk_size</code>和<code>similarity_top_k</code>两个参数优化检索效果</p>
<ul>
<li><a href="https://medium.com/gitconnected/automating-hyperparameter-tuning-with-llamaindex-72fdd68e3b90?sk=0a29f2025b965040b9b1defd9525e4eb">通过 LlamaIndex 实现超参数自动调整中</a></li>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/param_optimizer/param_optimizer.html">对 RAG 进行超参数优化</a></li>
</ul>
</li>
<li>
<p>检索结果的优化排序（Rerank算法）</p>
<ul>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/CohereRerank.html">优化排序的前后差异</a></li>
<li>另外，通过各种嵌入技术和排序器，可以对检索性能进行评估和提升，详见<a href="https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83">提升 RAG 性能：挑选最优的嵌入技术和排序模型</a>，由 Ravi Theja 撰写。</li>
<li>定制化的排序器经过微调后能够实现更优的检索性能，具体实施方法请参阅<a href="https://blog.llamaindex.ai/improving-retrieval-performance-by-fine-tuning-cohere-reranker-with-llamaindex-16c0c1f9b33b">通过微调 Cohere 排序器与 LlamaIndex 提升检索效果</a></li>
</ul>
</li>
</ul>
<h1 id="痛点3：文档整合的长度限制一超出上下文">痛点3：文档整合的长度限制一超出上下文</h1>
<p><strong>具体描述</strong>：数据库检索到包含答案的文档，但这些文档没有被包含在生成答案的上下文中。当数据库返回许多文档时，需要进行整合处理以检索答案。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>调整检索策略：比如：基础检索、知识图谱检索等</p>
</li>
<li>
<p>微调嵌入技术：如果使用的是开源嵌入模型，对其进行微调是提高检索准确度的有效手段。<a href="https://docs.llamaindex.ai/en/stable/examples/finetuning/embeddings/finetune_embedding.html">嵌入模型微调指南</a></p>
</li>
</ul>
<h1 id="痛点4：提取困难">痛点4：提取困难</h1>
<p><strong>具体描述</strong>：答案存在于上下文中，但大型语言模型未能提取出正确的答案。这通常发生在上下文中存在太多噪声或矛盾信息时。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>数据清洗</p>
</li>
<li>
<p>提示信息压缩，可以参考：<a href="https://rzv2chzpkh.feishu.cn/wiki/FIMJwPPyGiKJmAkuhJGcBrAonKe#CZQ6dQ58HotZswxkNTrcqZiwnGf">LongLLMLingua.pdf</a></p>
</li>
<li>
<p>LongContextReorder（长内容优先排序）：<a href="https://arxiv.org/abs/2307.03172">研究</a>发现，当关键数据被放置在输入内容的开始或结尾时，往往能够获得最佳的性能表现。为了解决信息在输入中间部分“迷失”的问题，LongContextReorder 应运而生，它通过重新排序检索到的节点来优化处理，特别适用于需要处理大量顶级结果的情形。</p>
</li>
</ul>
<h1 id="痛点5：格式错误">痛点5：格式错误</h1>
<p><strong>具体描述</strong>：问题涉及以特定格式（如表格或列表）提取信息，但大型语言模型忽略了指令。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>prompt优化</p>
</li>
<li>
<p>输出解析：可以在以下方面帮助确保获得期望的输出：为任何提示/查询提供格式化指令；对大语言模型的输出进行“解析”</p>
<ul>
<li><a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/pydantic_program.html">Pydantic程序</a></li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> llama_index.program <span class="keyword">import</span> OpenAIPydanticProgram</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define output schema (without docstring)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Song</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    title: <span class="built_in">str</span></span><br><span class="line">    length_seconds: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Album</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    artist: <span class="built_in">str</span></span><br><span class="line">    songs: List[Song]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define openai pydantic program</span></span><br><span class="line">prompt_template_str = <span class="string">&quot;&quot;&quot;\</span></span><br><span class="line"><span class="string">Generate an example album, with an artist and a list of songs. \</span></span><br><span class="line"><span class="string">Using the movie &#123;movie_name&#125; as inspiration.\</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">program = OpenAIPydanticProgram.from_defaults(</span><br><span class="line">    output_cls=Album, prompt_template_str=prompt_template_str, verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run program to get structured output</span></span><br><span class="line">output = program(</span><br><span class="line">    movie_name=<span class="string">&quot;The Shining&quot;</span>, description=<span class="string">&quot;Data model for an album.&quot;</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="痛点6：缺乏具体细节">痛点6：缺乏具体细节</h1>
<p><strong>具体描述</strong>：回答在响应中返回，但不够具体或过于具体，无法满足用户的需求。当RAG系统设计者对给定问题有预期结果时（例如针对学生的教学内容），就会发生这种情况。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>进阶检索技巧：从小到大的信息聚合检索、递归式检索方法
<ul>
<li>参考文章：<a href="https://towardsdatascience.com/jump-start-your-rag-pipelines-with%E9%AB%98%E7%BA%A7%E6%A3%80%E7%B4%A2-llamapacks-%E5%92%8C-lighthouz-ai-80a09b7c7d9d?sk=14e50a68f9ef825aaa6634365c7d9617">如何通过高级检索 LlamaPacks 优化您的 RAG 流程，并利用 Lighthouz AI 进行性能基准测试</a></li>
</ul>
</li>
</ul>
<h1 id="痛点7：回答不全面">痛点7：回答不全面</h1>
<p><strong>具体描述</strong>：回答不完整并不是错误的，但遗漏了一些信息，尽管这些信息在上下文中可用并且可以提取。例如，对于&quot;这些文件A、B和C的关键点是什么？&quot;这样的问题，更好的方法是分别询问这些问题。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>查询变换的技巧：一个有效提升凡AG处理能力的策略是增设一个查询理解层，即在实际检索知识库之前进行一系列的查询变换。具体来说，我们有以下四种变换方式：</p>
<ul>
<li>路由：在不改变原始查询的基础上，识别并定向到相关的工具子集，并将这些工具确定为处理该查询的首选。</li>
<li>查询改写：在保留选定工具的同时，通过多种方式重构查询语句，以便跨相同的工具集进行应用。</li>
<li>细分问题：将原查询拆解为若干个更小的问题，每个问题都针对特定的工具进行定向，这些工具是根据它们的元数据来选定的。</li>
<li>ReAct 代理工具选择：根据原始查询判断最适用的工具，并为在该工具上运行而特别构造的查询。</li>
</ul>
</li>
<li>
<p>参考文章：<a href="https://towardsdatascience.com/advanced-query-transformations-to-improve-rag-11adca9b19d1">提升 RAG 性能的高级查询变换技巧</a></p>
</li>
</ul>
<h1 id="痛点8：数据摄入的可扩展性问题">痛点8：数据摄入的可扩展性问题</h1>
<p><strong>具体描述</strong>：在RAG系统中，数据摄入的可扩展性问题指的是系统在有效管理和处理大规模数据时面临的挑战，这可能导致性能瓶颈甚至系统故障。这类问题可能会造成数据摄入时间过长、系统过载、数据质量下降以及可用性受限等现象。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>加速文档处理：并行摄取技术，参考：LlamaIndex 提供的<a href="https://github.com/run-llama/llama_index/blob/main/docs/examples/ingestion/parallel_execution_ingestion_pipeline.ipynb?__s=db5ef5gllwa79ba7a4r2&amp;utm_source=drip&amp;utm_medium=email&amp;utm_campaign=LlamaIndex+news%2C+2024-01-16">详细教程</a>。</li>
</ul>
<h1 id="痛点9：结构化数据的问答">痛点9：结构化数据的问答</h1>
<p><strong>具体描述</strong>：解读用户的查询并准确检索到所需的结构化数据是一项挑战，尤其是当面对复杂或模糊的查询请求时。这一挑战由于文本到SQL的转换不够灵活，以及当前大语言模型在处理这些任务上的局限性而更加复杂。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>链式思维表格包：适合处理包含多重信息的复杂表格单元问题，通过逐步精确地切割和解析数据，直至找到所需的数据子集，显著提高了对表格数据的查询效率，参考：<a href="https://arxiv.org/abs/2401.04398">链式表格原论文</a></p>
</li>
<li>
<p>混合自洽（多数投票法）查询引擎包：原文见<a href="https://arxiv.org/pdf/2312.16702v1.pdf">重新思考大语言模型如何理解表格数据</a></p>
</li>
</ul>
<h1 id="痛点10：从复杂pdf中提取数据">痛点10：从复杂PDF中提取数据</h1>
<p><strong>具体描述</strong>：在从复杂PDF文档，如嵌入表格的文档中提取数据进行问答时，传统的检索方法往往无法达到目的。需要一个更高效的方法来处理这种复杂的PDF数据提取需求。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>嵌入式表格检索技术：LlamaIndex 提出了一种解决方案——`EmbeddedTablesUnstructuredRetrieverPack</li>
</ul>
<h1 id="痛点11：备用模型策略">痛点11：备用模型策略</h1>
<p><strong>具体描述</strong>：在使用大语言模型过程中，可能会担心模型可能会遇到问题，比如遇到OpenAI模型的访问频率限制错误。这时候就需要一个或多个备用模型作为后备，以防主模型出现故障。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>
<p>Neutrino Router：Neutrino路由器能够通过一个预测模型，智能地选择最适合输入问题的大语言模型。</p>
</li>
<li>
<p>OpenRouter：OpenRouter提供了一个一站式的API接口，能够接入任何大语言模型。不仅能找到市场上任一模型的最低价格，还能在首选的服务提供商遇到问题时，自动切换到其他选项。</p>
</li>
</ul>
<h1 id="痛点12：llm的安全性：">痛点12：LLM的安全性：</h1>
<p><strong>具体描述</strong>：在设计和开发 AI 系统时，如何有效防止恶意输入、确保输出安全、保护敏感信息不被泄露等问题，都是每位 AI 设计师和开发者需要面对的重要挑战。</p>
<p><strong>解决方案</strong>：</p>
<ul>
<li>Llama Guard：保护大语言模型的新工具，借鉴7-B Llama 2的技术，Llama Guard旨在通过评估输入（例如分析提问的内容）和输出（即对回答的分类）来帮助大语言模型 (LLMs) 鉴别内容是否安全。它本身也使用了大语言模型技术，能够判断某个问题或回答是否安全，若发现不安全的内容，还会详细列出违反的具体规则。</li>
</ul>
]]></content>
      <categories>
        <category>大模型</category>
        <category>RAG</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>RAG</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读记录 —— LLM 相关</title>
    <url>/2024/07/20/LLM-Learning4/</url>
    <content><![CDATA[<h1 id="learning-to-reason-and-memorize-with-self-notes">Learning to Reason and Memorize with Self-Notes</h1>
<ul>
<li>原文链接：<a href="https://arxiv.org/abs/2404.14963">Learning to Reason and Memorize with Self-Notes</a></li>
<li>发表：NeurIPS 2023</li>
<li>时间：2023</li>
<li>机构：Meta AI</li>
</ul>
 <img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/20/LLM-Learning4/p2.png" class title="p2">
<h2 id="研究动机-motivation">研究动机（Motivation）</h2>
<p>大型语言模型（LLMs）在<strong>多步推理</strong>任务中表现不佳，并且<strong>无法保留先前的推理步骤</strong>以供将来使用。这限制了它们在复杂问题解答中的性能。</p>
<h2 id="解决的问题">解决的问题</h2>
<p>论文提出了一种名为“Self-Notes”的方法，旨在解决上述问题。这种方法允许<strong>模型在阅读上下文时，随时偏离输入内容生成明确的推理标记（即“Self-Notes”）</strong>，以增强其记忆并实现多步推理。</p>
<h2 id="方法">方法</h2>
<p>（需要微调）</p>
<ul>
<li>Self-Notes：与链式思维（Chain-of-Thought）或草稿板（Scratchpad）方法不同，Self-Notes 允许模型<strong>在任何时候</strong>插入与输入上下文和问题交织的内部推理笔记。</li>
<li>模型架构：考虑了一个自回归的变换器模型，该模型在生成最终输出之前，可以通过生成“笔记标记”来丰富上下文。</li>
</ul>
<h2 id="思考">思考</h2>
<ul>
<li>优势：可以帮助语言模型更好地处理长序列或复杂任务，且不需要太多的监督信号。</li>
<li>关键思路：与草稿板方法不同，本论文中的模型可以随时偏离输入上下文以明确思考。这种方法允许模型在阅读上下文的同时回忆信息并进行推理，从而扩展其记忆并实现多步推理。相比当前领域的研究状况，这篇论文的思路在于通过自我笔记的方式来解决有限上下文记忆和多步推理的问题。</li>
</ul>
<h1 id="dup">DUP</h1>
<p>Achieving &gt;97% on GSM8K: Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems</p>
<ul>
<li>发表：<a href="https://arxiv.org/abs/2404.14963">https://arxiv.org/abs/2404.14963</a></li>
<li>时间：2024.5.29</li>
<li>机构：武汉大学 &amp; 悉尼大学 &amp; 南洋理工大学</li>
</ul>
 <img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/20/LLM-Learning4/p1.png" class title="p1">
<h2 id="摘要总结">摘要总结</h2>
<p>大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但在处理复杂的数学文字题时，它们的推理能力常常不尽人意。这类问题通常包含三种错误：语义理解错误、计算错误和步骤遗漏错误。尽管已有研究关注计算错误和步骤遗漏错误，但语义理解错误作为限制LLMs性能的主要因素，却被忽视了。<br>
论文提出了一种简单但有效的方法，称为“Deeply Understanding the Problems”（DUP），通过解决语义理解错误来提高LLMs<strong>解决数学问题</strong>的能力。DUP方法的核心是<strong>鼓励LLMs深入理解问题</strong>，<strong>提取关键的解题信息</strong>，以进行更好的推理。</p>
<h2 id="研究动机">研究动机</h2>
<p>尽管 LLMs 在各种自然语言理解和生成任务中表现出色，但它们在推理任务（例如数学推理、常识推理和符号推理）中的表现往往不尽如人意。CoT prompting 方法虽然能够显著提升 LLMs 的推理能力，但它在处理复杂数学问题，尤其是数学应用题时，仍然存在以下三个主要问题：</p>
<ul>
<li>语义误解错误: LLMs 无法准确理解问题的核心内容，导致无法提取出解决问题的关键信息。</li>
<li>计算错误: LLMs 在进行计算时可能出现错误，导致最终答案不正确。</li>
<li>步骤缺失错误: LLMs 可能会遗漏解决问题的某个步骤，导致推理过程不完整。<br>
现有的研究主要集中在解决计算错误和步骤缺失错误，而<strong>对语义误解错误关注较少</strong>。然而，语义误解错误是限制 LLMs 推理能力的主要因素。<br>
因此，文章提出了一种名为 Deeply Understanding the Problems (DUP) 的方法，旨在通过解决语义误解错误来提升 LLMs 的数学问题解决能力。</li>
</ul>
<h2 id="方法">方法</h2>
<p>DUP（Deeply Understanding the Problems）方法是一种针对大型语言模型（LLMs）的提示策略，旨在提高它们解决数学文字题的能力。以下是DUP方法的详细步骤和特点：</p>
<ol>
<li>
<p>揭示核心问题（Reveal the Core Question）<br>
这是DUP方法的第一阶段，目的是从复杂和冗长的问题描述中明确问题的核心。通过设计一个提示，要求LLM明确提取问题的核心部分，从而帮助模型集中注意力于问题的目标。</p>
</li>
<li>
<p>提取解题信息（Extract the Problem-solving Information）<br>
第二阶段进一步从问题描述中提取对解决核心问题至关重要的信息。这一步骤通过一个提示来实现，该提示要求LLM列出与核心问题直接相关的最有用的信息。</p>
</li>
<li>
<p>生成并提取答案（Generate and Extract the Answer）<br>
在前两个阶段的基础上，第三阶段将核心问题和解题信息结合起来，生成详细的回答，并从中提取最终答案。这一步骤通过一个模板提示来实现，该模板明确指出了目标和解决问题所需的必要信息。</p>
</li>
</ol>
<h2 id="实验">实验</h2>
<ul>
<li>数据集:
<ul>
<li>算术推理数据集: GSM8K、SVAMP、MultiArith、AddSub、AQuA、SingleEq</li>
<li>常识推理数据集: CommonsenseQA、StrategyQA</li>
<li>符号推理数据集: Last Letter、Coin Flip</li>
</ul>
</li>
<li>基线方法：
<ul>
<li>零样本方法: Zero-shot CoT、Least-to-Most、Zero-shot PS+</li>
<li>少样本方法: Manual-CoT、Auto-CoT</li>
</ul>
</li>
<li>实验设置:
<ul>
<li>LLMs: GPT-3.5-Turbo 和 GPT-4</li>
<li>解码策略: 具有自一致性（SC）的解码策略（Wang et al., 2023b）</li>
</ul>
</li>
<li>实验结果:
<ul>
<li>DUP 方法在所有推理数据集上均取得了显著优于其他方法的性能。</li>
<li>DUP 方法的零样本性能甚至超过了少样本方法的性能。</li>
<li>DUP 方法在 GSM8K 和 SVAMP 数据集上取得了新的 SOTA 结果。</li>
</ul>
</li>
<li>消融实验:
<ul>
<li>探究 DUP 方法中各个阶段的重要性。</li>
<li>探究如何在不降低性能的情况下降低 DUP 方法的推理成本。（将三阶段提示合并为一个提示）</li>
</ul>
</li>
<li>讨论和分析:
<ul>
<li>分析 DUP 方法与 SC 解码的兼容性。</li>
<li>验证 DUP 方法是否可以应用于开源 LLMs。</li>
<li>分析更准确的核心问题和问题解决信息如何提升推理性能。</li>
<li>进行错误分析，验证 DUP 方法是否有效减少了语义误解错误。</li>
</ul>
</li>
</ul>
 <!-- <img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/20/LLM-Learning4/p1.png" class="" title="p1"> -->
<h1 id="re-reading-improves-reasoning-in-large-language-models">Re-Reading Improves Reasoning in Large Language Models</h1>
<p>重读能提升大模型推理能力</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/20/LLM-Learning4/p3.png" style="zoom:45%;">
<h2 id="研究背景">研究背景</h2>
<p>本文旨在介绍一种简单有效的提示方法“重复阅读(RE2)”以提升大型语言模型(LLMs)的推理能力。这一方法受到人类在学习和解决问题时倾向于<strong>重复阅读问题以提高理解</strong>的观察启发。</p>
<h2 id="研究目标和假设">研究目标和假设</h2>
<p>本文旨在探讨重复阅读问题是否能提升LLMs的推理性能。关键假设是，重复阅读问题可以帮助LLMs更深入地理解输入，从而提高推理能力。</p>
<h2 id="研究方法">研究方法</h2>
<p>本文介绍了“RE2”<strong>提示</strong>方法，即在提示中重复两次输入问题。这可以作为一个“即插即用”模块，与各种诱导思考的提示策略（如思维链和程序辅助语言）集成使用。</p>
<h2 id="结果和发现">结果和发现</h2>
<p>论文评估了RE2在各种推理基准测试(包括算术、常识和符号推理任务)上的有效性。<br>
研究结果显示，RE2 能够持续提升LLMs的推理性能，包括ChatGPT等指令微调(IFT)模型和 LLaMA-2 等非IFT模型。RE2与各种诱导思考的提示方法兼容,也可以有效地与少样本提示和自一致性方法相结合。</p>
<h2 id="思考">思考</h2>
<p>很简单的方法，可以学习其写作技巧。</p>
]]></content>
      <categories>
        <category>大模型</category>
        <category>论文阅读</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>网络协议安全基础</title>
    <url>/2022/09/01/NetProtoSec-LearningNotes1/</url>
    <content><![CDATA[<blockquote>
<p>知识背景：</p>
<ul>
<li>计算机网络</li>
<li>部分密码学知识<a href="https://www.bilibili.com/video/BV1vq4y1R7Yt?is_story_h5=false&amp;p=1&amp;share_from=ugc&amp;share_medium=android&amp;share_plat=android&amp;share_session_id=9e54e092-697a-4e52-b1db-99433ded35b8&amp;share_source=WEIXIN&amp;share_tag=s_i&amp;timestamp=1660828486&amp;unique_k=5oAWIQa">密码学教程（P5-P12）</a></li>
</ul>
</blockquote>
<h1 id="网络协议结构">网络协议结构</h1>
<h2 id="tcp-ip协议">TCP/IP协议</h2>
<h3 id="局域网lan与广域网wan">局域网LAN与广域网WAN</h3>
<h4 id="lan">LAN</h4>
<ul>
<li>特点：距离小、延迟小</li>
<li>构建LAN设备：线缆、网卡、集线器（已不用）、交换机、路由器</li>
</ul>
<blockquote>
<p>举例：校园网</p>
</blockquote>
<h4 id="wan">WAN</h4>
<ul>
<li>定义：在大范围区域内提供数据通信服务，主要用于互联局域网</li>
<li>结构：<strong>末端系统</strong>+<strong>通信系统（中间链路）</strong>
<ul>
<li><strong>通信系统</strong>工作在<strong>物理层＋数据链路层</strong></li>
</ul>
</li>
<li>交换模式：
<ul>
<li><strong>电路交换</strong>：带宽固定</li>
<li><strong>分组交换</strong>：多路复用</li>
</ul>
</li>
</ul>
<h3 id="osi参考模型">OSI参考模型</h3>
<h4 id="七层功能">七层功能</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p1.png" class title="p1">
<h4 id="数据通信">数据通信</h4>
<p>数据通信两个原则：</p>
<ul>
<li><strong>对等通信</strong>：每一层使用自己的协议</li>
<li><strong>数据封装</strong>：封装指网络节点（node）将要传送的<strong>数据用特定的协议头打包</strong></li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p2.png" class title="p2">
<blockquote>
<p>提问：为何这里的路由器只画了三层？<br>
回答：从端到端通信的角度，路由器不需要工作在4、5层。但是我们需要知道，路由器也有高层协议（RIP/OSFP协议）。</p>
</blockquote>
<h3 id="tcp-ip协议栈">TCP/IP协议栈</h3>
<h4 id="与osi对应关系">与OSI对应关系</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p3.png" class title="p3">
<h4 id="tcp-ip的封装">TCP/IP的封装</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p4.png" class title="p4">
<h4 id="各层功能">各层功能</h4>
<ul>
<li>应用层</li>
<li>传输层：提供端到端（端口号区分）连接、流量控制（窗口机制）、可靠性（序列号和确认技术实现）
<ul>
<li>TCP：可靠，面向连接
<ul>
<li>三次握手+四次挥手</li>
</ul>
</li>
<li>UDP：无连接通信，可靠性由上层负责</li>
</ul>
</li>
<li>网络层：寻址和路由选择
<ul>
<li>IP协议：IP协议和路由协议协同工作寻找最优路径。不关心报文内容，提供无连接的、不可靠的服务。</li>
<li>ARP协议：IP协议 -&gt; MAC地址</li>
<li>ICMP协议：定义了网络层控制和传递消息的功能</li>
<li>RARP、IGMP</li>
</ul>
</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p5.png" class title="p5">
<h4 id="思考：手机lte与电脑wifi通信？">思考：手机LTE与电脑WiFi通信？</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p6.png" class title="p6">
<ul>
<li>手机 -&gt; 网关：通过承载网（下面的IP是在承载网上寻址）</li>
<li>手机网络相当于是一个大二层网络，能够全球通信</li>
</ul>
<h2 id="tcp-ip协议族的安全性">TCP/IP协议族的安全性</h2>
<h3 id="因特网存在的问题">因特网存在的问题</h3>
<ul>
<li>资源共享与分组交换
<ul>
<li>IP地址的可见性</li>
<li>分组交换的方式导致：攻击数据包在被判断恶意前都会被转发到受害者（查找吓下一跳时不会判断是否恶意，容易被DoS攻击）</li>
</ul>
</li>
<li>认证与可追踪性
<ul>
<li>Internet没有认证机制 —&gt; IP欺骗（路由表项只根据目的IP，不会看源IP）</li>
<li>路由器无数据追踪功能</li>
</ul>
</li>
<li>尽力而为 -&gt; DoS攻击</li>
<li>匿名与隐私：IP -&gt; 地址，身份 -&gt; ?</li>
<li>全球网络基础设置不提供可靠性、安全性保证</li>
</ul>
<h3 id="设计新的协议栈">设计新的协议栈</h3>
<ul>
<li>不能暴露IP</li>
<li>路由决策</li>
<li>认证</li>
<li>路由器可溯源（路由历史记录）</li>
<li>QoS/流量控制</li>
<li>身份标识</li>
</ul>
<h1 id="网络协议安全威胁分类">网络协议安全威胁分类</h1>
<h2 id="网络漏洞分类">网络漏洞分类</h2>
<ul>
<li>基于<strong>头部</strong>
<ul>
<li>头部某个域使用了无效值</li>
<li>TCP的FLAG误用攻击</li>
</ul>
</li>
<li>基于<strong>协议</strong>
<ul>
<li>不按顺序发送数据包</li>
<li>发送太快/太慢：DoS攻击</li>
<li>没发送数据包：SYN雪崩式攻击</li>
</ul>
</li>
<li>基于<strong>验证</strong>
<ul>
<li>非法访问接入点</li>
<li>IPv4地址欺骗</li>
<li>DNS欺骗</li>
</ul>
</li>
<li>基于<strong>流量</strong>
<ul>
<li>雪崩流量：ping一个广播地址</li>
<li>数据包<strong>嗅探</strong>:DoS攻击</li>
</ul>
</li>
</ul>
<h2 id="网络层次分类">网络层次分类</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/01/NetProtoSec-LearningNotes1/p7.png" class title="p7">]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>网络协议安全</category>
      </categories>
      <tags>
        <tag>网络协议</tag>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>主机和端口扫描</title>
    <url>/2022/09/07/NetProtoSec-LearningNotes2/</url>
    <content><![CDATA[<blockquote>
<p>实验环境：Kali+Wireshark+Nmap</p>
<ul>
<li>Kali：是一个基于Debian的Linux发行版，预装了许多渗透测试软件，是一个很酷的“黑客操作系统”；</li>
<li>Wireshark：是一个网络封包分析软件，功能是截取网络封包，并尽可能显示出最为详细的网络封包资料。Wireshark使用WinPCAP作为接口，直接与网卡进行数据报文交换；</li>
<li>Nmap：即Network Mapper，是Linux下的网络扫描和嗅探工具包。</li>
</ul>
</blockquote>
<h1 id="实验内容">实验内容</h1>
<p>1.在Nmap中，使用nmap –sP xx指令实现主机扫描，用wireshark抓取扫描过程中的ARP请求和响应报文；通过ping指令发起ICMP扫描，用wireshark抓取扫描过程中的ICMP报文；</p>
<p>2.在Nmap中，使用nmap –sS xx指令实现端口扫描，用wireshark抓取扫描过程中的TCP报文。</p>
<h1 id="kali网络配置">kali网络配置</h1>
<p>由于我使用的是校园网，因此我这里使用NAT模式。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p1.png" class title="p1"> 
<h2 id="1-查看主机地址">1.查看主机地址</h2>
<p>首先通过<code>win</code>+<code>R</code>输入cmd打开终端，然后通过<code>ipconfig</code>查看自己主机的ip地址，网关，网段（我这里选择VMnet8）。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p2.png" class title="p2"> 
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IPv4 地址: 192.168.253.1</span><br><span class="line">子网掩码: 255.255.255.0</span><br></pre></td></tr></table></figure>
<h2 id="2-修改-etc-network-interfaces文件">2.修改/etc/network/interfaces文件</h2>
<p>然后，通过<code>vim /etc/network/interfaces</code>，设置静态IP：<br>
address：把ip地址设置为自己主机网段中的一个，如：我的主机ip是192.168.253.1，这里设为192.168.253.36<br>
gateway：在其中加上自己主机的网关，如：192.168.253.2<br>
netmask：子网掩码照抄自己主机的，如：255.255.255.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto eth0</span><br><span class="line">iface eth0 inet static</span><br><span class="line">address 192.168.253.36</span><br><span class="line">netmask 255.255.255.0</span><br><span class="line">gateway 192.168.253.2</span><br></pre></td></tr></table></figure>
<h2 id="3-修改dns">3.修改dns</h2>
<p><code>vim /etc/resolv.conf</code>添加几个常用DNS：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">domain localdomain</span><br><span class="line">search localdomain</span><br><span class="line">nameserver 8.8.8.8</span><br><span class="line">nameserver 114.114.114.114</span><br><span class="line">nameserver 192.168.253.2</span><br></pre></td></tr></table></figure>
<h2 id="4-重启网络">4.重启网络</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart networking</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;init.d&#x2F;networking restart</span><br></pre></td></tr></table></figure>
<h2 id="5-测试">5.测试</h2>
<p>输入<code>ifconfig -a</code>查看ip：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p3.png" class title="p3"> 
<h2 id="nmap参数速查">nmap参数速查</h2>
<table>
<thead>
<tr>
<th style="text-align:center">命令</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">nmap IP</td>
<td style="text-align:center">扫描IP</td>
</tr>
<tr>
<td style="text-align:center">nmap -v IP</td>
<td style="text-align:center">加强扫描</td>
</tr>
<tr>
<td style="text-align:center">nmap IP1 IP2 …</td>
<td style="text-align:center">扫描多IP</td>
</tr>
<tr>
<td style="text-align:center">nmap a.b.c.*</td>
<td style="text-align:center">扫描整个子网</td>
</tr>
<tr>
<td style="text-align:center">nmap a.b.c.x,y,…</td>
<td style="text-align:center">扫描多子网地址</td>
</tr>
<tr>
<td style="text-align:center">nmap -iL xxx.txt</td>
<td style="text-align:center">根据文件扫描多IP</td>
</tr>
<tr>
<td style="text-align:center">nmap a.b.c.x-y</td>
<td style="text-align:center">扫描子网IP范围</td>
</tr>
<tr>
<td style="text-align:center">nmap a.b.c.* --exclude IP</td>
<td style="text-align:center">排除指定IP扫描整个子网</td>
</tr>
<tr>
<td style="text-align:center">nmap -A IP</td>
<td style="text-align:center">全面的系统扫描,包括操作系统探测、版本探测、脚本扫描、路径跟踪</td>
</tr>
<tr>
<td style="text-align:center">nmap -O IP</td>
<td style="text-align:center">探测操作系统</td>
</tr>
<tr>
<td style="text-align:center">nmap -sA/-PN IP</td>
<td style="text-align:center">探测防火墙</td>
</tr>
<tr>
<td style="text-align:center">nmap -sP a.b.c.*</td>
<td style="text-align:center">探测在线主机</td>
</tr>
<tr>
<td style="text-align:center">nmap -F IP</td>
<td style="text-align:center">快速扫描</td>
</tr>
<tr>
<td style="text-align:center">nmap -r IP</td>
<td style="text-align:center">按顺序扫描</td>
</tr>
<tr>
<td style="text-align:center">nmap -iflist</td>
<td style="text-align:center">显示接口和路由信息</td>
</tr>
<tr>
<td style="text-align:center">nmap -p n1,n2… IP</td>
<td style="text-align:center">扫描指定端口</td>
</tr>
<tr>
<td style="text-align:center">nmap -p T:n1,n2… IP</td>
<td style="text-align:center">扫描TCP端口</td>
</tr>
<tr>
<td style="text-align:center">nmap -sU n1,n2… IP</td>
<td style="text-align:center">扫描UDP端口</td>
</tr>
<tr>
<td style="text-align:center">nmap -sV IP</td>
<td style="text-align:center">查看服务的版本</td>
</tr>
<tr>
<td style="text-align:center">nmap -PS IP</td>
<td style="text-align:center">TCP ACK扫描</td>
</tr>
<tr>
<td style="text-align:center">nmap -PA IP</td>
<td style="text-align:center">TCP SYN扫描</td>
</tr>
<tr>
<td style="text-align:center">nmap -sS IP</td>
<td style="text-align:center">隐蔽扫描</td>
</tr>
<tr>
<td style="text-align:center">nmap -sN IP</td>
<td style="text-align:center">TCP空扫描欺骗防火墙</td>
</tr>
</tbody>
</table>
<h1 id="主机扫描">主机扫描</h1>
<blockquote>
<p>开两个虚拟机：192.168.253.36 + 192.168.253.37</p>
</blockquote>
<h2 id="主机扫描参数">主机扫描参数</h2>
<p>主机发现有时候也叫做ping扫描，有以下选项：<br>
<code>-sL</code>（列表扫描）：它仅仅列出指定网络上的每台主机，不发送任何报文到目标主机；<br>
<code>-sP</code>（Ping扫描）：该选项告诉Nmap仅仅进行ping扫描（主机发现），然后打印出对扫描做出响应的那些主机；Nmap会发一个ICMP ECHO请求和一个TCP报文到目标端口；<br>
<code>-Pn</code>（无ping）：无Ping扫描通常用于防火墙禁止Ping的情况下，完全跳过Nmap发现阶段，且对目标主机进行端口扫描；<br>
<code>-PS</code>（TCP SYN ping）：该选项发送了一个设置了SYN标志位的空TCP报文，需要root权限；<br>
<code>-PA</code>（TCP ACK ping）：它与TCP SYN Ping扫描类似，不同的只是设置的TCP报文的标志位是ACK；<br>
<code>-PU</code>（UDP  ping）：发送一个空的UDP报文到指定端口，很少用；<br>
<code>-PE/PP/PM</code>（ICMP ECHO/时间戳/地址掩码Ping）；<br>
<code>-ARP</code>（ARP ping）：该选项通常在扫描局域网时使用，在内网中使用ARP Ping是非常有效的。</p>
<h2 id="实验过程">实验过程</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nmap -P 192.168.253.1/24</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p4.png" class title="p4"> 
<p>wireshark抓取ARP请求和响应报文：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p5.png" class title="p5">
<p>ping命令发起ICMP扫描，wireshark抓取ICMP报文：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p6.png" class title="p6">
<h1 id="端口扫描">端口扫描</h1>
<h2 id="端口扫描基础">端口扫描基础</h2>
<h3 id="端口状态">端口状态</h3>
<p>Nmap所识别的6个端口状态：</p>
<ul>
<li><code>Opend</code>：端口开启；</li>
<li><code>Closed</code>： 端口关闭；</li>
<li><code>Filtered</code>：端口被过滤，数据没有到达主机，返回的结果为空，数据被防火墙拦截了；</li>
<li><code>Unfiltered</code>：未被过滤，数据有到达主机，但是不能识别端口的当前状态；</li>
<li><code>Open|filtered</code>：开放或者被过滤，端口没有返回值，主要发生在UDP、IP、FIN、NULL和X mas扫描中；</li>
<li><code>Closed|filtered</code>：关闭或者被过滤，只发生在IP ID idle扫描。</li>
</ul>
<h3 id="命令参数">命令参数</h3>
<p>-<code>sS</code>（TCP SYN扫描）：半开扫描，很少有系统能把它记入系统日志。不过，需要Root权限；<br>
-<code>sT</code>（TCP connect()扫描）:当SYN扫描不能用时，CP Connect()扫描就是默认的TCP扫描；<br>
-<code>sN/-sF/-sX</code>（TCP Null/FIN/Xmas扫描）:能躲过一些无状态防火墙和报文过滤路由器；<br>
-<code>p</code>：指定范围性扫描端口；<br>
-<code>v</code>：详细信息。</p>
<h2 id="实验过程">实验过程</h2>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">┌──(root㉿kali)-[~]</span><br><span class="line">└─<span class="comment"># nmap -sS 192.168.253.1</span></span><br><span class="line">Starting Nmap 7.92 ( https://nmap.org ) at 2022-09-07 22:42 EDT</span><br><span class="line">Nmap scan report <span class="keyword">for</span> 192.168.253.1</span><br><span class="line">Host is up (0.00019s latency).</span><br><span class="line">Not shown: 996 filtered tcp ports (no-response)</span><br><span class="line">PORT     STATE SERVICE</span><br><span class="line">135/tcp  open  msrpc</span><br><span class="line">139/tcp  open  netbios-ssn</span><br><span class="line">445/tcp  open  microsoft-ds</span><br><span class="line">4001/tcp open  newoak</span><br><span class="line">MAC Address: 00:50:56:C0:00:08 (VMware)</span><br><span class="line"></span><br><span class="line">Nmap <span class="keyword">done</span>: 1 IP address (1 host up) scanned <span class="keyword">in</span> 4.70 seconds</span><br></pre></td></tr></table></figure>
<p>打开wireshark抓取tcp包，可看到：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/07/NetProtoSec-LearningNotes2/p7.png" class title="p7">
<p>扫描主机的135和139端口已经回发数据了。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>网络协议安全</category>
      </categories>
      <tags>
        <tag>网络安全</tag>
        <tag>Wireshark</tag>
        <tag>Nmap</tag>
      </tags>
  </entry>
  <entry>
    <title>链路层协议安全</title>
    <url>/2022/09/18/NetProtoSec-LearningNotes3/</url>
    <content><![CDATA[<blockquote>
<p>本节分为三个部分：</p>
<ul>
<li>有线网络协议安全</li>
<li>无线网络协议安全</li>
<li>VLAN安全</li>
</ul>
</blockquote>
<h1 id="链路层协议安全">链路层协议安全</h1>
<h2 id="有线网络协议安全">有线网络协议安全</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p1.png" class title="p1">
<h2 id="无线网络协议安全">无线网络协议安全</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p2.png" class title="p2">
<h2 id="vlan安全">VLAN安全</h2>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p3.png" class title="p3">
<h3 id="特点">特点</h3>
<p>VLAN与传统LAN相比，具有以下特点：</p>
<ul>
<li>隔离广播域</li>
<li>创建虚拟工作组，超越传统网络的工作方式，减少改变的代价，安全性⬆，健壮性⬆</li>
</ul>
<p>VLAN的划分方法有以下几种：</p>
<ul>
<li>基于端口（静态）</li>
<li>基于MAC（动态）</li>
<li>基于协议</li>
<li>基于子网</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p4.png" class title="p4">
<h3 id="三层交换机">三层交换机</h3>
<p>不同VLAN的信息必须通过三层路由处理才能转发到端口上。</p>
<h4 id="二层交换机与路由器">二层交换机与路由器</h4>
<p>二层交换机：数据交换靠硬件，但不能处理不同子网(包括VLAN)间数据交换；<br>
路由器：主要功能是路由转发，通过软件实现，所以转发效率低。</p>
<h4 id="三层交换技术">三层交换技术</h4>
<p>三层交换技术其实就是：二层交换技术+三层转发技术。它能做到<strong>一次路由，多次转发</strong>，对于数据包转发等规律性的过程由硬件高速实现，而像路由信息更新、路由表维护、路由计算等功能，由软件实现。</p>
<h4 id="工作过程">工作过程</h4>
<p>1.第一个包过来（包目的MAC是自己，交给IP层，发现IP地址不是自己），硬件转发表无表项，交给路由进程处理，查找下一跳IP，通过ARP得到MAC；<br>
2.转发时：修改IP包ttl；修改原mac；建立硬件转发表；<br>
3.下一包，直接查看硬件转发表直接转发，而不会经过路由表查询。</p>
<h3 id="链路类型">链路类型</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p5.png" class title="p5">
<p>1.干道链路<br>
可以承载多个不同VLAN数据，用于交换机间、交换机与路由器间的互连，<strong>它不属于任何一个具体VLAN</strong>。所有在干道链路上传输的帧都是打上标记的帧。</p>
<p>2.接入链路<br>
用于连接主机和交换机的链路，接入链路属于某一个特定的端口，这个端口属于一个并且只能是一个VLAN。</p>
<h3 id="帧在网络通信中的变化">帧在网络通信中的变化</h3>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p6.png" class title="p6">
<h3 id="本征vlan">本征VLAN</h3>
<p>相当于默认VLAN，可以在Trunk链路上指定一个Native VLAN。Access端口只属于一个VLAN，所以它的缺省ID就是它所在的VLAN，不用设置；Trunk端口属于多个VLAN， 所以需要设置缺省VLAN ID，缺省情况下为VLAN 1。<br>
来自Native VLAN的数据帧通过Trunk链路时不重新封装，以原有的帧传输（不重新打标签）。</p>
<h3 id="转发原则-由交换机实现">转发原则(由交换机实现)</h3>
<h4 id="access-link">Access-Link</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p7.png" class title="p7">
<h4 id="trunk-link">Trunk-Link</h4>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p8.png" class title="p8">
<h3 id="vlan安全威胁">VLAN安全威胁</h3>
<h4 id="双标签跳跃攻击">双标签跳跃攻击</h4>
<p>原理：构造含有双层标签的帧，其外层标记为Trunk链路的 Native VLAN 号，交换机trunk端口发送帧时，将外层标签去掉<br>
缺点：只能单项攻击<br>
防范：native VLAN设置为一个不存在的VLAN</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p9.png" class title="p9">
<h4 id="dtp跳跃攻击">DTP跳跃攻击</h4>
<p>DTP：有设备主动向接口发起协议，接口将形成Trunk，该链路可以双向传输任何VLAN数据<br>
特点：可双向访问，绕过防火墙</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/18/NetProtoSec-LearningNotes3/p10.png" class title="p10">
<h4 id="vpt攻击">VPT攻击</h4>
<p>原理：VLAN信息的同步是通过VTP通告来实现的， VTP通告只能在Trunk链路上传输（因此交换机之间的Trunk链路必须成功配置了Trunk）<br>
思路：攻击者发送高的Revision的VTP通告，就能把网络中的VLAN信息覆盖了。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>网络协议安全</category>
      </categories>
      <tags>
        <tag>网络协议</tag>
        <tag>网络安全</tag>
      </tags>
  </entry>
  <entry>
    <title>网络与系统安全随记</title>
    <url>/2022/09/09/NetSysSec-LearningNotes/</url>
    <content><![CDATA[<h1 id="20220909">20220909</h1>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/09/NetSysSec-LearningNotes/p1.png" class title="p1"> 
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>网络与系统安全</category>
      </categories>
      <tags>
        <tag>网络与系统安全</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统的“公理化”</title>
    <url>/2022/08/30/OS-LearningNotes1/</url>
    <content><![CDATA[<blockquote>
<ul>
<li>源码阅读工具：Source Insight</li>
<li>关键字:
<ul>
<li>内核Kernel</li>
<li>特权级</li>
<li>授权</li>
</ul>
</li>
<li>主要内容：本节课主要探讨了Linux内核，老师从逻辑推理的角度带大家体会什么是内核，为什么需要内核。</li>
</ul>
</blockquote>
<h1 id="授权">授权</h1>
<h2 id="观点：未经授权-不得访问其他用户的资源">观点：未经授权，不得访问其他用户的资源</h2>
<blockquote>
<p>访问自己的资源，总是授权的。</p>
</blockquote>
<h2 id="探讨">探讨</h2>
<h3 id="问题：未经许可-用户是否能访问外设-io-中自己的资源？">问题：未经许可，用户是否能访问外设（IO）中自己的资源？</h3>
<ul>
<li>答案：不可以。</li>
<li>原因：IO物理端口只有一个，而用户程序具有不确定性（可能会做一些坏事），如果开放端口，可能会无法控制。</li>
<li>解决办法：若用户非要访问（IO指令/MMIO），则用特权级拦住。
<ul>
<li>特权级：CPU剥夺了应用程序访问外设的能力。</li>
</ul>
</li>
</ul>
<h3 id="问题：而自己的资源-应该要能访问的-那怎么办？">问题：而自己的资源，应该要能访问的，那怎么办？</h3>
<ul>
<li>因为：用户进程是不确定的，并且它应该是不确定的，没有理由要求它确定。</li>
<li>由<strong>一组确定的程序</strong>来访问自己的资源————即<strong>内核</strong>。</li>
</ul>
<h1 id="特权级">特权级</h1>
<h2 id="特权级的概念">特权级的概念</h2>
<p>在linux系统中特权级别分为0，1，2，3一共四个级别，0最大 ，3最小。</p>
<ul>
<li>一般内核代码运行在0特权级；</li>
<li>驱动、虚拟机等运行在1，2特权级；</li>
<li>而我们自己写的程序一般运行在3特权级，也就是最低级别。</li>
</ul>
<h2 id="探讨">探讨</h2>
<h3 id="用户程序指令-3特权-为什么不能访问0特权的数据？">用户程序指令（3特权）为什么不能访问0特权的数据？</h3>
<p>答：因为用户程序指令具有不确定性。</p>
<h3 id="0特权能否直接跳到3特权？">0特权能否直接跳到3特权？</h3>
<p>答：不允许，若此时0特权跳转过去后仍保持全态，那么应用程序就会直接变为kernel。</p>
<h1 id="接续访问机制">接续访问机制</h1>
<p><strong>接续访问机制</strong>：用户发起 -&gt; 内核接续（IO行为） -&gt; 交付用户</p>
<h2 id="观点：内核的工作-是用户进程访问行为的延续">观点：内核的工作，是用户进程访问行为的延续</h2>
<h2 id="观点：内核需要结构化-提供一组自洽的-一致的syscall">观点：内核需要结构化，提供一组自洽的、一致的syscall</h2>
<h2 id="提问：既然未经授权-不得访问其他用户的资源-那所谓授权-又是给谁的？">提问：既然未经授权，不得访问其他用户的资源。那所谓授权，又是给谁的？</h2>
<p>思考：</p>
<ul>
<li>给用户？同一个用户，有可能可以读A文件，而B文件不行；</li>
<li>给资源？同一份资源，有可能用户1可以读，而用户2不行。</li>
</ul>
<p>答：给&quot;访问&quot;：一般是三元组（用户，操作，资源）。即<strong>一次授权对应一次访问</strong></p>
<h2 id="提问：从用户发起到内核接续-也即不确定行为到确定行为-如何实现？">提问：从用户发起到内核接续，也即不确定行为到确定行为，如何实现？</h2>
<p>答：1. 反转状态；2. 要求转移指令确定的落点：（1）限制用户进程的跳转指令；（2）限制用户进程的跳转落点.</p>
<blockquote>
<p>补充：以RISC-V为例，（1）只能是ecall指令；（2）只能是mtvec，中断向量基址，该值由OS内核指定。</p>
</blockquote>
<h2 id="观点：接续访问机制的重要保障：用户态和内核态之间有面-墙">观点：接续访问机制的重要保障：用户态和内核态之间有面&quot;墙&quot;</h2>
<p>墙是由某些硬件机制创建的。</p>
<blockquote>
<p>以RISCV为例：CSR寄存器组和CSR指令（CSR：Control and Status Registers）。</p>
</blockquote>
<h2 id="提问：既然内核可以用某些硬件机制建墙-那用户岂不是也可以用它来拆墙？">提问：既然内核可以用某些硬件机制建墙，那用户岂不是也可以用它来拆墙？</h2>
<h3 id="通俗版解答">通俗版解答</h3>
<ul>
<li>机器上电，操作系统先来，先建好墙，完事了把拆墙工具收到墙内。</li>
<li>用户想要拆墙，就要先进到墙内；</li>
<li>想要进到墙内，就要先拆墙。</li>
</ul>
<blockquote>
<p>以RISCV为例：<br>
想要从U模式变到M模式，就必须使用CSR指令修改CSR寄存器组；<br>
想要使用CSR指令修改CSR寄存器组，就必须已经处于M模式，否则机器报异常。</p>
</blockquote>
<h3 id="学术版解答">学术版解答</h3>
<ul>
<li>用时间的不可逆性来建构空间的各项异性；</li>
<li>互为必要条件。</li>
</ul>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>操作系统高级教程</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux Kernel</tag>
        <tag>特权级</tag>
        <tag>授权</tag>
      </tags>
  </entry>
  <entry>
    <title>从开机加电到执行main函数之前的过程</title>
    <url>/2022/09/06/OS-LearningNotes2/</url>
    <content><![CDATA[<blockquote>
<p>参考用书：《Linux内核设计的艺术》</p>
<p>题外话：由于疫情，国科大现在实行线下上网课的形式。本节课就是大家全部到教室，然后老师共享屏幕来教学的，虽然互动减少了，但是还是干货满满。本周主要的笔记是记在电子版书上，下周可能会考虑整个思维导图，或许思路会更清晰。总之，开学前两周，先摸索一下学习方式。</p>
</blockquote>
<h1 id="引言">引言</h1>
<p>从开机加电到执行main函数之前，主要分为以下三个部分：</p>
<ol>
<li>启动BIOS，准备实模式下的中断向量表和中断服务程序</li>
<li>从启动盘加载操作系统程序到内存：
<ul>
<li>bootsect程序（扇区 -&gt; 主机内存）</li>
<li>setup程序（设置内核运行所需的机器系统数据）</li>
<li>head程序（保护模式，内存分页）</li>
</ul>
</li>
<li>为执行32位的main函数做过渡</li>
</ol>
<p>整体思维导图：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/xmind.png" class title="xmind">
<h1 id="启动bios">启动BIOS</h1>
<ol>
<li>CPU的硬件都设置为加电进入实模式</li>
<li>BIOS程序被固化在ROM中，由<strong>硬件方式</strong>执行：加电瞬间，CS:IP指向BIOS程序的入口地址（0xFFFF0）</li>
<li>BIOS检测显卡、内存······，并且<strong>在内存中建立中断向量表和中断服务程序</strong></li>
</ol>
<blockquote>
<p>补充知识：</p>
<ul>
<li>ROM：只读存储器，断电之后仍能保存信息</li>
<li>0x00400 = 4*(16^2)字节 = 4*256字节 = 1024字节 = 1KB</li>
</ul>
</blockquote>
<h1 id="加载操作系统内核程序">加载操作系统内核程序</h1>
<h2 id="加载第一部分内核代码-引导程序bootsect">加载第一部分内核代码——引导程序bootsect</h2>
<p><strong>理解</strong>： bootsect中sect是section的缩写，代表软盘。整个bootsect程序就是<strong>将内核程序从软盘加载到主机内存</strong>的过程。<br>
<strong>过程</strong>：</p>
<ol>
<li>CPU接收到一个int 0x19中断</li>
<li>对应中断服务程序把软盘中第一扇区的程序（512B）加载到内存的指定位置（0x07C00）</li>
</ol>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/p1.png" class title="p1">
<blockquote>
<p>冷知识：0x07C00来自Intel第一台个人电脑8088芯片，为了保持兼容，以后的CPU都保留此地址</p>
</blockquote>
<h2 id="加载第二部分内核代码-setup">加载第二部分内核代码——setup</h2>
<p>BIOS将引导程序bootsect载入内存后，现在需要将第二批、第三批程序陆续加载到内存中。</p>
<p><strong>1.bootsect对内存的规划</strong><br>
为了实现上述操作，bootsect首要工作就是先规划内存。如图，bootsect程序对后续操作涉及的内存位置进行了设置：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/p2.png" class title="p2">
<p><strong>2.复制bootsect</strong><br>
接下来，bootsect将自身复制至内存0x90000（INITSEG）处：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/p3.png" class title="p3">
<p><strong>过程</strong>：一遍执行，一边复制<br>
<strong>目的</strong>：复制完后，就能根据自己的需要规划内存，程序可以执行更复杂的数据运算类指令了</p>
<p><strong>3.将setup程序加载到内存中</strong><br>
通过BIOS提供的int 0x13中断向量指向的中断服务程序，将软盘第二扇区开始的4个扇区（即setup.s对应程序）加载到内存中（SETUPSEG）。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/p4.png" class title="p4">
<p>此时，操作系统已经从软盘中加载了5个扇区的代码。bootsect程序执行完后，setup程序就要开始工作了。</p>
<h2 id="加载第三部分内核代码-system模块">加载第三部分内核代码——system模块</h2>
<p><strong>1.bootsect载入系统模块</strong><br>
接下来，bootsect程序进行第三批程序的载入工作。首先，bootsect借助BIOS中断int 0x13，将240个扇区的system<strong>系统模块加载进内存</strong>。至此，整个操作系统的代码已全部加载至内存。bootsect还需要再确认一下根设备号，然后其工作就结束了！</p>
<blockquote>
<p>补充：Linux0.11要求系统必须存在一个根文件系统，这里的文件系统☞配套文件系统格式的设备，如一张格式化好的软盘</p>
</blockquote>
<p><strong>2.setup程序提取机器系统数据</strong><br>
setup程序现在开始执行。首先，它利用BIOS中断服务程序从设备上提取内核所需要运行的机器系统数据（光标位置、显示页面等），并加载在内存中。<br>
<strong>注意</strong>：BIOS提取的机器系统数据将覆盖bootsect程序所在部分区域，这提高了内存的利用率。<br>
到此为止，内核已全部加载完成。接下来，系统将通过已加载到内存的代码，实现<strong>从实模式到保护模式的转变</strong>，使得Linux真正成为“现代”操作系统！</p>
<h1 id="向32位模式转变">向32位模式转变</h1>
<p>本节，操作系统执行的操作包括打开32位的寻址空间、打开保护模式、建立保护模式下的中断响应机制等与保护模式相关的工作、建立内存分页机制，最后最好调用main函数的准备。</p>
<h2 id="关闭中断-移动system">关闭中断，移动system</h2>
<p>首先<strong>关闭中断</strong>，即将CPU的标志寄存器（EFLAGS）的中断允许标志（IF）置0。</p>
<blockquote>
<p>补充：</p>
<ul>
<li>EFLAGS相当于总开关</li>
<li>这里的关闭中断并不意味着没有中断了，其实是仍会存在中断，只是不再响应处理而已</li>
</ul>
</blockquote>
<p>接下来，setup程序<strong>将位于0x10000的内核程序复制至内存起始地址0x00000处</strong>，将BIOS中断向量表和BIOS数据区完全覆盖。</p>
<h2 id="设置中断描述符表和全集描述符表">设置中断描述符表和全集描述符表</h2>
<p>setup程序<strong>对中断描述符表寄存器（IDTR）和全局描述符表寄存器（GDTR）进行初始化设置</strong>。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/p5.png" class title="p5">
<blockquote>
<p>补充知识：<br>
GDT：全局描述符表，是存放段寄存器内容（段描述符）的数组，可以理解为进程总目录表<br>
GDTR：GDT基地址寄存器，是GDT的入口<br>
IDT：中断描述符表，保护模式下所有中断服务程序的入口地址，相当于实模式下的中断向量表<br>
IDTR：IDT基地址寄存器，是IDT的入口</p>
</blockquote>
<h2 id="打开a20-实现32位寻址">打开A20，实现32位寻址</h2>
<blockquote>
<p>寻址：CPU能使用多大空间的内存</p>
</blockquote>
<p>打开A20，意味CPU可以进行32位寻址，最大寻址空间为4GB，内存条范围由0~0xFFFFF扩展为0~0xFFFFFFFF。</p>
<blockquote>
<p>2^32 = 4*2^30 = 4GB；2^32 = 16^8 = 0xFFFFFFFF</p>
</blockquote>
<h2 id="为保护模式下执行head-s做准备">为保护模式下执行head.s做准备</h2>
<p><strong>1.setup程序对可编程中断控制器重新编程</strong><br>
若不对其重新编程，一些Intel保留作为内部的中断和异常中断将被覆盖。</p>
<p><strong>2.设置CPU为保护模式</strong><br>
setup程序将CR0寄存器第0位(PE)置1，即设置CPU为保护模式。</p>
<p><strong>3.跳转到head程序</strong><br>
通过<code>jmpi  0, 8</code>，从setup跳转到head程序。需要把这里的<code>8</code>看成二进制<code>1000</code>：</p>
<ul>
<li>0:段内偏移</li>
<li>8:段选择符
<ul>
<li>二进制1000
<ul>
<li>最后两位(00)：内核特权级
<ul>
<li>倒第三位(0)：代表GDT</li>
<li>第一位(1)：GDT项号为第2项(从0开始)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="head-s开始执行">head.s开始执行</h2>
<h3 id="执行过程的整体策略">执行过程的整体策略</h3>
<p><strong>1.head程序的加载</strong><br>
head.s先汇编成目标代码，c语言内核程序编译成目标代码，然后链接成system模块。</p>
<p><strong>2.head程序创建了内核分页机制</strong><br>
在0x000000创建页目录表、页表、页表缓冲区、GDT、IDT，并将head执行完的代码所占内存空间覆盖。这也意味着head将自己废弃，main函数开始执行。</p>
<h3 id="步骤">步骤</h3>
<p>1._pg_dir标识内核分页机制完成后的内核起始位置，head程序从这里建立页目录表，为分页机制做准备。<br>
2.head正式执行，将CS的用法转为保护模式（CS作为代码段选择符），<code>jump 0,8</code>使CS和GDT第2项关联，并使代码段基址指向0x000000。<br>
3.段选择子指向内核代码段：DS、ES、FS和GS（都是段选择子）的值都置为<code>0x10</code>，这里的<code>0x10</code>也看成二进制<code>00010000</code>，其中：</p>
<ul>
<li>最后两位（00）：内存特权级；</li>
<li>倒数第三位（0）：代表GDT；</li>
<li>第4、5位两位（10）：GDT的2项（从0开始），即第3项。</li>
</ul>
<p>（<strong>重要：理解每一位代表的东西</strong>）</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/06/OS-LearningNotes2/p6.png" class title="p6">
<p>4.对栈的设置：SS转为栈段选择符，栈顶指针成为32位的esp。</p>
<blockquote>
<p>注意：栈顶增长方向由高地址向低地址</p>
</blockquote>
<p>5.设置IDT：先让所有中断描述符默认指向ignore_int这个位置，然后对IDT寄存器的值进行设置。</p>
<ul>
<li>IDT的一部分 ——&gt; GDT表项 ——&gt; 基址</li>
<li>另一部分 —解析—&gt;偏移+特权等信息</li>
</ul>
<p>6.废除已有的GDT，并在内核新位置重建 ——&gt; 段限长增加了一倍，变为16MB。这里再次对一些段选择符进行重新设置，包括DS、ES等。</p>
<p>7.检验A20地址线、数学协处理器。</p>
<p>8.将L6标号和main函数入口地址压栈，栈顶位main函数地址，这使得head执行完，能通过ret直接执行main函数。</p>
<p>9.创建<strong>分页机制</strong>：<br>
首先，将页目录表和4个页表放在物理内存起始位置，此步骤覆盖了head程序自身内存空间（注意：这4个页表都是内核专属页表，将来每个用户进程都有他们的专属页表）。然后，设置页目录表的前4项，分别指向后4个表。然后，将CR3指向页目录表（CR3是物理地址！），启动分页机制开关PG标志置位。然后认定页目录表在内存的起始位置，这个位置是<strong>内核通过分页机制能够实现线性地址等于物理地址</strong>的唯一起始位置。</p>
<blockquote>
<p>页目录表、页表都占1页(1 页 4KB，1 项 4B)<br>
1 个页表有 1K 项，1 项对应一页覆盖的物理地址(4KB)<br>
1 个页目录表覆盖 1K<em>1K</em>4KB = 4GB物理地址</p>
</blockquote>
<p>10.ret，通过跳入main函数执行，将压入的main函数在执行入口地址弹出给EIP。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>操作系统高级教程</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux Kernel</tag>
        <tag>BIOS</tag>
      </tags>
  </entry>
  <entry>
    <title>补充知识整理</title>
    <url>/2022/09/20/OS-LearningNotes3/</url>
    <content><![CDATA[<h1 id="分段和分页">分段和分页</h1>
<blockquote>
<p>起因是上《操作系统高级教程》时，突然发现对这块的知识已经混沌了，所以重新总结下。<br>
参考：<br>
<a href="https://blog.csdn.net/yzy1103203312/article/details/78529067">https://blog.csdn.net/yzy1103203312/article/details/78529067</a><br>
<a href="https://blog.csdn.net/qq_32740495/article/details/102924136">https://blog.csdn.net/qq_32740495/article/details/102924136</a></p>
</blockquote>
<h2 id="为何需要分段">为何需要分段</h2>
<p>在8086处理器诞生之前，内存寻址方式就是直接访问物理地址（实模式）。8086处理器为了寻址1M的内存空间，把<strong>地址总线扩展到了20位</strong>。但是，ALU的宽度只有16位，即ALU不能计算20位的地址。为了解决这个问题，从而引入了<strong>分段机制</strong>。</p>
<h2 id="ia32框架的内存寻址">IA32框架的内存寻址</h2>
<h3 id="三类地址">三类地址</h3>
<p>IA32的三类地址如下：</p>
<ul>
<li><strong>逻辑地址</strong>：<strong>机器语言指令</strong>用这类地址指定<strong>一个操作数的地址或一条指令的地址</strong>，最原始的地址就是逻辑地址。</li>
<li><strong>线性地址</strong>：将逻辑地址经过<strong>分段机制转换</strong>之后，便得到了线性地址，每个线性地址都<strong>由一个段基址和段内偏移量组成</strong>。</li>
<li><strong>物理地址</strong>：线性地址<strong>经过分页单元的处理</strong>之后得到一个实际物理地址，也就是<strong>内存单元的实际地址</strong>，用于芯片级内存单元寻址。</li>
</ul>
<blockquote>
<p><strong>地址空间</strong>：操作系统给每个进程用的一段连续的虚拟内存空间。这个地址范围不是真实的，是虚拟地址的范围，有时甚至会超过实际物理内存的大小。</p>
</blockquote>
<h3 id="三类地址的转化">三类地址的转化</h3>
<p>以上3类地址通过MMU（内存管理单元）来进行转换。其中MMU处理时包含2个过程，分段和分页。在这里简单的说明下具体过程：</p>
<ol>
<li>当一条<strong>机器指令</strong>给出一个地址时，这时候的地址便是<strong>逻辑地址</strong>；</li>
<li>为了得到线性地址，需要从相应的段寄存器中取出16位的段标识符（段选择符），通过这个段标识符可以得到一个段基址。然后将得到的<strong>段基址与指令中的地址相加</strong>，从而得到一个<strong>线性地址</strong>；</li>
<li>有了线性地址之后，再通过<strong>分页单元</strong>得到<strong>实际的物理地址</strong>。<br>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="https://img-blog.csdnimg.cn/76d5c9e629654292b413216ab1ed2c4a.png" alt="在这里插入图片描述"></li>
</ol>
<h2 id="分段">分段</h2>
<h3 id="硬件中的分段">硬件中的分段</h3>
<p>段是虚拟地址空间的基本单位，分段机制必须把虚拟地址空间的一个地址转换为线性地址空间的一个线性地址。<br>
为了实现这种映射，仅仅用段寄存器来确定一个基地址是不够的，至少还得描述段的长度，并且还需要段的一些其他信息，比如访问权之类。所以，这里需要的是一个数据结构——段描述符，它包括三个方面的内容：</p>
<ul>
<li>段的基地址(Base Address)：在线性地址空间中段的起始地址。</li>
<li>段的界限(Limit)：在虚拟地址空间中，段内可以使用的最大偏移量。</li>
<li>段的保护属性(Attribute)：表示段的特性。例如，该段是否可被读出或写入，或者该段是否作为一个程序来执行，以及段的特权级等等。</li>
</ul>
<p>多个段描述符组成的表称为段描述符表。</p>
<p>逻辑地址的段寄存器中的值提供<strong>段描述符</strong>，然后从段描述符中得到<strong>段基址</strong>和<strong>段界限</strong>，然后<strong>加上逻辑地址的偏移量</strong>，就得到了线性地址，线性地址通过分页机制得到物理地址。</p>
<h3 id="linux的分段">Linux的分段</h3>
<p>为了支持分段，8086处理器设置了四个段寄存器：CS, DS, SS, ES。每个段寄存器都是16位的，都包含着相应段的基址。访存指令中的地址也是16位的，但是，在送入地址总线之前，CPU先把它与某个段寄存器内的值按以下方式相加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">实际物理地址 &#x3D; （段寄存器地址 &lt;&lt; 4） + （指令访存地址）</span><br></pre></td></tr></table></figure>
<p>这四个段寄存器的段首地址均是0，也就是说，段首地址+逻辑地址=线性地址，这个公式里面的段首地址为0，也就意味着在linux中，<strong>逻辑地址=线性地址</strong>，这就是linux的分段技术。</p>
<h2 id="分页">分页</h2>
<p>对于物理内存，分页单元把它分为固定长度的页框（page frame），每一个页框包含一个页（page）。对于虚拟地址空间，也把它分为一个个的页。为了访问每一个物理页，需要有一个页表，记录每个物理页的起始地址，简单说通过页表就可以将一个虚拟内存中的页与具体的物理页一一对应起来。虚拟地址可以分为两部分，页号和页内偏移，页号为页表的索引，得到页的基地址后，加上偏移地址就可以得到具体的物理地址。</p>
<p>以32位环境为例，<strong>虚拟地址空间为4G</strong>，一般<strong>一页为4KB</strong>，这样4G内存可以分为1M个页，由于<strong>每个页表项需要4个字节</strong>来描述，因此一共需要4M的存储空间，因为每个进程都有自己的页表，所以1个进程就需要4M的存储空间。</p>
<h1 id="特权级cpl-dpl和rpl">特权级CPL、DPL和RPL</h1>
<h2 id="相关概念">相关概念</h2>
<p>x86 处理器中，提供了4个特权级别：0，1，2，3。数字越小，特权级别越高！一般来说，操作系统是的重要性、可靠性是最高的，需要运行在0特权级；应用程序工作在最上层，来源广泛、可靠性最低，工作在3特权级别。中间的1和2两个特权级别，一般很少使用。这几个个特权级均由两位（bit）组成，可以表示0～3共4个等级。</p>
<p>在处理器中，有3个相关的术语与特权级密切相关：</p>
<ul>
<li>CPL：<strong>当前进程</strong>的权限级别（Current Privilege Level），是当前<strong>正在执行的代码所在的段</strong>的特权级，存在于cs寄存器的低两位。</li>
<li>RPL: 说明的是<strong>进程对段访问的请求权限</strong>（Request Privilege Level），是对于段选择子而言的，每个段选择子有自己的RPL，它说明的是进程对段访问的请求权限，有点像函数参数。而且<strong>RPL对每个段来说不是固定的</strong>，两次访问同一段时的RPL可以不同。RPL可能会削弱CPL的作用，例如当前CPL=0的进程要访问一个数据段，它把段选择符中的RPL设为3，这样虽然它是0特权，但对该段仍然只有特权为3的访问权限。</li>
<li>DPL: 存储在段描述符中，规定<strong>访问该段的权限级别</strong>(Descriptor Privilege Level)，每个段的DPL固定。当进程访问一个段时，需要进程特权级检查，一般要求 DPL &gt;= max {CPL, RPL}</li>
</ul>
<p>在保护模式下，cpu利用cpl/rpl/dpl对程序的<strong>访问操作</strong>进行特权级检查，数据段和代码段的特权级检查规则有所不同。</p>
<h2 id="对数据段和堆栈段访问时的特权级控制：">对数据段和堆栈段访问时的特权级控制：</h2>
<p>要求访问数据段或堆栈段的程序的CPL ≤ 待访问的数据段或堆栈段的DPL，同时选择子的 RPL ≤ 待访问的数据段或堆栈段的 DPL。即程序访问数据段或堆栈段要遵循一个准则：<strong>只有相同或更高特权级的代码才能访问相应的数据段</strong>。这里，RPL可能会削弱CPL的作用，访问数据段或堆栈段时，默认用CPU和RPL中的最小特权级去访问数据段，所以max {CPL, RPL} ≤ DPL，否则访问失败。</p>
<h2 id="对代码段访问的特权级控制-代码执行权的特权转移-：">对代码段访问的特权级控制（代码执行权的特权转移）：</h2>
<p>一些“定律”：</p>
<ul>
<li>所有的程序转跳，CPU都不会把段选择子的RPL赋给转跳后程序的CS.RPL.</li>
<li>转跳后程序的CPL(CS.RPL)只会有下面的2种可能：
<ul>
<li>转跳后程序的CPL(CS.RPL) = 转跳前程序的CPL(CS.RPL)</li>
<li>转跳后程序的CPL(CS.RPL) =　转跳后程序的CodeDescriptor.DPL</li>
</ul>
</li>
<li>CPU不允许程序向低特权级跳转（认为低特权级的代码不可靠，有风险）</li>
<li>只有一种方式能够使特权级发生改变，call + 调用门 + 非一致代码段，且当前cpl大于目标段dpl，且特权级只能向上跳转。</li>
</ul>
<h1 id="gdt-tss-idt-ldt">GDT TSS IDT LDT</h1>
<h2 id="回顾linux寻址">回顾Linux寻址</h2>
<p>Linux中的寻址: logical addr --&gt; linear addr --&gt; physical addr<br>
第一个转换是通过GDT的分段机制,第二个转换是通过分页机制。CPU使用logical addr, CPU中的MMU部件使用physical addr。比如一个程序编译后，代码段的指令地址是0x08048888，这就是logical addr，CPU就取这个地址。GDT是一个表，用来实现logical addr–&gt; linear addr的转化，也就是分段思想的实现。gdtr寄存器指向GDT在内存中的首地址，用CS,DS中的内容做为index，这个index的学名叫segment selector。</p>
<p>CS：在保护模式下的段选择器,我们一直都只把它看做一个段描述符的“索引号”，用来在 GDT (全局描述描述符表) 中查找一个段描述符。<br>
用户程序拥有自己私有的描述符表 LDT(Local Descriptor Table),并且拥有自己的特权级别(总不能让用户程序与操作系统一样,工作在非常高的 0 特权级别)。</p>
<p>正如处理器中有一个寄存器 GDTR，保存着 GDT 的开始地址和长度；处理器中还有一个寄存器 LDTR，存储着当前正在执行的那个应用程序的 LDT 开始地址和长度。</p>
<h3 id="gdt">GDT</h3>
<p>在Protected Mode下，对一个段的描述则包括3方面因素：【Base Address, Limit, Access】，它们加在一起被放在一个64-bit长的数据结构中，被称为段描述符。但是，无法通过16-bit长度的段寄存器来直接引用64-bit的段描述符。解决的方法就是把这些长度为64-bit的段描述符放入一个数组中，而将段寄存器中的值作为下标索引来间接引用（事实上，是将段寄存器中的高13 -bit的内容作为索引）。这个全局的数组就是GDT。</p>
<h3 id="ldt">LDT</h3>
<p>除了GDT之外，IA-32还允许程序员构建与GDT类似的数据结构，它们被称作LDT（Local Descriptor Table，局部描述符表），但与GDT不同的是，LDT在系统中可以存在多个，并且从LDT的名字可以得知，LDT不是全局可见的，它们只对引用它们的任务可见，每个任务最多可以拥有一个LDT。另外，每一个LDT自身作为一个段存在，它们的段描述符被放在GDT中。</p>
<p>由于每个进程都有自己的一套程序段、数据段、堆栈段，有了局部描述符表则可以将每个进程的程序段、数据段、堆栈段封装在一起，只要改变LDTR就可以实现对不同进程的段进行访问。</p>
<h3 id="段选择子是什么？">段选择子是什么？</h3>
<p>保护模式下，处理器提供段寄存器，处理器提供了6个段寄存器来保存段描述符。这些段寄存器称为cs、ss、ds、es、fs和gs。每个段寄存器都由可见部分和不可见部分组成，当段选择子（可见部分）被加载至段寄存器时，处理器也通过段选择子所指向的段描述符获取了这个段的不可见部分。</p>
<p>段选择子段选择符为16位，描述段的一些信息，它不是直接指向段，指向在GDT或LDT中的段描述符。它的高13位作为被引用的段描述符在GDT/LDT中的下标索引，bit 2用来指定被引用段描述符被放在GDT中还是到LDT中，bit 0和bit 1是RPL——请求特权等级，被用来做保护目的。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/20/OS-LearningNotes3/p1.png" class title="p1">
<p>段选择子包括三部分：描述符索引（index）、TI、请求特权级（RPL）。它的index（描述符索引）部分表示<strong>所需要的段描述符在描述符表的位置</strong>，由这个位置再根据在GDTR中存储的描述符表基址就可以找到相应的描述符。然后用描述符表中的段基址加上逻辑地址（SEL:OFFSET）的OFFSET就可以转换成线性地址，段选择子中的TI值只有一位0或1，0代表选择子是在GDT选择，1代表选择子是在LDT选择。请求特权级（RPL）则代表选择子的特权级，共有4个特权级（0级、1级、2级、3级）。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/20/OS-LearningNotes3/p2.png" class title="p2">
<h3 id="tss-任务状态段">TSS: 任务状态段</h3>
<p>顾名思义，任务状态段就是用来存储和恢复任务的状态信息。</p>
<p>经常听到一个术语:任务上下文。<br>
TSS是一个特殊的段。在Linux中，CPU从系统态切换到用户态时，会用到TSS里面的ss0和esp0。每个CPU只维护一个TSS。TR寄存器指向这个TSS，切换时里面的ss0和esp0会有改变。相应有一个TSSD放在GDT中，是GDT的一个表项。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/09/20/OS-LearningNotes3/p3.png" class title="p3">
<p>可以看到：任务寄存器中可见部分的段选择符加载TSS描述符的段选择符，访问GDT中TSS描述符，通过TSS描述符访问TSS。同时TSS描述符中的基址和界限字段的值又加载到任务寄存器的不可见部分的基址和界限字段，这样做的目的是下次访问该TSS时可以不用通过GDT中的TSS描述符访问TSS，而是直接通过缓存在任务寄存器中的基址和界限字段访问TSS，加快了系统对TSS的访问。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>操作系统高级教程</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux Kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>设备环境初始化及激活进程0</title>
    <url>/2022/10/01/OS-LearningNotes4/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<h2 id="设置根设备-硬盘">设置根设备、硬盘</h2>
<p>用<code>bootsect.s</code>中写入机器系统数据的信息设置软盘为根设备，并设置内核中的硬盘信息。</p>
<h2 id="规划物理内存格局">规划物理内存格局</h2>
<p>设置内存中除内核代码和数据之外三部分的位置和大小：</p>
<ul>
<li>主内存区：进程代码运行的空间；</li>
<li>缓冲区：主机与外设（块设备）交换数据的中转站；</li>
<li>虚拟盘区：可选，可将外设数据先复制至虚拟盘区，然后加以使用。</li>
</ul>
<blockquote>
<p>注：&lt;&lt;12或&gt;&gt;12相当于乘或除以4KB——页</p>
</blockquote>
<h2 id="设置虚拟盘空间并初始化">设置虚拟盘空间并初始化</h2>
<p>设定内存16MB，虚拟盘2MB（缓冲区末端2MB设为虚拟盘）。调用<code>rd_init()</code>函数，对虚拟盘设置：<br>
将虚拟盘请求项处理函数<code>do_rd_request</code>与 请求项处理函数控制结构<code>blk_dev[7]</code>第二项挂钩，意味着内核能通过调用<code>do_rd_request</code>函数处理与虚拟盘相关的请求项操作。</p>
<h2 id="内存管理结构-mem-map-初始化">内存管理结构 mem_map 初始化</h2>
<p>调用<code>mem_init()</code>函数，通过<code>mem_map[]</code>对 1MB (内核所在区域)以上的内存分页进行管理，记录一个页面的使用次数</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/01/OS-LearningNotes4/p1.png" class title="p1">
<h2 id="异常处理类中断服务程序挂接">异常处理类中断服务程序挂接</h2>
<p><code>trap_init()</code>函数将中断、异常处理的服务程序与IDT进行挂接，逐步重建中断服务体系。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/01/OS-LearningNotes4/p2.png" class title="p2">
<p>其中，还需要拼接中断描述符：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/01/OS-LearningNotes4/p3.png" class title="p3">
<h2 id="初始化块设备请求项结构">初始化块设备请求项结构</h2>
<p>linux外设分为块设备（硬盘、软盘）和字符设备（键盘、黑屏命令行显示器），进程想与块设备进行沟通，必须经过主机内存的缓冲区。<br>
请求项管理结构<code>request[32]</code>就是操作系统管理缓冲区与块设备逻辑块读写关系的数据结构。操作系统决定缓冲块与块设备间的读写操作，并把需要操作的缓冲块记录在请求项中，得到读写块设备操作指令后，只根据请求项中的记录决定要处理哪个设备的哪个逻辑块。</p>
<p>初始化：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">request[i].dev&#x3D;-1; &#x2F;&#x2F;请求项未对应哪个设备</span><br><span class="line">request[i].next&#x3D;NULL; &#x2F;&#x2F;还未形成请求项队列</span><br></pre></td></tr></table></figure>
<h2 id="与人机交互界面相关外设中断服务程序挂接">与人机交互界面相关外设中断服务程序挂接</h2>
<p>对串行口、显示器、键盘、开机启动时间设置，以及与此相关的中断服务程序与IDT挂接。</p>
<h2 id="初始化0进程-重要">初始化0进程（重要）</h2>
<p>大致过程如下，都由<code>sched_init()</code>函数实现：</p>
<ol>
<li>初始化进程0
<ul>
<li>将进程0的task_struct中LDT、TSS与GDT挂接</li>
<li>初始化GDT、task[64]以及与进程调度相关寄存器</li>
</ul>
</li>
<li>时钟中断设置 —&gt; 多进程轮转</li>
<li>系统调用：通过set_system_gate将system_call与IDT挂接（特权3，set_trap_gate为特权0）</li>
</ol>
<h3 id="初始化进程0">初始化进程0</h3>
<p>首先在GDT中初始化进程0所占的4、5项，即初始化TSS0（任务状态段）和LDT0（局部描述符）。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/01/OS-LearningNotes4/p4.png" class title="p4">
<p>另外，需要拼接对应的段描述符：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/10/01/OS-LearningNotes4/p5.png" class title="p5">
<p>然后还需要通过INIT_TASK指针初始化进程0的task_struct（内核栈）。每个进程都有自己的用户栈和内核栈（跑内核代码时用这个）。</p>
<h3 id="设置时钟中断">设置时钟中断</h3>
<p>时钟中断是进程0及其他由它创建的进程轮转的基础。</p>
<h3 id="设置系统调用总入口">设置系统调用总入口</h3>
<p>将系统调用函数 system_call 与 int 0x80 中断描述符表挂接。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>操作系统高级教程</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux Kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>PTA习题2-7</title>
    <url>/2021/04/20/PTA%E4%B9%A0%E9%A2%982-7/</url>
    <content><![CDATA[<h1 id="弹球距离">弹球距离</h1>
<p>设有一个球从高度为h米的地方落下，碰到地面后又弹到高度为原来p倍的位置，然后又落下，再弹起，再落下…。请编写函数求初始高度为h的球下落后到基本停下来（高度小于给定阈值TOL）时在空中所经过的路程总和。</p>
<p>函数接口定义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double dist( double h, double p );</span><br></pre></td></tr></table></figure>
<p>其中h是球的初始高度，p是球弹起高度与弹起前落下高度的比值；函数dist要返回球下落后到基本停下来时在空中所经过的路程总和。注意：当弹起的高度小于裁判程序定义的常数TOL时，弹起的距离不计算在内。</p>
<p>裁判测试程序样例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#define TOL 1E-2</span><br><span class="line"></span><br><span class="line">double dist( double h, double p );</span><br><span class="line"></span><br><span class="line">int main()</span><br><span class="line">&#123;</span><br><span class="line">    double h, p, d;</span><br><span class="line">    scanf(&quot;%lf %lf&quot;, &amp;h, &amp;p);</span><br><span class="line">    d &#x3D; dist(h, p);</span><br><span class="line">    printf(&quot;%.6f\n&quot;, d);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;* 你的代码将被嵌在这里 *&#x2F;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输入样例：<br>
<code>1.0 0.4</code><br>
输出样例：<br>
<code>2.319680</code></p>
<p><strong>递归实现</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double dist( double h, double p )&#123;</span><br><span class="line">    if(p*h&lt;TOL) return h;</span><br><span class="line">    else return h+h*p+dist(h*p,p);&#x2F;&#x2F;重复的</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>非递归实现</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">double dist( double h, double p )&#x2F;&#x2F;右一个注意点两次触地时走过的距离为 h+2*h*p</span><br><span class="line">&#123;</span><br><span class="line">    double mix&#x3D;h*p;</span><br><span class="line">    double sum &#x3D; h;&#x2F;&#x2F;第一次落下走过的距离是h</span><br><span class="line">    while(mix&gt;&#x3D;TOL)</span><br><span class="line">    &#123;</span><br><span class="line">        sum+&#x3D; 2*mix;&#x2F;&#x2F;第二次落下走过的是 h+2*h*p，依次类推</span><br><span class="line">        mix &#x3D; mix*p;</span><br><span class="line">    &#125;</span><br><span class="line">    return sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>刷题</category>
      </categories>
      <tags>
        <tag>PTA</tag>
      </tags>
  </entry>
  <entry>
    <title>PTA习题7-1</title>
    <url>/2021/05/13/PTA%E4%B9%A0%E9%A2%987-1/</url>
    <content><![CDATA[<h1 id="7-1-最大子列和问题">7-1 最大子列和问题</h1>
<p>给定K个整数组成的序列 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>N</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>N</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>N</mi><mi>k</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\lbrace N_1,N_2,\cdots,N_k \rbrace</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>，“连续子列”被定义为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>N</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>N</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>N</mi><mi>j</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\lbrace N_i,N_{i+1},\cdots,N_j \rbrace</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span>，其中 1≤i≤j≤K。“最大子列和”则被定义为所有连续子列元素的和中最大者。例如给定序列{ -2, 11, -4, 13, -5, -2 }，其连续子列{ 11, -4, 13 }有最大的和20。现要求你编写程序，计算给定整数序列的最大子列和。</p>
<p>本题旨在测试各种不同的算法在各种数据情况下的表现。各组测试数据特点如下：</p>
<ul>
<li>数据1：与样例等价，测试基本正确性；</li>
<li>数据2：102个随机整数；</li>
<li>数据3：103个随机整数；</li>
<li>数据4：104个随机整数；</li>
<li>数据5：105个随机整数；</li>
</ul>
<p>输入格式:<br>
<code>输入第1行给出正整数K (≤100000)；第2行给出K个整数，其间以空格分隔。</code></p>
<p>输出格式:<br>
<code>在一行中输出最大子列和。如果序列中所有整数皆为负数，则输出0。</code></p>
<p>输入样例:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">6</span><br><span class="line">-2 11 -4 13 -5 -2</span><br></pre></td></tr></table></figure>
<h2 id="解法一：存放在数组中-一个一个来比较">解法一：存放在数组中，一个一个来比较</h2>
<p>时间复杂度为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mi>O</mi><mo stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(n)=O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i,j,n,max=<span class="number">0</span>,sum=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;n);</span><br><span class="line">    <span class="keyword">int</span> a[n];</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">        <span class="comment">//每一趟</span></span><br><span class="line">        <span class="keyword">for</span>(j=i;j&lt;n;j++)&#123;</span><br><span class="line">            sum+=a[j];</span><br><span class="line">            <span class="keyword">if</span>(sum&gt;max)&#123;</span><br><span class="line">                max=sum;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        sum=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d&quot;</span>,max);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="解法二：联机实现">解法二：联机实现</h2>
<p>时间复杂度为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(n)=O(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathdefault">n</span><span class="mclose">)</span></span></span></span></p>
<p>步骤：</p>
<ol>
<li>先进行初始化，max赋0</li>
<li>再从头开始累加，加到大于最大子序列和的值，把这个值给MaxSum</li>
<li>如果累加为负数，这一小段的最大子序列就已经出来了，可以重新进行累加比较了</li>
<li>最后MaxSum一定为最大子序列的和</li>
</ol>
<p>这题的关键：只要是首位元素为负数的肯定不是最大子列的组成部分，我们可以将其抛弃。即如果某个子列的首位为负数，那么它一定要借助后面的非负数。所以<strong>如果前面的n项是负数的话，后面的K-n项和一定会比K项和要大，所以在遇到前n项和是负数时，直接将和置0，从n+1项重新开始加</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">int</span> a[<span class="number">100001</span>];</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;a[i]);</span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>, maxsum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        sum += a[i]; <span class="comment">//依次向右累加</span></span><br><span class="line">        <span class="keyword">if</span> (sum &gt; maxsum)</span><br><span class="line">            maxsum = sum; <span class="comment">//更新最大值</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (sum &lt; <span class="number">0</span>)</span><br><span class="line">            sum = <span class="number">0</span>; <span class="comment">//如果当前和为负数，那么后面的和会减小，所以需要新的起点。</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, maxsum);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="解法三：分治法">解法三：分治法</h2>
<p>首先，我们可以把整个序列平均分成左右两部分，答案则会在以下三种情况中：</p>
<ol>
<li>所求序列完全包含在左半部分的序列中。</li>
<li>所求序列完全包含在右半部分的序列中。</li>
<li>所求序列刚好横跨分割点，即左右序列各占一部分。</li>
</ol>
<p>前两种情况和大问题一样，只是规模小了些，如果三个子问题都能解决，那么答案就是三个结果的最大值。</p>
<p>我们主要研究一下第<strong>三种情况</strong>如何解决：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/05/13/PTA%E4%B9%A0%E9%A2%987-1/img.png" class title="img">
<p>我们只要计算出：以分割点为起点向左的最大连续序列和、以分割点为起点向右的最大连续序列和，这两个结果的和就是第三种情况的答案。因为已知起点，所以这两个结果都能在O(N)的时间复杂度能算出来。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//N是数组长度，num是待计算的数组，放在全局区是因为可以开很大的数组</span></span><br><span class="line"><span class="keyword">int</span> N, num[<span class="number">16777216</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">solve</span><span class="params">(<span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//序列长度为1时</span></span><br><span class="line">    <span class="keyword">if</span>(left == right)</span><br><span class="line">        <span class="keyword">return</span> num[left];</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//划分为两个规模更小的问题</span></span><br><span class="line">    <span class="keyword">int</span> mid = left + right &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">int</span> lans = solve(left, mid);</span><br><span class="line">    <span class="keyword">int</span> rans = solve(mid + <span class="number">1</span>, right);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//横跨分割点的情况</span></span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>, lmax = num[mid], rmax = num[mid + <span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = mid; i &gt;= left; i--) &#123;</span><br><span class="line">        sum += num[i];</span><br><span class="line">        <span class="keyword">if</span>(sum &gt; lmax) lmax = sum;</span><br><span class="line">    &#125;</span><br><span class="line">    sum = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = mid + <span class="number">1</span>; i &lt;= right; i++) &#123;</span><br><span class="line">        sum += num[i];</span><br><span class="line">        <span class="keyword">if</span>(sum &gt; rmax) rmax = sum;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//答案是三种情况的最大值</span></span><br><span class="line">    <span class="keyword">int</span> ans = lmax + rmax;</span><br><span class="line">    <span class="keyword">if</span>(lans &gt; ans) ans = lans;</span><br><span class="line">    <span class="keyword">if</span>(rans &gt; ans) ans = rans;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//输入数据</span></span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;N);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++)</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;num[i]);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, solve(<span class="number">1</span>, N));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>刷题</category>
      </categories>
      <tags>
        <tag>PTA</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo搭建博客</title>
    <url>/2021/01/31/build-blog/</url>
    <content><![CDATA[<h2 id="准备工作">准备工作</h2>
<h3 id="预备知识">预备知识</h3>
<ul>
<li>有一个GitHub账号，没有的话去注册一个；</li>
<li>安装了node.js、npm，并了解相关基础知识；</li>
<li>安装了git for windows（或者其它git客户端）</li>
</ul>
<h3 id="本文所使用环境">本文所使用环境</h3>
<ul>
<li>Windows8.1</li>
<li>node.js@5.5.0</li>
<li>git@1.9.2</li>
<li>hexo@3.2.2</li>
</ul>
<h2 id="搭建github博客">搭建GitHub博客</h2>
<h3 id="安装hexo">安装hexo</h3>
<p>先创建一个文件夹blog，然后cd到这个文件夹下（或者在这个文件夹下直接右键git bash打开）。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>接下来初始化一下hexo</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init myblog</span><br></pre></td></tr></table></figure>
<p>这个myblog可以自己取什么名字都行，然后</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> myblog //进入这个myblog文件夹</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
<p>新建完成后，指定文件夹目录下有：</p>
<ul>
<li>node_modules: 依赖包</li>
<li>public：存放生成的页面</li>
<li>scaffolds：生成文章的一些模板</li>
<li>source：用来存放你的文章</li>
<li>themes：主题</li>
<li>_config.yml: 博客的配置文件</li>
</ul>
<p>打开hexo的服务：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure>
<p>在浏览器输入localhost:4000就可以看到生成的博客了。<br>
使用<code>ctrl+c</code>可以把服务关掉。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<h3 id="将hexo部署到github">将hexo部署到GitHub</h3>
<h4 id="新建仓库">新建仓库</h4>
<p>新建一个名为你的<code>用户名.github.io</code>的仓库</p>
<h4 id="将hexo和github关联起来">将hexo和GitHub关联起来</h4>
<p>也就是将hexo生成的文章部署到GitHub上，打开站点配置文件 _config.yml，翻到最后，修改为：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/YourgithubName/YourgithubName.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>
<p>这个时候需要先安装deploy-git ，也就是部署的命令,这样才能用命令部署到GitHub。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
<h4 id="hexo相关命令">hexo相关命令</h4>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>hexo clean清除了你之前生成的东西，也可以不加。</li>
<li>hexo generate 顾名思义，生成静态文章，可以用 hexo g缩写</li>
<li>hexo deploy 部署文章，可以用hexo d缩写</li>
</ul>
<p>然后，可以在http://yourname.github.io 这个网站看到自己的博客了！！</p>
<blockquote>
<p>有兴趣还可以自己购买域名哦！</p>
</blockquote>
<h2 id="使用buttfly主题">使用buttfly主题</h2>
<h3 id="使用butterfly主题-稳定版-配置">使用butterfly主题（稳定版）配置</h3>
<h4 id="clone主题">clone主题</h4>
<p>在博客根目录里：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly</span><br></pre></td></tr></table></figure>
<h4 id="应用主题">应用主题</h4>
<p>修改站点配置文件<code>_config.yml</code>，把主题改为butterfly：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">butterfly</span></span><br></pre></td></tr></table></figure>
<h4 id="安装插件">安装插件</h4>
<p>载安装 pug 以及 stylus 的渲染器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-renderer-pug hexo-renderer-stylus --save</span><br></pre></td></tr></table></figure>
<h4 id="配置">配置</h4>
<p>把主题文件夹中的 <code>_config.yml</code> 复製到 Hexo 根目录里，同时重新命名为 <code>_config.butterfly.yml</code>。</p>
<p>以后只需要在 <code>_config.butterfly.yml</code>进行配置就行。</p>
<p>Hexo会自动合併主题中的<code>_config.yml</code>和 <code>_config.butterfly.yml</code>里的配置，如果存在同名配置，会使用<code>_config.butterfly.yml</code>的配置，其优先度较高。</p>
<h3 id="相关魔改">相关魔改</h3>
<p>参考：[<a href="https://butterfly.js.org">https://butterfly.js.org</a>]</p>
<h2 id="使用hexo">使用Hexo</h2>
<p>常用hexo命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;postName&quot;</span> <span class="comment">#新建文章</span></span><br><span class="line">hexo new page <span class="string">&quot;pageName&quot;</span> <span class="comment">#新建页面(菜单中的跳转页面)</span></span><br><span class="line">hexo generate <span class="comment">#生成静态页面至public目录</span></span><br><span class="line">hexo server <span class="comment">#开启预览访问端口（默认端口4000，&#x27;ctrl + c&#x27;关闭server）</span></span><br><span class="line">hexo deploy <span class="comment">#部署到GitHub</span></span><br><span class="line">hexo <span class="built_in">help</span>  <span class="comment"># 查看帮助</span></span><br><span class="line">hexo version  <span class="comment">#查看Hexo的版本</span></span><br></pre></td></tr></table></figure>
<p>部署文件需要三步</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo c</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>
<h2 id="markdown使用图片">markdown使用图片</h2>
<h3 id="安装图片插件hexo-asset-image">安装图片插件hexo-asset-image</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install https://github.com/CodeFalling/hexo-asset-image --save</span><br></pre></td></tr></table></figure>
<blockquote>
<p>由于hexo3版本后对很多插件支持有问题，hexo-asset-image插件在处理data.permalink链接时出现路径错误，因此<code>npm install hexo-asset-image --save</code>使用会出现错误</p>
</blockquote>
<h3 id="修改配置文件">修改配置文件</h3>
<p>在<code>_config.yml</code>配置文件中，修改为</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>然后新建一篇文章</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new post <span class="built_in">test</span></span><br></pre></td></tr></table></figure>
<p>这个时候会出现一个 <code>test.md</code> 和 <code>test</code> 文件夹，在文件夹中加入相关照片</p>
<p><img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/01/31/build-blog/addimg.png" alt="addimg"></p>
<p>然后就可以在文章中引用了</p>
<figure class="highlight md"><table><tr><td class="code"><pre><span class="line">&lt;!-- 方法一： --&gt;</span><br><span class="line">![<span class="string">img</span>](<span class="link">test/img.png</span>)</span><br><span class="line">&lt;!-- 方法二 --&gt;</span><br><span class="line">&#123;% asset<span class="emphasis">_img addimg.png This is an test image %&#125;</span></span><br></pre></td></tr></table></figure>
<p>重新编译一下，然后启动服务。</p>
<h2 id="添加本地搜索功能">添加本地搜索功能</h2>
<h3 id="安装hexo-generator-searchdb插件">安装hexo-generator-searchdb插件</h3>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<h3 id="修改站点配置文件-config-yml">修改站点配置文件<code>_config.yml</code></h3>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">search:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">search.xml</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">post</span></span><br><span class="line">  <span class="attr">format:</span> <span class="string">html</span></span><br><span class="line">  <span class="attr">limit:</span> <span class="number">10000</span></span><br></pre></td></tr></table></figure>
<h3 id="修改主题配置文件-config-butterfly-yml">修改主题配置文件<code>_config.butterfly.yml</code></h3>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>修改完上述的配置之后，就可以看到网站菜单上面多了一个搜索按钮，点击就可以进行搜索了。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP基础</title>
    <url>/2021/02/12/nlp1/</url>
    <content><![CDATA[<blockquote>
<p>参考书籍：</p>
<ul>
<li>《自然语言处理理论与实战》</li>
<li>《Python 自然语言处理》</li>
<li>《Python 自然语言处理实战：核心技术与算法》</li>
</ul>
</blockquote>
<h2 id="nlp基本概念">NLP基本概念</h2>
<h3 id="什么是nlp">什么是NLP</h3>
<p>NLP定义：自然语言处理，用计算机处理、理解以及运行的人类语言（如中文、英文等）</p>
<p>NLP分类：</p>
<ul>
<li>自然语言理解
<ul>
<li>音系学：语法中发讯的系统化组织</li>
<li>词态学：研究单词构成及相互关系</li>
<li>句法学：给定文本哪部分是语法正确的</li>
<li>语义句法学：给定文本的含义是什么？</li>
<li>语法学：文本的目的是什么？</li>
</ul>
</li>
<li>自然语言处理
<ul>
<li>自然语言文本</li>
</ul>
</li>
</ul>
<p>NLP的研究任务</p>
<ul>
<li>机器翻译：计算机具备将一种语言<strong>翻译成另一种语言</strong>的能力</li>
<li>情感分析：计算机能够判断用户评论<strong>是否积极</strong></li>
<li>智能问答：计算机能够正确<strong>回答输入的问题</strong></li>
<li>文摘生成：计算机能够准确<strong>归纳、总结并产生文本摘要</strong></li>
<li>文本分类：计算机能够采集各种文章，进行<strong>主题分析</strong>，从而进行<strong>自动分类</strong></li>
<li>舆论分析：计算机能够<strong>判断目前舆论的导向</strong></li>
<li>知识图谱：知识点相互连接而成的<strong>语义网络</strong></li>
</ul>
<h2 id="nlp常用术语">NLP常用术语</h2>
<ul>
<li>分词（segment）
<ul>
<li>将句子分成独立的有意义的语言成分（词）</li>
</ul>
</li>
<li>词性标注（part-of-speech tagging）
<ul>
<li>对词的词性进行标注（例：动词、名词、形容词）</li>
</ul>
</li>
<li>命名实体识别（NER, Named Entity Recognition）
<ul>
<li>从文本中识别具有特定类别的实体（例：人名、地名、机构名等）</li>
</ul>
</li>
<li>句法分析（syntax parsing）
<ul>
<li>分析句子各个成分的依赖关系（例：主从关系），最后可生成句法分析树</li>
</ul>
</li>
<li>指代消解（anaphora resolution）
<ul>
<li>代词指代</li>
</ul>
</li>
<li>情感识别（emotion recognition）
<ul>
<li>本质是分类问题，经常应用在舆情分析等领域，可分为两类（正面、负面）或者三类（+中性）</li>
</ul>
</li>
<li>纠错（correction）
<ul>
<li>在搜索技术和输入法中利用很多，具体做法可以根据N-Gram、字典树等等方法</li>
</ul>
</li>
<li>问答系统（QA system）
<ul>
<li>类似机器人的人工智能系统</li>
</ul>
</li>
</ul>
<h2 id="语料库">语料库</h2>
<ul>
<li>中文维基百科</li>
<li>搜狗新闻语料库</li>
<li>IMDB情感分析语料库</li>
<li>等</li>
</ul>
<h2 id="三个层次">三个层次</h2>
<ul>
<li>词法分析</li>
<li>句法分析</li>
<li>语义分析</li>
</ul>
]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>自然语言处理</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>seaborn</title>
    <url>/2021/02/03/seaborn/</url>
    <content><![CDATA[<h2 id="seaborn简介">seaborn简介</h2>
<p><code>seaborn</code>同<code>matplotlib</code>一样，是Python进行数据可视化分析的重要第三方包。但<code>seaborn</code>是在<code>matplotlib</code>的基础上进行了<strong>更高级的API封装</strong>。使用<code>seaborn</code>，可以在不需要了解那么多底层参数的情况下，同样能够画出比较好看的图表。</p>
<h2 id="seaborn使用">seaborn使用</h2>
<h3 id="安装-导入">安装&amp;导入</h3>
<p>首先确定你的电脑已安装以下应用</p>
<ul>
<li>Python 2.7+ or Python 3</li>
<li>Pandas</li>
<li>Matplotlib</li>
<li>Seaborn</li>
<li>Jupyter Notebook(可选)</li>
</ul>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>
<p>出现jupyternotebook的界面，即可进行代码编写：</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img1.png" class title="img1">
<p>导入相关包：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h3 id="seaborn绘图风格">seaborn绘图风格</h3>
<p>首先定义一个简单的方程来绘制一些偏置的正弦波：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sinplot</span>(<span class="params">flip=<span class="number">1</span></span>):</span></span><br><span class="line">    x = np.linspace(<span class="number">0</span>, <span class="number">14</span>, <span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">7</span>):</span><br><span class="line">        plt.plot(x, np.sin(x + i * <span class="number">.5</span>) * (<span class="number">7</span> - i) * flip)</span><br></pre></td></tr></table></figure>
<p><code>matplotlib</code>默认会绘制如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sinplot()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img2.png" class title="img2">
<p>转换为<code>seaborn</code>默认绘图，可以简单的用set()方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.<span class="built_in">set</span>()</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img3.png" class title="img3">
<p>有五种seaborn的风格，它们分别是：</p>
<ul>
<li>darkgrid（默认）</li>
<li>whitegrid</li>
<li>dark</li>
<li>white</li>
<li>ticks</li>
</ul>
<p>另外可以自己设置相关配置：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set_style(<span class="string">&quot;darkgrid&quot;</span>, &#123;<span class="string">&quot;axes.facecolor&quot;</span>: <span class="string">&quot;.9&quot;</span>&#125;)</span><br><span class="line">sinplot()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img4.png" class title="img4">
<h3 id="数据可视化demo">数据可视化demo</h3>
<p>对数据的可视化操作，乍看起来很复杂，其实种类总结起来可以分为下面几种：</p>
<ul>
<li>单变量分布可视化(displot)</li>
<li>双变量分布可视化(jointplot)</li>
<li>数据集中成对双变量分布(pairplot)</li>
<li>双变量-三变量散点图(relplot)</li>
<li>双变量-三变量连线图(relplot)</li>
<li>双变量-三变量简单拟合</li>
<li>分类数据的特殊绘图</li>
</ul>
<h4 id="单变量分布">单变量分布</h4>
<p>单变量分布可视化是通过将单变量数据进行统计从而实现画出概率分布的功能，<strong>同时</strong>概率分布有<strong>直方图</strong>与<strong>概率分布曲线</strong>两种形式。<br>
利用displot()对单变量分布画出直方图(可以取消)，并自动进行概率分布的拟合(也可以使用参数取消)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set_style(<span class="string">&#x27;darkgrid&#x27;</span>)</span><br><span class="line">x = np.random.randn(<span class="number">300</span>)</span><br><span class="line">sns.distplot(x);</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img5.png" class title="img5">
<p>还可以使用sns.kdeplot()画出核密度估计图。核密度估计是概率论上用来估计未知的密度函数，属于非参数检验，通过核密度估计图可以比较直观的看出样本数据本身的分布特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x=np.random.randn(<span class="number">100</span>)</span><br><span class="line"><span class="comment">#是否进行阴影处理</span></span><br><span class="line">sns.kdeplot(x,shade=<span class="literal">True</span>,color=<span class="string">&quot;g&quot;</span>)</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img6.png" class title="img6">
<p>二元kde图像，很少使用，稍微了解一下即可：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#x,y</span></span><br><span class="line">y=np.random.randn(<span class="number">100</span>)</span><br><span class="line"><span class="comment">#cbar：参数若为True，则会添加一个颜色棒(颜色帮在二元kde图像中才有)</span></span><br><span class="line">sns.kdeplot(x,y,shade=<span class="literal">True</span>,cbar=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img7.png" class title="img7">
<h4 id="双变量分布">双变量分布</h4>
<p>双变量分布通俗来说就是分析两个变量的联合概率分布和每一个变量的分布。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">mean, cov = [<span class="number">0</span>, <span class="number">1</span>], [(<span class="number">1</span>, <span class="number">.5</span>), (<span class="number">.5</span>, <span class="number">1</span>)]</span><br><span class="line">data = np.random.multivariate_normal(mean, cov, <span class="number">200</span>)</span><br><span class="line">df = pd.DataFrame(data, columns=[<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>])</span><br><span class="line">sns.jointplot(x=<span class="string">&quot;x&quot;</span>, y=<span class="string">&quot;y&quot;</span>, data=df);</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img8.png" class title="img8">
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 同样可以使用曲线来拟合分布密度</span></span><br><span class="line">sns.jointplot(x=<span class="string">&quot;x&quot;</span>, y=<span class="string">&quot;y&quot;</span>, data=df, kind=<span class="string">&quot;kde&quot;</span>);</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img9.png" class title="img9">
<h4 id="数据集中成对双变量分析">数据集中成对双变量分析</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对角线化的是单变量的分布</span></span><br><span class="line">iris = sns.load_dataset(<span class="string">&quot;iris&quot;</span>)</span><br><span class="line">sns.pairplot(iris);</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img10.png" class title="img10">
<p>可以进行一些配置：</p>
<ul>
<li>hue——》指定分类变量</li>
<li>markers——》使用不同的形状</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g1 = sns.pairplot(iris, hue=<span class="string">&quot;species&quot;</span>, markers=[<span class="string">&quot;o&quot;</span>, <span class="string">&quot;s&quot;</span>, <span class="string">&quot;D&quot;</span>])</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img11.png" class title="img11">
<p>还有其他配置如下:</p>
<ul>
<li>使用调色板</li>
<li>使用 KDE</li>
<li>使用回归</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">g2 = sns.pairplot(iris, hue=<span class="string">&quot;species&quot;</span>, palette=<span class="string">&quot;husl&quot;</span>)</span><br><span class="line">g3 = sns.pairplot(iris, diag_kind=<span class="string">&quot;kde&quot;</span>)</span><br><span class="line">g4 = sns.pairplot(iris, kind=<span class="string">&quot;reg&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="双变量-三变量散点图">双变量-三变量散点图</h4>
<p>这里使用tips数据集：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tips = sns.load_dataset(<span class="string">&quot;tips&quot;</span>)</span><br><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, data=tips);</span><br><span class="line"><span class="comment"># 除了画出双变量的散点图外，还可以利用颜色来增加一个维度将点分离开</span></span><br><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, hue=<span class="string">&quot;smoker&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>
<p><strong>通过hue设置来进行区分</strong></p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img11.png" class title="img11">
<h4 id="简单线性拟合">简单线性拟合</h4>
<p>主要用regplot()进行画图，这个函数绘制两个变量的散点图，x和y，然后拟合回归模型并绘制得到的回归直线和该回归一个95％置信区间。<br>
（不过一般这种工作可以用sklearn来做）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set_style(<span class="string">&#x27;darkgrid&#x27;</span>)</span><br><span class="line">sns.regplot(x=<span class="string">&quot;total_bill&quot;</span>, y=<span class="string">&quot;tip&quot;</span>, data=tips);</span><br></pre></td></tr></table></figure>
<p>线性模型对某些数据可能适应不够好，可以使用高阶模型拟合，也可以删除部分数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 利用order2阶模型来拟合</span></span><br><span class="line">sns.regplot(x=<span class="string">&quot;x&quot;</span>, y=<span class="string">&quot;y&quot;</span>, data=anscombe.query(<span class="string">&quot;dataset == &#x27;II&#x27;&quot;</span>),ci=<span class="literal">None</span>,order = <span class="number">2</span>);</span><br><span class="line"><span class="comment"># 如果数据中有明显错误的数据点可以进行删除</span></span><br><span class="line">sns.regplot(x=<span class="string">&quot;x&quot;</span>, y=<span class="string">&quot;y&quot;</span>, data=anscombe.query(<span class="string">&quot;dataset == &#x27;III&#x27;&quot;</span>),ci=<span class="literal">None</span>);</span><br><span class="line">plt.figure()</span><br><span class="line">sns.regplot(x=<span class="string">&quot;x&quot;</span>, y=<span class="string">&quot;y&quot;</span>, data=anscombe.query(<span class="string">&quot;dataset == &#x27;III&#x27;&quot;</span>),ci=<span class="literal">None</span>,robust = <span class="literal">True</span>);</span><br></pre></td></tr></table></figure>
<h4 id="热力图">热力图</h4>
<p>取出三个特征进行热力图的绘制figures.pivot() 其中第三个属性表示热力图上实际的值。<br>
常用设置：</p>
<ul>
<li>annot：是否显示数值注释</li>
<li>fmt：format的缩写，设置数值的格式化形式</li>
<li>linewidths：热力图矩阵之间的间隔大小</li>
<li>vmax,vmin：图例中最大值和最小值的显示值，没有该参数时默认不显示</li>
<li>cmap：matplotlib的colormap名称或颜色对象；如果没有提供，默认为：
<ul>
<li>cubehelix map (数据集为连续数据集时)</li>
<li>RdBu_r (数据集为离散数据集时)</li>
</ul>
</li>
<li>xticklabels, yticklabels：绘制dataframe的行列名</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">flights = sns.load_dataset(<span class="string">&#x27;flights&#x27;</span>)</span><br><span class="line"><span class="comment"># 取出这三个属性画热力图，坐标点的位置是passengers</span></span><br><span class="line">flights = flights.pivot(<span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;passengers&#x27;</span>)</span><br><span class="line">ax = sns.heatmap(flights)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将实际的数值绘制到上面</span></span><br><span class="line">flights = sns.load_dataset(<span class="string">&#x27;flights&#x27;</span>)</span><br><span class="line"><span class="comment"># 取出这三个属性画热力图，坐标点的位置是passengers</span></span><br><span class="line">flights = flights.pivot(<span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;passengers&#x27;</span>)</span><br><span class="line">ax = sns.heatmap(flights, annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;d&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2021/02/03/seaborn/img12.png" class title="img12">
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">ax = sns.heatmap(flights, fmt=<span class="string">&#x27;d&#x27;</span>, linewidths=<span class="number">.5</span>, cmap=<span class="string">&#x27;YlGnBu&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>论文阅读记录 —— LLM Agent</title>
    <url>/2024/07/19/LLM-Learning3/</url>
    <content><![CDATA[<h1 id="react">ReAct</h1>
<p>ReAct: Synergizing Reasoning and Acting in Language Models</p>
<ul>
<li>发表：ICLR</li>
<li>时间：2023</li>
<li>机构：普林斯顿大学 &amp; 谷歌</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/19/LLM-Learning3/p1.png" class title="p1">
<h2 id="摘要总结">摘要总结</h2>
<p>虽然大模型在语言理解和交互式决策等任务中表现出色，但它们的推理（例如思维链提示）和行动（例如行动计划生成）能力通常被识别为单独的研究领域。ReAct 论文提出了一种将推理和行动相结合的新方法，<strong>允许 LLM 以交错的方式生成推理轨迹和特定任务的行动</strong>。推理轨迹帮助模型归纳、跟踪和更新行动计划以及处理异常，而Action允许它与外部源（例如知识库或环境）交互并收集附加信息。ReAct 在多个任务上取得了成功，并在表现、可解释性和可信度方面优于现有基线。</p>
<h2 id="研究动机">研究动机</h2>
<ul>
<li>人脑智能的启发： 人类能够将任务导向的行动与语言推理（或内心独白）无缝结合，这在人类认知中发挥着重要作用，例如自我调节、策略规划和保持工作记忆。</li>
<li>现有方法的局限性：
<ul>
<li>链式思维推理（CoT）： CoT 虽然能进行推理，但通常是<strong>静态</strong>的，<strong>无法与外部世界交互</strong>，导致推理过程中出现事实虚构和错误传播等问题。</li>
<li>行动生成： 最近的行动生成方法通常将多模态观察转换为文本，使用语言模型生成特定领域的动作或计划，但<strong>缺乏对高级目标进行抽象推理</strong>或<strong>维持工作记忆</strong>的能力。</li>
</ul>
</li>
</ul>
<h2 id="主要贡献">主要贡献</h2>
<ul>
<li>提出了一种新的提示方法ReAct 模型，<strong>将推理和行动相结合</strong>，使 LLM 能够以交错的方式生成推理轨迹和特定任务的行动，从而实现更有效的推理和决策。</li>
<li>多基准评估： 在多个基准测试（包括问答、事实验证、文本游戏和网页导航）中进行了广泛的实验，证明了 ReAct 在少量学习设置下优于仅进行推理或行动生成的现有方法。</li>
<li>通过系统地进行消融实验和分析，研究了行动在推理任务中的重要性以及推理在交互任务中的重要性。</li>
<li>分析了 ReAct 在提示设置下的局限性（即推理和行动行为的有限支持），并进行了初步的微调实验，展示了 ReAct 在更多训练数据下改进的潜力。</li>
</ul>
<h2 id="叙事逻辑">叙事逻辑</h2>
<p>该文章首先从人类智能出发，指出人类能够将任务导向的行动与语言推理相结合，从而进行有效的认知活动。随后，文章指出现有方法（如 CoT 和行动生成）的局限性，例如 CoT 缺乏外部世界交互导致虚构事实，行动生成缺乏高级目标推理能力。接着，文章提出了 ReAct 模型，该模型通过将推理和行动相结合，使 LLM 能够更有效地进行推理、规划和决策，并与外部环境进行交互。文章通过跨任务评估证明了 ReAct 的有效性，并分析了其可解释性和可控性。最后，文章探讨了 ReAct 的局限性，并提出了改进方向，例如模型细化和使用更多训练数据。</p>
<h2 id="方法">方法</h2>
<p>ReAct 通过将 LLM 的行动空间扩展到包括语言行动（推理轨迹），允许模型进行动态推理和规划，同时与外部环境进行交互。首先，使用Few-Shot（人类轨迹）指导 LLM 生成推理轨迹和行动，这些示例包括分解目标、提取信息、应用常识等。接着，LLM 可以通过交互式地与外部环境（如维基百科）API 进行交互来支持推理，例如检索信息和更新行动计划。</p>
<h2 id="实验">实验</h2>
<ul>
<li>数据集和任务：
<ul>
<li>知识密集型推理任务：
<ul>
<li>多跳问答： HotpotQA，需要推理两个或更多维基百科段落来回答问题。</li>
<li>事实验证： Fever，需要根据维基百科段落判断陈述是否被支持、反驳或信息不足。</li>
</ul>
</li>
<li>决策制定任务：
<ul>
<li>基于文本的游戏： ALFWorld，需要通过文本行动与模拟家居环境交互，实现高层次目标。</li>
<li>网页导航： WebShop，需要根据用户指令进行网页交互，购买满足要求的产品。</li>
</ul>
</li>
</ul>
</li>
<li>行动空间：
<ul>
<li>知识密集型推理任务： 简单的维基百科 web API，包括搜索实体、查找字符串和完成回答三种行动。</li>
<li>决策制定任务： 根据任务类型设计，例如 WebShop 包含搜索、选择产品、选择选项和购买等行动。</li>
</ul>
</li>
<li>基线方法：
<ul>
<li>标准提示： 移除所有推理轨迹和行动，只提供问题和观察。</li>
<li>思维链提示 (CoT)： 移除行动和观察，只进行推理。</li>
<li>自我一致性 (CoT-SC)： 使用少量 CoT 轨迹作为样本，并选择多数答案。</li>
<li>仅行动提示： 移除推理轨迹，模型只与外部环境交互。</li>
</ul>
</li>
<li>评估指标：
<ul>
<li>知识密集型推理任务： 准确匹配、幻觉、推理错误、搜索结果错误、幻觉。</li>
<li>决策制定任务： 成功率、得分、成功率和专家人类的表现。</li>
</ul>
</li>
<li>其他实验：
<ul>
<li>GPT-3 实验： 验证 ReAct 提示的有效性在不同大型语言模型上的通用性。</li>
<li>人类在环 (HITL) 行为纠正： 允许人类编辑推理轨迹，纠正模型行为。</li>
<li>微调： 使用正确答案轨迹微调较小的语言模型，使其能够解码推理轨迹和行动。</li>
</ul>
</li>
</ul>
<h2 id="评价">评价</h2>
<p>后面agent范式的基准，很多都是基于这个进行改进的</p>
<h1 id="reflexion">Reflexion</h1>
<p>Reflexion: Language Agents with Verbal Reinforcement Learning</p>
<ul>
<li>发表：NeurIPS</li>
<li>时间：2023.10.10</li>
<li>机构：美国东北大学</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/19/LLM-Learning3/p2.png" class title="p2">
<h2 id="摘要总结">摘要总结</h2>
<p>agent越来越多地用于与外部环境进行交互。然而，对 agent 来说，进行传统的强化学习方法需要大量的训练样本和昂贵的模型微调。论文提出了 Reflexion，不通过更新权重，而是<strong>通过语言反馈来增强语言 agent</strong>。Reflexion 足够灵活，可以合并各种类型和来源的反馈信号，并在跨不同任务（顺序决策、编码、语言推理）的基准代理上获得显着改进。例如，Reflexion 在 HumanEval 编码基准上实现了 91% 的 pass@1 准确率，超过了之前最先进的 GPT-4 的 80%。我们还使用不同的反馈信号、反思合并方法和 agent 类型进行消融分析。</p>
<h2 id="研究动机">研究动机</h2>
<p>LLM-based Agent的在与外界环境交互、自主决策方面展现出巨大潜力，而传统强化学习方法在 agent 应用上具有局限性。</p>
<h2 id="主要贡献">主要贡献</h2>
<ul>
<li>提出了 Reflexion，一种“口头”强化的新范式，它将策略参数化为代理的记忆编码与 LLM 参数选择配对。</li>
<li>探索了 LLM 中自我反思的这一新兴特性，并根据经验表明，自我反思对于通过少量试验学习复杂任务非常有用。</li>
<li>引入了 LeetcodeHardGym 数据集：一个包含 40 个具有挑战性的 Leetcode 困难问题的代码生成 RL gym 环境。用于测试代码生成代理的能力，并提供一个新的基准。</li>
<li>实验表明 Reflexion 在多个任务的强大基线上实现了改进，并在各种代码生成基准上取得了最先进的结果。</li>
</ul>
<h2 id="叙事逻辑">叙事逻辑</h2>
<ol>
<li>提出问题：LLMs 作为语言代理在处理外部环境方面展现出潜力，但传统强化学习方法学习效率低下。</li>
<li>提出解决方案：提出 Reflexion 框架，利用语言代理的自我反思能力进行强化学习；通过语言反馈而非参数更新来增强代理，并存储反思文本以指导后续决策。</li>
<li>论述 Reflexion 的优势：相比于传统强化学习方法，Reflexion 更轻量级，无需微调 LLM；允许更细微的反馈形式，并提供更明确和可解释的情境记忆。</li>
<li>实验验证：在决策、推理和编程任务中，Reflexion 代理的表现都优于基线方法；Reflexion 在 LeetcodeHardGym 数据集上也取得了优异的成绩。</li>
<li>讨论局限性：Reflexion 可能陷入局部最优解；需要更强的 LLM 进行自我评估；没有成功的正式保证；需要更多的安全性和道德考量；可能使自主 agent 更具可解释性。</li>
<li>总结与展望：Reflexion 框架为语言代理的快速有效学习提供了一种新的思路；未来可以探索更多高级技术，例如价值学习和离策略探索技术。</li>
</ol>
<h2 id="实现">实现</h2>
<ul>
<li>Actor：角色，使用 LLM 实现，它基于可观察的状态，利用<strong>提示生成文本和动作</strong>。</li>
<li>Evaluator：评估器，用于评估 Actor 输出的质量。<strong>将生成的轨迹作为输入，计算在给定任务上下文中的奖励分数</strong>。</li>
<li>Self-reflection：自我反思，<strong>使用 LLM 实现</strong>，用于生成基于语言的反思。在给出稀疏奖励信号，如二元状态（成功/失败），当前轨迹及其持久记忆内存。自我反思模型会生成<strong>细致入微且具体的反馈</strong>，这种反馈相比标量奖励提供更多信息，然后被存储在代理的内存 (mem) 中。</li>
<li>Memory：内存组件，为 Agent 提供额外的上下文。它提供<strong>短期记忆和长期记忆</strong>。在推理时，Actor 根据短期和长期记忆做出决定，在强化学习设置中，<strong>轨迹历史充当短期记忆，而自我反思模型的输出则存储在长期记忆中</strong>。</li>
<li><strong>过程</strong>：在第一次试验中，Actor 通过与环境交互产生轨迹 τ0。然后评估器产生一个分数 r0；rt 是标量奖励；为了放大 r0，自我反思模型分析 {τ0, r0} 集合以生成存储在内存 mem 中的摘要 sr0。srt 是对试验 t 的语言反馈。Actor、Evaluator 和 Self-Reflection 模型通过循环试验协同工作，直到 Evaluator 认为 τt 是正确的。每次试验后 t、srt 都会附加存入 mem。在实践中，通过存储经验的最大数量 Ω（通常设置为 1-3）来限制 mem，从而不超过 LLM 的上下文限制。</li>
</ul>
<h2 id="实验">实验</h2>
<ul>
<li>任务类型： 选择了三种类型的任务来评估 Reflexion 的效果：
<ul>
<li>决策任务： 在 AlfWorld 环境中进行多步决策，例如寻找隐藏物体、移动物体等。</li>
<li>推理任务： 在 HotPotQA 数据集上进行基于 Wikipedia 的问答，需要理解和推理多个支持文档。</li>
<li>编程任务： 在 HumanEval、MBPP 和 LeetcodeHardGym 数据集上进行 Python 和 Rust 代码生成。</li>
</ul>
</li>
<li>基线方法： 与多种基线方法进行比较，包括：
<ul>
<li>ReAct： 基于大型语言模型的决策模型。</li>
<li>Chain-of-Thought (CoT)： 基于大型语言模型的推理模型。</li>
<li>CodeT： 基于大型语言模型的代码生成模型。</li>
</ul>
</li>
<li>评估指标： 根据任务类型选择不同的评估指标，例如：
<ul>
<li>决策任务： 成功解决任务的百分比。</li>
<li>推理任务： 答案与正确答案完全匹配的百分比。</li>
<li>编程任务： 函数体生成的准确率，以及代码是否通过单元测试。</li>
</ul>
</li>
</ul>
<h2 id="评价">评价</h2>
<ul>
<li>论文提出了一种强化学习方法。传统的调优主要是通过训练调整网络参数，而文中提出的方法则是<strong>分析错误，形成反思的文字并保存</strong>，在之后的决策中，将其<strong>作为上下文</strong>以帮助决策。</li>
<li>它<strong>利用大模型</strong>构造了角色的行为、对结果的评价、当不能达成目标时，利用大模型来反思执行过程中具体哪一步出了问题，并将其作为反思存储。这样就构造了<strong>基于当前环境的短期存储</strong>，和<strong>基于反思的长期存储</strong>，结合二者使模型在未来做出更好的决策。</li>
<li>提供了完整的代码</li>
<li>局限：依赖于 LLM 的自我评估能力（或启发式方法）；无法保证成功。</li>
</ul>
<h1 id="retroformer">Retroformer</h1>
<p>Retroformer: Retrospective large language agents with policy gradient optimization</p>
<ul>
<li>发表：ICLR</li>
<li>时间：2024</li>
<li>机构：Salesforce AI</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/19/LLM-Learning3/p3.png" class title="p3">
<h2 id="摘要总结">摘要总结</h2>
<p>一些agent通过口头反馈以完成迭代的反馈学习，他们并没有以基于reward的梯度学习来进行推理和规划。本文介绍了一种新型框架Retroformer ，旨在通过学习回顾模型来强化LLM agent。该框架利用策略梯度优化基于环境反馈的提示，从而自动调整agent的行为，使其能够独立执行面向目标的多步骤任务。与现有的agent不同，Retroformer 能够从环境反馈中学习，并利用<strong>梯度信号</strong>进行推理和规划。实验结果表明，Retroformer 代理在多个任务上表现出优异的性能，证明了其有效性。</p>
<h2 id="研究动机">研究动机</h2>
<p>回顾性学习的优势显现 + 手动提示工程在更新的局限性</p>
<h2 id="主要贡献">主要贡献</h2>
<ul>
<li>提出了 Retroformer，它根据环境反馈迭代微调更新LLM agent的提示。采用<strong>策略梯度</strong>方法，将 Actor LLM 作为环境的一部分，允许从各种任务的广泛奖励信号中学习。</li>
<li>Retroformer关注微调 agent 架构中的回顾模型（retrospective model），<strong>无需访问Actor LLM 参数</strong>或通过它传播梯度。 Retroformer 的不可知特性（agnostic），使其成为各种基于云的 LLM 的灵活插件模块，例如 OpenAI GPT 或 Google Bard。</li>
</ul>
<h2 id="叙事逻辑">叙事逻辑</h2>
<p>首先指出 LLM agent在利用环境反馈和奖励方面存在的局限性，然后介绍了现有的 LLM agent和 Transformer 强化学习技术，并将 Retroformer 与相关研究进行比较。接着，论文定义了 LLM agent、环境和回顾模型的相关符号和公式，并详细介绍了 Retroformer 框架的组成部分，包括actor模型、回顾模型（retrospective model）、记忆模块和奖励构造。随后，论文解释了如何使用策略梯度优化来微调retrospective model，并生成更有利于任务完成的提示。最后，论文在 HotPotQA、AlfWorld 和 WebShop 等真实世界数据集上进行了实验，并将 Retroformer 与其他 agent 进行了比较，结果表明 Retroformer 能够显著提高 LLM 代理的任务完成效率和学习速度。</p>
<h2 id="方法">方法</h2>
<p>文章提出Retroformer,用策略梯度的方式调优prompt，更好的利用环境的reward。大体思路是学习一个retrospective LLM，将之前的轨迹和得分作为输入，得到一个新的prompt，这个prompt综合分析了之前的经验，从而提供一个更好的prompt。然后不断和环境交互，用PPO训练retrospective LLM。具体的，整个架构包括Actor Model，Retrospective Model和Memory Module。</p>
<ul>
<li>Actor Model是一个固定参数的LLM，用来输入prompt生成动作。</li>
<li>Retrospective Model用来根据之前的经验生成新的prompt（Its primary function is to produce self-reflections, offering valuable feedback for diagnosing a possible reason for prior failure and devising a new, concise, high-level plan that aims to mitigate same failure.）。</li>
<li>Memory Module存储长短时记忆。其中Short-term memory指当前episode，Long-term memory指Retrospective Model输出的总结了之前的失败经验的prompt。</li>
</ul>
<h2 id="实验">实验</h2>
<ul>
<li>设置：实验使用 GPT-3 和 GPT-4 作为冻结的actor模型，LongChat 作为回顾模型，并使用 LoRA 进行微调。</li>
<li>在 HotPotQA 中，Retroformer 通过分析文本匹配度来评估答案的准确性；</li>
<li>在 AlfWorld 中，使用二元成功/失败状态作为奖励；</li>
<li>在 WebShop 中，根据商品属性和选项匹配度以及价格限制来计算奖励。</li>
</ul>
<h2 id="评价">评价</h2>
<p>真正在agent中做了一个强化学习的工作，虽然是在prompt上。另外，当前使用的是基于文本的记忆模块，可以考虑使用更复杂的记忆模块，例如知识图谱，以更好地存储和利用 LLM 代理的长期记忆。</p>
<h1 id="expel">ExpeL</h1>
<h1 id="memorybank">MemoryBank</h1>
<p>MemoryBank: Enhancing Large Language Models with Long-Term Memory</p>
<ul>
<li>发表：arxiv</li>
<li>时间：2023.05</li>
<li>机构：中山大学</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/19/LLM-Learning3/p4.png" class title="p4">
<h2 id="摘要总结">摘要总结</h2>
<p>MemoryBank 是一种新型记忆机制，旨在解决 LLM 缺乏长期记忆的问题。它通过存储、检索和更新记忆，并总结出用户画像，使 LLM 能够更好地理解用户并适应其个性，从而提供更个性化、更具同理心的交互体验，作为一个优秀的 AI 伴侣。</p>
<h2 id="研究动机">研究动机</h2>
<p>艾宾浩斯（Ebbinghaus，1964）的遗忘曲线理论中记忆随时间的保留和遗忘模式</p>
<h2 id="主要贡献">主要贡献</h2>
<ul>
<li>提出 MemoryBank： 一种新型记忆机制，为 LLM 提供长期记忆能力，使其能够存储、检索和更新记忆，并绘制用户画像。（<strong>方法</strong>）</li>
<li>展示 MemoryBank 的实用性： 通过开发 SiliconFriend 聊天机器人，证明 MemoryBank 可以使 LLM 更好地理解用户并适应其个性，提供更个性化、更具同理心的交互体验。（<strong>用处</strong>）</li>
<li>验证 MemoryBank 的有效性： 通过定性和定量分析评估 MemoryBank 的有效性，结果表明其在记忆回忆、提供同理心的陪伴和理解用户画像方面表现出色。（<strong>性能</strong>）</li>
<li>MemoryBank 的通用性： MemoryBank 可以与开源和闭源 LLM 配合使用，并支持中英双语，具有广泛的适用性。（<strong>通用、泛化</strong>）</li>
</ul>
<h2 id="叙事逻辑">叙事逻辑</h2>
<p>首先指出了 LLM 缺乏长期记忆机制的问题，然后介绍了 MemoryBank 这种新型记忆机制，接着详细解释了 MemoryBank 的组成部分和工作原理，并通过 SiliconFriend 聊天机器人的应用案例展示了 MemoryBank 的有效性，最后通过定性和定量分析评估了 MemoryBank 的性能。</p>
<h2 id="方法">方法</h2>
<p>MemoryBank 通过以下几个步骤实现：</p>
<ul>
<li>记忆存储： 将用户与 LLM 的对话记录存储下来，并生成事件摘要和用户画像。</li>
<li>记忆检索： 使用嵌入模型和索引技术，根据当前对话内容检索相关的记忆片段。</li>
<li>记忆更新： 基于艾宾浩斯遗忘曲线理论，根据时间衰减和记忆强度更新记忆，使 LLM 能够模拟人类的遗忘和记忆强化过程。</li>
</ul>
<h2 id="实验">实验</h2>
<p>设计了 194 个探索性问题来评估模型是否能够成功回忆起相关记忆并提供适当的回答。实验结果展示了SiliconFriend在记忆回忆、提供同理心陪伴和理解用户画像方面的能力。</p>
<h2 id="评价">评价</h2>
<p>Motivation很好，但是应用在了AI伴侣上，而且实验比较主观，都是基于人类打分。</p>
]]></content>
      <categories>
        <category>大模型</category>
        <category>Agent</category>
      </categories>
      <tags>
        <tag>大模型</tag>
        <tag>Agent</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型的对抗攻击与防御</title>
    <url>/2024/07/10/LLM-Security1/</url>
    <content><![CDATA[<blockquote>
<p>原文：OpenAI 安全系统（Safety Systems）团队负责人 Lilian Weng 发布的一篇博客文章 <a href="https://lilianweng.github.io/lil-log/2023/11/07/adversarial-attacks-on-llms.html">《Adversarial Attacks on LLMs》</a></p>
</blockquote>
<p>随着 ChatGPT 的发布，大型语言模型应用正在加速大范围铺开。OpenAI 的安全系统团队已经投入了大量资源，研究如何在对齐过程中为模型构建默认的安全行为。但是，对抗攻击或 prompt 越狱依然有可能让模型输出我们不期望看到的内容。</p>
<p>目前在对抗攻击方面的研究很多集中在图像方面，也就是在连续的高维空间。而对于文本这样的离散数据，由于缺乏梯度信号，人们普遍认为攻击会困难得多。Lilian Weng 之前曾写过一篇文章<a href="https://lilianweng.github.io/posts/2021-01-02-controllable-text-generation/">《Controllable Text Generation》</a>探讨过这一主题。简单来说：攻击 LLM 本质上就是控制该模型输出特定类项的（不安全）内容。</p>
<p>此外，还有研究者试图通过攻击大语言模型来提取其预训练数据、私有信息或者通过数据毒化手段来干扰模型的训练过程。但这些并非本文要探讨的主题。</p>
<h1 id="基础">基础</h1>
<h2 id="威胁模型">威胁模型</h2>
<p>对抗攻击是<strong>对输入样本进行微小难以察觉的修改，诱使模型输出我们不期望的内容</strong>。许多早期研究关注的重点是分类任务，而近期的工作则开始更多关注生成模型的输出。本文探讨的是大型语言模型，并且假定攻击<strong>仅发生在推理阶段</strong>，也就是说模型权重是固定的。</p>
<!-- <img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p1.png" class="" title="p1"> -->
<blockquote>
<p>对抗样本的定义:对抗样本是指能够欺骗模型，使其做出错误预测的输入样本，但与原始样本在语义上仍然相似，不易被人察觉。</p>
</blockquote>
<h3 id="分类">分类</h3>
<p>在过去，研究者更关注的是对分类器进行对抗攻击，并且许多是在图像领域。LLM 也可被用于分类，给定一个输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 和一个分类器 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(.)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord">.</span><span class="mclose">)</span></span></span></span>，我们希望找到该输入的一个差异细微的对抗版本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>a</mi><mi>d</mi><mi>v</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{adv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>a</mi><mi>d</mi><mi>v</mi></mrow></msub><mo stretchy="false">)</mo><mo mathvariant="normal">≠</mo><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x_{adv})≠f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>。</p>
<h3 id="文本生成">文本生成</h3>
<p>给定一个输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>和一个生成模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(.)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord">.</span><span class="mclose">)</span></span></span></span>，该模型可输出一个样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y \sim p(.|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord">.</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>。这里的对抗攻击是找到一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>，使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 会违反该模型内置的安全行为，比如输出非法主题的不安全内容、泄漏隐私信息或模型训练数据。对<strong>生成任务</strong>而言，判断一次攻击成功与否并非易事，这<strong>需要一个超高质量的分类器来判断 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 是否安全或需要人类来进行审查</strong>。</p>
<h3 id="白盒攻击和黑盒攻击">白盒攻击和黑盒攻击</h3>
<ul>
<li>
<p><strong>白盒攻击</strong>（White-box attacks）假设攻击者可以<strong>完全访问</strong>模型权重、架构和训练工作流程，这样一来攻击者就可以获得<strong>梯度信号</strong>。这里我们并不假设攻击者能获得全部训练数据。这仅适用于开源模型。</p>
</li>
<li>
<p><strong>黑盒攻击</strong>（Black-box attacks）则是假设攻击者只能访问 API 类型的服务 —— 攻击者可以提供输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 并获取反馈的样本 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span>，而不知道有关模型的更多信息。</p>
</li>
</ul>
<h1 id="对抗性攻击的种类">对抗性攻击的种类</h1>
<p>为了让大语言模型 (LLMs) 做出错误的输出，研究人员发明了多种对抗性输入方法。这里，我们介绍五种主要策略。</p>
<table>
<thead>
<tr>
<th>攻击方式</th>
<th>类型</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>Token操作</td>
<td>黑盒</td>
<td>微调输入文本的少量 Token，引发模型失效，同时保留原文的含义。</td>
</tr>
<tr>
<td>基于梯度的攻击</td>
<td>白盒</td>
<td>利用梯度信息来制定出有效的攻击策略。</td>
</tr>
<tr>
<td>越狱式提示</td>
<td>黑盒</td>
<td>常用一些基于直觉的提示来绕过模型内建的安全机制。</td>
</tr>
<tr>
<td>人类参与的红队策略</td>
<td>黑盒</td>
<td>人工对模型进行攻击，可能会借助其他模型的协助。</td>
</tr>
<tr>
<td>模型红队攻击</td>
<td>黑盒</td>
<td>一个模型对另一个模型进行攻击，攻击者模型可以根据需要进行调整。</td>
</tr>
</tbody>
</table>
<h2 id="token操作">Token操作</h2>
<p>给定一段包含一个 token 序列的文本输入，我们可以使用<strong>简单的token操作</strong>（比如<strong>替换成同义词</strong>）来诱使模型给出错误预测。</p>
<blockquote>
<p>想象一下，如果我们有一段文本，里面充满了各种Token（就是文字或词汇），我们可以对这些Token进行一些小把戏，比如换个同义词，就能让智能模型搞不清楚状况，做出错误的判断。这种在所谓的黑盒环境下的“Token 操纵术”是可行的。</p>
</blockquote>
<p>基于 token 操作的攻击属于黑盒攻击。在 Python 框架中，Morris et al. 2020 的论文《TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP》实现了许多词和 token 操作攻击方法，可用于为 NLP 模型创建对抗样本。这一领域的许多实验主要针对分类和文本蕴含。</p>
<p>举个例子，Ribeiro et al (2018) 的研究《Semantically Equivalent Adversarial Rules for Debugging NLP models》依赖于人工提出的「语义等价式对抗规则（SEAR）」，其可以通过尽可能少的 token 操作来让模型无法生成正确答案。比如，其中的规则包括将 What 换成 Which、将 was 换为 is。另外，还有其他研究者提出的替换关键词、用同义词替换等方法。</p>
<h2 id="基于梯度的攻击">基于梯度的攻击</h2>
<p>如果是白盒攻击，则攻击者可以获取所有的模型参数和架构。因此，攻击者就可以<strong>依靠梯度下降</strong>来通过编程方式学习最有效的攻击手段。这种基于梯度的攻击手法，<strong>只适用于可以完全访问内部结构的白盒环境</strong>，比如开源 LLM。</p>
<h3 id="gbda">GBDA</h3>
<p>Guo et al. 2021 的论文《Gradient-based Adversarial Attacks against Text Transformers》提出的基于梯度的分布式攻击（GBDA）使用了 Gumbel-Softmax 近似法,来使对抗损失优化可微。在这种方法中，BERTScore 和困惑度（perplexity）用来衡量生成的文本既关联又流畅。然而，Gumbel-softmax 技巧难以扩展用于 token 删除或增添，它受限于 token 替换操作。</p>
<ul>
<li>
<p><strong>核心思想</strong>：<strong>寻找一个对抗分布</strong>，而不是单个对抗样本。这个对抗分布参数化地表示一系列可能的对抗样本，并使用连续的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>进行控制。通过优化<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span>，我们可以调整对抗分布，使其包含更多能够欺骗目标模型 h 的样本。</p>
</li>
<li>
<p><strong>优化过程</strong>：</p>
<ul>
<li>GBDA 使用 Gumbel-softmax 技术将对抗分布的采样过程变得可微分，从而可以使用梯度下降等优化算法进行优化。</li>
<li>优化过程中，目标是最小化一个包含对抗损失、流畅性约束和语义相似性约束的损失函数。</li>
<li>对抗损失鼓励模型对样本做出错误预测。</li>
<li>流畅性约束使用语言模型来评估样本的流畅程度，并鼓励生成更自然的文本。</li>
<li>语义相似性约束使用 BERTScore 来评估样本与原始样本在语义上的相似程度，并鼓励生成语义上更接近原始样本的对抗样本。</li>
</ul>
</li>
<li>
<p><strong>生成对抗样本</strong>：优化完成后，从对抗分布 PΘ 中采样即可得到对抗样本。由于对抗分布中包含多种可能的对抗样本，我们可以从中选择最适合当前任务和目标模型的样本。</p>
</li>
</ul>
<h3 id="hotflip">HotFlip</h3>
<p>Ebrahimi et al. 2018 在论文《HotFlip: White-Box Adversarial Examples for Text Classification》 中则是<strong>将文本操作看作是向量空间中的输入</strong>，度量的是损失在这些向量上的导数。基于one-hot表示的梯度来有效估计单个操作所造成的最大损失的变化，通过原子翻转操作（将一个字符替换为另一个字符）生成对抗样本，并通过一系列的字符翻转来支持插入和删除操作。HotFlip 可以扩展用于 token 删除或增添。</p>
<h3 id="uta">UTA</h3>
<p>Wallace et al. (2019) 的论文《Universal Adversarial Triggers for Attacking and Analyzing NLP》提出了一种<strong>在 token 上进行梯度引导式搜索</strong>的方法，可以找到诱使模型输出特定预测结果的短序列，这个短序列被称为 Universal Adversarial Triggers （UAT，通用对抗触发器）。UAT 不受输入的影响，这意味着这些触发器可以<strong>作为前缀（或后缀）连接</strong>到来自数据集的任意输入上。</p>
<p>上面的 token 搜索方法可以使用<strong>波束搜索增强</strong>。当寻找最优的 token 嵌入时，可以选取 top-k 个候选项，而不是单独一个，在当前数据批上从左到右搜索，并根据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>a</mi><mi>d</mi><mi>v</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{adv}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">d</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 为每个波束评分。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p1.png" style="zoom:45%;">
<p>UAT 的损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>a</mi></msub><mi>d</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">L_adv</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span>  需要针对具体任务而设计。分类或阅读理解依赖于交叉熵。</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p3.png" style="zoom:45%;">
<p>UAT 为何有效？这是一个很有趣的问题。因为 UAT 是与输入无关的，并且可以在有不同嵌入、token 化方案和架构的模型之间迁移，因此它们也许可以有效地利用训练数据中的偏差，毕竟这种偏差已经融入到了模型的全局行为中。</p>
<p>使用 UAT 攻击有一个缺点：<strong>很容易检测出来</strong>。原因是所学习到的触发器往往是毫无意义的。Mehrabi et al. (2022) 在论文《Robust Conversational Agents against Imperceptible Toxicity Triggers》中研究了 UAT 的两种变体，它们会促使所学到的触发器在多轮对话语境中难以察觉。其目标是创建能在给定对话中有效触发有毒响应的攻击性消息，同时保证该攻击在对话中是流畅、连贯和一致的。</p>
<h3 id="autoprompt">AutoPrompt</h3>
<p>Shin et al., 2020 的《AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts》使用了同样的<strong>基于梯度的搜索策略</strong>来为多样化的任务寻找最有效的 <strong>prompt</strong> 模板。</p>
<h3 id="通用对抗触发-token-作为后缀连接到输入">通用对抗触发 token 作为后缀连接到输入</h3>
<p>Zou et al. (2023) 的论文《Robust Conversational Agents against Imperceptible Toxicity Triggers》也研究了将通用对抗触发 token 作为后缀连接到输入请求上的情况。他们具体研究了对 LLM 的恶意请求 —— 对此模型应当拒绝回答。事实上，拒绝不被允许的内容类别（比如犯罪建议）是 GPT-4 内置的一个重要的安全措施。对抗性的目标是，<strong>即使面对应该被拒绝的请求，也能操纵语言模型给出 肯定的回应</strong>。例如，面对一个恶意请求，模型可能会回答说：“Sure, here is how to …”。为了避免仅仅通过改变话题来引出一个 “sure” 回答，预期中的肯定回应也被设定为会重复用户的部分提示。而计算这种回应的可能性时使用的损失函数非常简单，就是目标回应的负对数似然 (NLL)。</p>
<h3 id="gcg">GCG</h3>
<p>为了在多个输入上引发模型给出肯定回应，研究人员在两个不同的模型 Vicuna-7b 和 Vicuna-13b 上进行了实验。他们使用了一种称为贪婪坐标梯度 (GCG) 的搜索技术，来找到能在所有可能的单个 Token 替换中减少损失最多的候选 Token。鉴于实际上不可能评估所有 Token 的替换，研究者采用了一种基于梯度的 Token 搜索策略，这种策略与 UAT 和 AutoPrompt 相似，可以<strong>为每个 Token 找出能够最大化减少损失函数梯度的最佳候选 Token</strong>。</p>
<p>尽管他们的攻击序列完全是基于开源模型训练的，但它们却出乎意料地可以移植用于其它商用模型，这表明对开源模型的白盒攻击对私有模型也有效，尤其是当低层的训练数据有所重叠时。注意 Vicuna 的训练使用了从 GPT-3.5-turbo 收集的数据（通过 shareGPT），这本质上是蒸馏，因此这种攻击更像是白盒攻击。</p>
<h3 id="arca">ARCA</h3>
<p>Jones et al. 2023 等提出的自回归随机坐标上升（ARCA）,ARCA 考虑了一系列更广泛的优化问题，用以寻找符合某种特定行为模式的输入输出对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span>；例如，输入是以 “Barack Obama” 开头的无害内容，但可能产生有害的输出。</p>
<h2 id="越狱式提示">越狱式提示</h2>
<p>Jailbreak 提示技术是一种利用弱点强制大语言模型（LLMs）产出那些本应被过滤的有害内容。这种技术属于黑盒攻击，其措辞组合的选取是基于经验法则和手动尝试。</p>
<p>Wei et al. (2023) 的论文《Jailbroken: How Does LLM Safety Training Fail?》提出了 LLM 安全的两种失败模式，可用于指导越狱攻击的设计:</p>
<ol>
<li>
<p><strong>目标冲突</strong>：当一个模型在执行能力（比如“必须严格执行指令”）和安全目标之间出现矛盾时，我们称之为目标冲突。举例来说，有些人可能会利用这种冲突来实施所谓的“越狱攻击”：</p>
<ul>
<li>前缀引导：让模型以肯定答复开始对话。</li>
<li>拒绝抑制：详细指示模型避免使用拒绝的表达方式。</li>
<li>风格限制：要求模型不使用复杂词汇，这样它就无法使用专业术语或详细解释来拒绝某些请求。</li>
<li>角色扮演：例如，扮演 DAN（立即行动），AIM（总是表现出高智能和机智）等角色。</li>
</ul>
</li>
<li>
<p><strong>泛化失配</strong>：安全训练未能覆盖到模型实际具备能力的领域。这种情况通常发生在模型的安全训练数据未涉及到的领域，但这些输入却在它广泛的预训练资料库中。比如：</p>
<ul>
<li>特殊编码：使用 Base64 编码来构建对抗性输入。</li>
<li>字符变换：ROT13 密码、火星文或脑残体（用视觉上相似的数字和符号替换字母）、摩尔斯电码。</li>
<li>词变换：Pig Latin（用同义词替换敏感词，比如用「窃」替换「偷」）、拆分关键词（即所谓的 token smuggling，也就是把敏感词分成几部分）。</li>
<li>prompt 层面的混淆：翻译成其它语言、要求模型以其能理解的方式进行混淆。</li>
</ul>
</li>
</ol>
<p>Wei et al. (2023) 实验了大量越狱方法，包括由以上原理构建的组合型策略。</p>
<ul>
<li>combination_1 组合了前缀引导、拒绝抑制和 Base64 攻击。</li>
<li>combination_2 加入了风格限制。</li>
<li>combination_3 又添加了生成网站内容和格式化限制条件。</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p4.png" style="zoom:35%;">
<p>Greshake et al. (2023) 的论文《Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection》则在较高层面上观察了 prompt 注入攻击。其中指出，即便当攻击无法提供详细的方法而仅仅提供一个目标时，模型也有可能自动去实现它。当模型可以访问外部 API 和工具时，对更多信息（甚至是专有信息）的获取可能导致更大的钓鱼攻击和私密窥探攻击风险。</p>
<h2 id="有人类参与的红队策略">有人类参与的红队策略</h2>
<p>由 Wallace 等人 (2019) 提出的“人类参与的敌对生成”策略，旨在<strong>开发工具辅助人类“智破”人工智能模型</strong>。在他们的研究中，以 QuizBowl QA 数据集 为基础，他们设计了一套敌对性写作界面。这个界面可以引导用户编写类似《危险边缘》节目风格的问题，目的是让人工智能模型产生错误的判断。系统会根据每个词的重要度来进行颜色高亮显示，这个重要度是通过移除该词后模型预测概率的变化来确定的，具体是通过计算模型对词嵌入的梯度来近似得到的。<br>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p5.png" style="zoom:45%;"><br>
界面由（左上角）模型的前五个预测和（右下角）根据词语重要性高亮显示的用户问题组成。</p>
<p>在 Ziegler 等人 (2022) 的一个实验中，研究人员指导人类参与者寻找针对暴力内容的安全分类器的潜在失败点。他们开发了一种工具，帮助参与者更快速、更有效地发现并解决分类器的漏洞。使用工具辅助的改写比全手工改写更高效，把处理每个案例的时间从 20 分钟缩短至 13 分钟。具体来说，他们为人类作者引入了两种辅助特性：</p>
<ul>
<li>特征 1: <strong>每个词语的显著性分数展示</strong>。工具界面会突出那些一旦被移除就可能影响分类器判定结果的词语。一个词语的显著性分数是根据这个词语的嵌入对分类器输出的梯度幅值来确定的，这和 Wallace 等人 (2019) 的做法是一样的。</li>
<li>特征 2: <strong>词语替换与添加</strong>。这项功能让用户通过 BERT-Attack 轻松进行词语的操作。接着，由人类作者对词语更新进行复核。只要点击文本片段中的某个词语，就会弹出一个下拉菜单，里面按照能够降低当前模型分数的程度，列出了新的词语选项。目的是减少模型预测这些输入为暴力内容的可能性。</li>
</ul>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p6.png" style="zoom:35%;">
<p>Xu et al. 2021 的《Bot-Adversarial Dialogue for Safe Conversational Agents》提出了 Bot-Adversarial Dialogue（BAD），该框架可以引导人类去诱使模型犯错（比如输出不安全的内容）。他们收集了 5000 多组模型与众包工作者的对话。每一组对话都包含 14 轮，然后他们根据不安全对话轮次的数量给模型打分。他们最终得到了 BAD 数据集，其中包含大约 2500 组带有攻击性标签的对话。</p>
<p>Anthropic 的红队数据集包含接近 4 万个对抗攻击，它们收集自人类红队者与 LLM 的对话。他们发现，RLHF 的规模越大，就越难以攻击。OpenAI 发布的大模型（比如 GPT-4 和 DALL-E 3）普遍使用了人类专家红队，以确保系统的安全性。</p>
<h2 id="模型红队攻击">模型红队攻击</h2>
<p>人类红队策略很强大，但是难以大规模实施而且可能需要大量经过培训的专业人士。现在想象一下：我们可以学习一个红队模型 red 来与目标 LLM 进行对抗，以触发其给出不安全响应。对于基于模型的红队策略，主要的难题是<strong>如何判断一次攻击是否成功</strong>；只有知道了这一点，我们才能构建用于训练红队模型的合适学习信号。</p>
<p>假设我们已经有一个高质量的分类器，能够判断模型的输出是否有害，我们就可以将其用作奖励来训练红队模型，以得到一些能最大化分类器在目标模型输出上的分数的输入。令 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r(x, y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> 是一个这样的红队分类器，其可以判断在给定测试输入<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span>时，输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 是否有害(基于Perez et al. 2022 的论文《Red Teaming Language Models with Language Models》)。</p>
<p>Casper et al. (2023) 的论文《Explore, Establish, Exploit: Red Teaming Language Models from Scratch》设计了一种有人类参与的红队过程。其与 Perez et al. (2022) 的主要不同之处在于其明确地为目标模型设置了一个数据采样阶段，这样就可以收集其上的人类标签来训练针对特定任务的红队分类器。其包含探索（Explore）、建立（Establish）和利用（Exploit）三个阶段。使用强化学习培养一个对抗性的提示生成器，这个生成器能够触发一系列多样化的有害输出。</p>
<p>Mehrabi et al. (2023) 的论文《FLIRT: Feedback Loop In-context Red Teaming》则是依靠红队 LM <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>r</mi></msub><mi>e</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">p_red</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span></span></span></span> 的上下文学习来攻击图像或文本生成模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span>，使其输出不安全的内容。红队语言模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{red}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 创造了一个根据示例定制的对抗性提示 $ x \sim {p_{red}{(.∣{examples})}}$ 这些初步的示例是由人工仔细打造的；生成模型<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span>会以这个提示为条件，输出图像或文字 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>∼</mo><mi>p</mi><mo stretchy="false">(</mo><mi mathvariant="normal">.</mi><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">y \sim p(.∣x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord">.</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>。然后，生成的作品 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span></span> 会被检测，比如使用分类器来判定其是否安全；如果结果是不安全的，那么这个触发提示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span></span></span></span> 就会用来更新上下文的案例，从而让 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{red}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 按照某种策略制作出新的对抗性提示。</p>
<h1 id="如何应对攻击">如何应对攻击</h1>
<h2 id="鞍点问题">鞍点问题</h2>
<p>Madry et al. 2017 的《Towards Deep Learning Models Resistant to Adversarial Attacks》提出了一个很不错的对抗稳健性（adversarial robustness）框架，即将对抗稳健性建模成一个鞍点问题，这样就变成了一个稳健优化（robust optimization）问题。该框架是为分类任务的连续输入而提出的，但它用相当简洁的数学公式描述了双层优化过程。其目标由一个<strong>内部最大化</strong>问题和一个<strong>外部最小化</strong>问题组成：</p>
<ul>
<li>内部最大化：寻找能导致高损失的最有效的对抗数据点 𝐱+𝜹。所有对抗性攻击方法最终都可归结为如何最大化这个内部过程的损失。</li>
<li>外部最小化：寻找最佳的模型参数化方案，使得由内部最大化过程找到的最有效攻击的损失能被最小化。要训练出稳健的模型，一个简单方法是将每个数据点替换为其扰动版本，这些版本可以是一个数据点的多个对抗变体。<br>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2024/07/10/LLM-Security1/p7.png" style="zoom:45%;"></li>
</ul>
<h2 id="llm-稳健性">LLM 稳健性</h2>
<p>这里简单谈谈一些有关 LLM 稳健性的研究。</p>
<p>Xie et al. 2023 的论文《Defending ChatGPT against Jailbreak Attack via Self-Reminder》发现了一种简单直观的保护模型免受对抗攻击的方法：<strong>明确地指示模型成为负责任的模型，不要生成有害内</strong>容。这会极大降低越狱攻击的成功率，但对模型的生成质量会有副作用，这是因为这样的指示<strong>会让模型变得保守</strong>（比如不利于创意写作），或者会在某些情况下错误地解读指令（比如在安全 - 不安全分类时）。</p>
<p>目前降低恶意攻击风险最常见的方法是<strong>对抗性训练</strong>，即在攻击样本上训练模型。这种方法被认为是最有效的防御手段，但它需要在模型稳健性和性能之间做出权衡。在 Jain 等人 2023 的《Baseline Defenses for Adversarial Attacks Against Aligned Language Models》中，他们测试了两种对抗性训练方案：（1）将有害提示与 “I’m sorry. As a …” 的回应配对进行梯度下降；（2）在每个训练步骤中，对拒绝回应进行一次梯度下降，而对“红队”的不当回应进行一次梯度上升。结果显示方案（2）几乎无效，因为它严重降低了模型生成的质量，而攻击成功率却仅有少量下降。</p>
<p>白盒攻击通常会产生毫无意义的恶意提示，这些提示可以通过<strong>检查困惑度</strong>来识别。当然，白盒攻击可以通过专门优化以降低困惑度来规避这一检测，比如 UAT-LM，它是 UAT 的变体。不过，这种方法也有其权衡，可能会降低攻击的成功率。</p>
<p>Jain et al. 2023 还测试了对文本输入进行预处理的方法，使得能在移除对抗性修改的同时维持语义含义。</p>
<ul>
<li>解释含义：使用 LLM 来解释输入文本的含义，这可能会对下游任务性能造成较小影响。</li>
<li>重新 token 化：将 token 拆分开并使用多个更小的 token 来表示它们，比如使用 BPE-dropout（随机丢弃一定比例的 token）。使用这种方法的假设是对抗性 prompt 很可能会利用特定的对抗性 token 组合。这也确实有助于降低攻击成功率，但也有限，比如从 90% 以上降至 40%。</li>
</ul>
]]></content>
      <categories>
        <category>智能算法安全</category>
        <category>大模型</category>
        <category>大模型安全</category>
        <category>大模型对抗攻击</category>
      </categories>
      <tags>
        <tag>智能算法安全</tag>
        <tag>生成式人工智能</tag>
        <tag>大模型</tag>
      </tags>
  </entry>
  <entry>
    <title>思考题</title>
    <url>/2022/11/16/OS-LearningNotes5/</url>
    <content><![CDATA[<h1 id="思考题">思考题</h1>
<h2 id="为什么开始启动计算机的时候-执行的是bios代码而不是操作系统自身的代码？-p1-3">为什么开始启动计算机的时候，执行的是BIOS代码而不是操作系统自身的代码？（P1，3）</h2>
<p>加电的一瞬间，计算机内存中，准确的说是RAM中，还未初始化，没有任何程序。软盘里虽然有操作系统程序，但CPU的逻辑电路被设计为只能运行内存中的程序，没有能力直接从软盘运行操作系统。这就需要硬件主动加载0xffff0处的BIOS程序，由BIOS准备好中断向量表、中断服务程序，接着通过中断“int 0x19”将引导程序bootsect加载至内存，以及后续的一系列操作，最终操作系统自身代码才能位于内存中，被CPU执行。</p>
<p>在加电后，BIOS 需要完成一些检测工作，设置实模式下的中断向量表和服务程序，并将操作系统的引导扇区加载至 0x7C00 处，然后将跳转至 0x7C00运行操作系统自身的代码。</p>
<h2 id="为什么bios只加载了一个扇区-后续扇区却是由bootsect代码加载？为什么bios没有直接把所有需要加载的扇区都加载？-p6-7">为什么BIOS只加载了一个扇区，后续扇区却是由bootsect代码加载？为什么BIOS没有直接把所有需要加载的扇区都加载？（P6，7）</h2>
<p>BIOS和操作系统通常由不同的专业团队开发的，为了能协调工作，需要按固定的规则约定，进行灵活的各自设计相应的部分。<br>
因此，现行的方法是定位识别：对BIOS而言，“约定”接到启动操作系统命令，“定位识别”只从启动扇区把代码加载至0x7c00(BOOTSEG)位置，至于该扇区内容是什么，一概不管。而后续扇区则由操作系统自己的bootsect代码加载，这些代码由编写系统的用户负责，与之前BIOS也无关。<br>
这样构建的好处是站在整个体系的高度，统一设计安排，简单而有效。且BIOS和操作系统的开发都可遵循这一约定，按照自己的意愿进行各自的设计，包括内存的规划等都更为灵活。</p>
<p>如果BIOS一次性加载，会存在：<br>
1）对于不同的操作系统，其代码长度不一样，可能导致操作系统加载不完全；<br>
2）使用BIOS进行加载，且加载完成之后再执行，需要很长的时间，因此Linux采用的是边执行边加载的方法。</p>
<h2 id="为什么bios把bootsect加载到0x07c00-而不是0x00000？加载后又马上挪到0x90000处-是何道理？为什么不一次加载到位？-p4-p5-17">为什么BIOS把bootsect加载到0x07c00，而不是0x00000？加载后又马上挪到0x90000处，是何道理？为什么不一次加载到位？(P4、P5-17)</h2>
<p>1）0x07c00是历史约定。<br>
2）BIOS在从0x00000开始的1KB字节构建了中断向量表，接着的256KB字节内存空间构建了BIOS数据区，这些数据还有用处，所以不能把bootsect加载到0x00000。 0X07c00是BIOS设置的内存地址，不是bootsect能够决定的。<br>
3）挪到0x90000处是操作系统内存规划行为，主要为了避免在内核system占据0x000000处时可能将0x07c00(bootsect)覆盖，造成在main中设置根设备时取不到正确数据。将该扇区挪到0x90000，在setup.s中，获取一些硬件数据保存在0x90000~0x901ff处，可以对一些后面内核将要利用的数据，集中保存和管理。</p>
<h2 id="bootsect-setup-head程序之间是怎么衔接的？给出代码证据-p16-p24-p25-p26">bootsect、setup、head程序之间是怎么衔接的？给出代码证据。（P16、P24+P25+P26）</h2>
<p>1）bootsect跳转至setup程序：jmpi 0, SETUPSEG;<br>
解释：通过BIOS的“int 0x13”中断，找到bootsect自身的中断服务程序，将setup加载至SETUPSEG(0x90200)处。同样手法，将system加载至SYSSEG(0x10000)处。bootsect程序任务都已经完成。然后，通过“jmpi 0, SETUPSEG”跳转至setup程序的加载位置，此时CS:IP指向setup程序的第一条指令，意味着现在由setup程序接着bootsect程序继续执行。此时还是实模式。<br>
2）setup跳转至head程序：jmpi 0, 8<br>
解释：setup通过BIOS提供的中断服务程序提取了系统数据，存储在原来的bootsect位置只保留最后2字节未被覆盖（0x901fc，根设备号）。接着，将IF至0，完成关中断操作。然后，将system移动到0x00000位置，此时head已经占据了0x00000处，同时BIOS中断向量表彻底被覆盖。为此，setup开始为保护模式做准备，设置GDT、IDT并用CPU中专用寄存器IDTR、GDTR看住。接着，打开A20，也就是32位寻址模式，再对可编程中断控制器8259A进行重新编程，并置PE位为1，即设定处理器工作方式为保护模式，以后根据GDT决定执行哪里的程序。最后，通过“jmpi 0,8”跳转到head。“0”表示段内偏移，“8(1000)”是保护模式下的段选择符，最后两位“00”表示内核态，第二位“0”表示GDT，第一位“1”表示GDT表中GDT[1]项（内核代码段），从该项中得知段基址为0x00000000。结合上述偏移0，可知最终跳转至0x0000000处，执行head程序。</p>
<h2 id="setup程序的最后是jmpi-0-8-为什么这个8不能简单的当作阿拉伯数字8看待-究竟有什么内涵？-p25">setup程序的最后是jmpi 0,8 ，为什么这个8不能简单的当作阿拉伯数字8看待，究竟有什么内涵？(P25)</h2>
<p>此时为32位保护模式，0表示段内偏移，8表示段选择符，转化为二进制：1000。<br>
最后两位00表示内核特权级，第三位0表示GDT表，第四位1表示所选的表（在此就是GDT表）的1项来确定代码段的段基址和段限长等信息。<br>
这样可以得到代码是从段基址0x00000000、偏移为0处开始执行的，即head的开始位置。</p>
<blockquote>
<p>补充：</p>
<ul>
<li>最后两位表示特权，其中00是内核，11是用户。</li>
<li>倒数第3位如果是0表示GDT，1则表示LDT。</li>
<li>前两位表示这个表的第几项。GDT表的0表示空，1表示内核代码段，2表示内核数据段。LDT表的0表示空，1表示用户代码段，2表示用户数据段。</li>
</ul>
</blockquote>
<h2 id="保护模式在-保护-什么？它的-保护-体现在哪里？特权级的目的和意义是什么？分页有-保护-作用吗？-p436-p439-p443">保护模式在“保护”什么？它的“保护”体现在哪里？特权级的目的和意义是什么？分页有“保护”作用吗？(P436-P439、P443)</h2>
<p>1）打开了保护模式后，CPU的寻址模式发生了变化，需要依赖于GDT去获取代码或数据段的基址。从GDT可以看出，保护模式除了段基址外，还有段限长，这样相当于增加了一个段位寄存器。既有效地防止了对代码或数据段的覆盖，又防止了代码段自身的访问超限，明显增强了保护作用。<br>
2）体现：①在GDT、LDT及IDT中，均有自己界限特、权级等属性，这是对描述符所描述的对象的保护；②在不同特权级间访问时，系统会对CPL、RPL、DPL、IOPL 等进行检验，对不同层级的程序进行保护，同还限制某些特殊指令的使用，如 lgdt, lidt,cli等。<br>
3）特权级的目的和意义：①为了更好的管理资源并保护系统不受侵害，操作系统利用先机，以时间换取特权，先霸占所有特权；②依托CPU提供的保护模式，着眼于“段”，在所有的段选择符最后两位标示特权级，禁止用户执行cli、sti等对掌控局面至关重要的指令。③操作系统可以把内核设计成最高特权级，把用户进程设计成最低特权级。这样，操作系统可以访问 GDT、LDT、TR，而 GDT、LDT是逻辑地址形成线性地址的关键，因此操作系统可以掌控线性地址。物理地址是由内核将线性地址转换而成的，所以操作系统可以访问任何物理地址，而用户进程只能使用逻辑地址。<br>
4）①分页机制中PDE和PTE中的R/W和U/S等，提供了页级保护；②分页机制将线性地址与物理地址加以映射，提供了对物理地址的保护。<br>
补充：为什么特权级是基于段的?<br>
在操作系统设计中，一般一个段实现的功能相对完整，可以把代码放在一个段，数据放在一个段，并通过段选择符（包括CS、SS、DS、ES、FS和GS）获取段的基址和特权级等信息。特权级基于段，这样当段选择子具有不匹配的特权级时，按照特权级规则判断是否可以访问。特权级基于段，是结合了程序的特点和硬件实现的一种考虑。</p>
<h2 id="在setup程序里曾经设置过gdt-为什么在head程序中将其废弃-又重新设置了一个？为什么设置两次-而不是一次搞好？-p33">在setup程序里曾经设置过gdt，为什么在head程序中将其废弃，又重新设置了一个？为什么设置两次，而不是一次搞好？(P33)</h2>
<p>原来GDT所在的位置是设计代码时在setup.s里面设置的数据，将来这个setup模块所在的内存位置会在设计缓冲区时被覆盖。如果不改变位置，将来GDT的内容肯定会被缓冲区覆盖掉，从而影响系统的运行。这样一来，将来整个内存空间中唯一安全的地方就是现在head.s所在的位置了。<br>
不能在执行setup程序时直接把GDT的内容复制到head.s所在位置：如果先复制GDT内容，后移动system模块，它就会被后者覆盖；如果先移动system模块，后复制GDT内容，它又会把head.s对应的程序覆盖，而这时head.s还没有执行。所以无论如何都要重新建立GDT。</p>
<h2 id="进程0的task-struct在哪？具体内容是什么？-p70">进程0的task_struct在哪？具体内容是什么？(P70)</h2>
<p>进程0的task_struct、内核栈、用户栈都在内核数据段。<br>
进程0的task_struct 的具体内容包括状态、信号、pid、alarm、ldt、tss等管理该进程所需的数据。如下代码所示：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 进程0的task_struct</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INIT_TASK \</span></span><br><span class="line"><span class="comment">/* state etc */</span>	&#123; <span class="number">0</span>,<span class="number">15</span>,<span class="number">15</span>, \</span><br><span class="line"><span class="comment">/* signals */</span>	<span class="number">0</span>,&#123;&#123;&#125;,&#125;,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* ec,brk... */</span>	<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* pid etc.. */</span>	<span class="number">0</span>,<span class="number">-1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* uid etc */</span>	<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* alarm */</span>	<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* math */</span>	<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* fs info */</span>	<span class="number">-1</span>,<span class="number">0022</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="literal">NULL</span>,<span class="number">0</span>, \</span><br><span class="line"><span class="comment">/* filp */</span>	&#123;<span class="literal">NULL</span>,&#125;, \</span><br><span class="line">	&#123; \</span><br><span class="line">		&#123;<span class="number">0</span>,<span class="number">0</span>&#125;, \</span><br><span class="line"><span class="comment">/* ldt */</span>	&#123;<span class="number">0x9f</span>,<span class="number">0xc0fa00</span>&#125;, \</span><br><span class="line">		&#123;<span class="number">0x9f</span>,<span class="number">0xc0f200</span>&#125;, \</span><br><span class="line">	&#125;, \</span><br><span class="line"><span class="comment">/*tss*/</span>	&#123;<span class="number">0</span>,PAGE_SIZE+(<span class="keyword">long</span>)&amp;init_task,<span class="number">0x10</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,(<span class="keyword">long</span>)&amp;pg_dir,\</span><br><span class="line">	 <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \</span><br><span class="line">	 <span class="number">0</span>,<span class="number">0</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>, \</span><br><span class="line">	 _LDT(<span class="number">0</span>),<span class="number">0x80000000</span>, \</span><br><span class="line">		&#123;&#125; \</span><br><span class="line">	&#125;, \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以下代码说明user_stack在内核数据段。（0x10）（参考杨炯的内核代码完全注释）一个任务的数据结构与其内核态堆栈是放在同一内存页中。所以进程0的内核栈是跟着task struct后面的，所以进程0的内核栈不是user_stack，user_stack是进程0的用户栈。（P91的图）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">long</span> user_stack [ PAGE_SIZE&gt;&gt;<span class="number">2</span> ] ;<span class="comment">//定义用户堆栈4K，指针指向最后一项</span></span><br><span class="line"><span class="comment">//该结构用于设置堆栈ss：esp（数据段选择符）</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">	<span class="keyword">long</span> * a;</span><br><span class="line">	<span class="keyword">short</span> b;</span><br><span class="line">	&#125; stack_start = &#123; &amp; user_stack [PAGE_SIZE&gt;&gt;<span class="number">2</span>] , <span class="number">0x10</span> &#125;;<span class="comment">//内核数据段</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//每个进程在内核态运行时都有自己的内核态堆栈，这里定义了内核态堆栈的结构</span></span><br><span class="line"><span class="class"><span class="keyword">union</span> <span class="title">task_union</span> &#123;</span></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> <span class="title">task</span>;</span></span><br><span class="line">	<span class="keyword">char</span> <span class="built_in">stack</span>[PAGE_SIZE];</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">union</span> <span class="title">task_union</span> <span class="title">init_task</span> =</span> &#123;INIT_TASK,&#125;;</span><br></pre></td></tr></table></figure>
<h2 id="内核的线性地址空间是如何分页的？-p37-38-画出从0x000000开始的7个页-包括页目录表-页表所在页-的挂接关系图-就是页目录表的前四个页目录项-第一个个页表的前7个页表项指向什么位置？-p39-给出代码证据-p39">内核的线性地址空间是如何分页的？（P37-38）画出从0x000000开始的7个页（包括页目录表、页表所在页）的挂接关系图，就是页目录表的前四个页目录项、第一个个页表的前7个页表项指向什么位置？（P39）给出代码证据。（P39）</h2>
<p>1）head.s在setup_paging开始创建分页机制。将页目录表和4个页表放到物理内存的起始位置，从内存起始位置开始的5个页空间内容全部清零（每页4kb），然后设置页目录表的前4项，使之分别指向4个页表。然后开始从高地址向低地址方向填写4个页表，依次指向内存从高地址向低地址方向的各个页面。即将第4个页表的最后一项（pg3+4092指向的位置）指向寻址范围的最后一个页面。即从0xFFF000开始的4kb 大小的内存空间。将第4个页表的倒数第二个页表项（pg3-4+4092）指向倒数第二个页面，即0xFFF000-0x1000开始的4KB字节的内存空间，依此类推。<br>
2）图见P39</p>
<img src= "data:image/gif;base64,R0lGODdhAQABAPAAAMPDwwAAACwAAAAAAQABAAACAkQBADs=" data-lazy-src="/2022/11/16/OS-LearningNotes5/p1.png" class title="p1">
<p>3）Head.s中：（P39）\</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">setup_paging: </span><br><span class="line">movl $1024*5,%ecx  &#x2F;* 5 pages - pg_dir+4 page tables *&#x2F; </span><br><span class="line">xorl %eax,%eax </span><br><span class="line">xorl %edi,%edi  &#x2F;* pg_dir is at 0x000 *&#x2F; </span><br><span class="line">cld;rep;stosl</span><br><span class="line"> movl $pg0+7,pg_dir  &#x2F;* set present bit&#x2F;user r&#x2F;w *&#x2F;  </span><br><span class="line">movl $pg1+7,pg_dir+4  &#x2F;*  --------- &quot; &quot; --------- *&#x2F; </span><br><span class="line">movl $pg2+7,pg_dir+8  &#x2F;*  --------- &quot; &quot; --------- *&#x2F;  </span><br><span class="line">movl $pg3+7,pg_dir+12  &#x2F;*  --------- &quot; &quot; --------- *&#x2F; </span><br><span class="line">_pg_dir用于表示内核分页机制完成后的内核起始位置，也就是物理内存的起始位置0x000000，以上四句完成页目录表的前四项与页表1，2,3,4的挂接 </span><br><span class="line">movl $pg3+4092,%edi </span><br><span class="line">movl $0xfff007,%eax  &#x2F;*  16Mb - 4096 + 7 (r&#x2F;w user,p) *&#x2F; </span><br><span class="line">std </span><br><span class="line">1: 	stosl   &#x2F;* fill pages backwards - more efficient :-) *&#x2F; </span><br><span class="line">subl $0x1000,%eax</span><br><span class="line">	jge 1b</span><br><span class="line">	xorl %eax,%eax		&#x2F;* pg_dir is at 0x0000 *&#x2F;</span><br><span class="line">	movl %eax,%cr3		&#x2F;* cr3 - page directory start *&#x2F;</span><br><span class="line">	movl %cr0,%eax</span><br><span class="line">	orl $0x80000000,%eax</span><br><span class="line">	movl %eax,%cr0		&#x2F;* set paging (PG) bit *&#x2F;</span><br><span class="line">	ret			&#x2F;* this also flushes prefetch-queue *&#x2F;</span><br></pre></td></tr></table></figure>
<p>完成页表项与页面的挂接，是从高地址向低地址方向完成挂接的，16M内存全部完成挂接（注意页表从0开始，页表0-页表3）</p>
<h2 id="在head程序执行结束的时候-在idt的前面有184个字节的head程序的剩余代码-剩余了什么？为什么要剩余？-p31-p36-p40">在head程序执行结束的时候，在idt的前面有184个字节的head程序的剩余代码，剩余了什么？为什么要剩余？(P31、P36、P40)</h2>
<p>1）剩余的内容：0x5400~0x54b7处，包含代码段：after_page_tables(栈中压入了些参数)、 ignore_int(初始化中断时的中断处理函数) 和 setup_paging(初始化分页)。<br>
2）原因：after_page_tables中压入了一些参数，为内核进入main函数的跳转做准备。为了谨慎起见，设计者在栈中压入了L6，以使得系统可能出错时，返回到L6处执行。ignore_int: 使用 ignore_int将 idt全部初始化，因此如果中断开启后，可能使用了未设置的中断向量，那么将默认跳转到 ignore_int处执行。这样做的好处是使得系统不会跳转到随机的地方执行错误的代码，所以ignore_int不能被覆盖。 setup_paging:为设置分页机制的代码，它在分页完成前不能被覆盖。</p>
<h2 id="为什么不用call-而是用ret-调用-main函数？画出调用路线图-给出代码证据-p42">为什么不用call，而是用ret“调用”main函数？画出调用路线图，给出代码证据。(P42)</h2>
<p>call指令会将EIP的值自动压栈，保护返回现场，然后执行被调函数的程序，等到执行被调函数的ret指令时，自动出栈给EIP并还原现场，继续执行call的下一条指令。然而对操作系统的main函数来说，如果用call调用main函数，那么ret时返回给谁呢？因为没有更底层的函数程序接收操作系统的返回。用ret实现的调用操作当然就不需要返回了，call做的压栈和跳转动作需要手工编写代码。<br>
2）图在p42仿call示意图下面部分</p>
<p>3）代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">after_page_tables:</span><br><span class="line">	pushl $0		# These are the parameters to main :-)</span><br><span class="line">	pushl $0</span><br><span class="line">	pushl $0</span><br><span class="line">	pushl $L6		# return address for main, if it decides to.</span><br><span class="line">   	pushl $__main; &#x2F;&#x2F;将main的地址压入栈，即EIP</span><br><span class="line">jmp setup_paging</span><br><span class="line">setup_paging:</span><br><span class="line">   	ret; &#x2F;&#x2F;弹出EIP，针对EIP指向的值继续执行，即main函数的入口地址。</span><br></pre></td></tr></table></figure>
<h2 id="用文字和图说明中断描述符表是如何初始化的-可以举例说明-比如：set-trap-gate-0-divide-error-并给出代码证据-p52">用文字和图说明中断描述符表是如何初始化的，可以举例说明（比如：set_trap_gate(0,&amp;divide_error)），并给出代码证据。（P52）</h2>
<p>对中断描述符表的初始化，就是将中断、异常处理的服务程序与IDT进行挂接，逐步重建中断服务体系。<br>
（先画图见P54 图2-9然后解释）<br>
以set_trap_gate(0,&amp;divide_error)//除零错误 为例，进行宏展开后得到：</p>
<p>其中：n是0；gate_addr是&amp;idt[0]，也就是IDT的第一项中断描述符的地址；type是15；dpl（描述符特权级）是0；addr是中断服务程序divide_error(void)的入口地址。</p>
<h2 id="在ia-32中-有大约20多个指令是只能在0特权级下使用-其他的指令-比如cli-并没有这个约定-奇怪的是-在linux0-11中-3特权级的进程代码并不能使用cli指令-这是为什么？请解释并给出代码证据-p68-p79-p92">在IA-32中，有大约20多个指令是只能在0特权级下使用，其他的指令，比如cli，并没有这个约定。奇怪的是，在Linux0.11中，3特权级的进程代码并不能使用cli指令，这是为什么？请解释并给出代码证据。(P68、P79、P92)</h2>
<p>根据IA-32手册，某些系统指令是禁止应用程序使用的。cli指令用于复位IF标志位，cli指令与CPL和EFLAGS[IOPL]有关。如果CPL的权限高于等于EFLAGS中的IOPL的权限，即数值上CPL&lt;=IOPL，则可以执行该指令，IF位清除为0。如果CPL大于当前程序或过程的IOPL，则产生保护模式异常。<br>
由于在内核中IOPL的值初始为0，且未经改变。INIT_TASK的TSS中设置了EFLAGS值，进程0又在move_to_user_mode中，继承了内核的EFLAGS。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\include\linux\sched.h</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> INIT_TASK \</span></span><br><span class="line"><span class="comment">//..</span></span><br><span class="line"><span class="comment">/*tss*/</span>	&#123;<span class="number">0</span>,PAGE_SIZE+(<span class="keyword">long</span>)&amp;init_task,<span class="number">0x10</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,(<span class="keyword">long</span>)&amp;pg_dir,\</span><br><span class="line">	 <span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>, \     <span class="comment">//eflags的值，决定了cli这类指令只能在0特权级使用</span></span><br><span class="line">	 <span class="number">0</span>,<span class="number">0</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>,<span class="number">0x17</span>, \</span><br><span class="line">	 _LDT(<span class="number">0</span>),<span class="number">0x80000000</span>, \</span><br><span class="line">		&#123;&#125; \</span><br><span class="line">	&#125;, \</span><br><span class="line">&#125;</span><br><span class="line">\linux0<span class="number">.11</span>\include\<span class="keyword">asm</span>\system.h</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> move_to_user_mode() \</span></span><br><span class="line">	......</span><br><span class="line">	<span class="string">&quot;pushfl\n\t&quot;</span> \   <span class="comment">//eflags进栈</span></span><br><span class="line">	......</span><br><span class="line">	<span class="string">&quot;iret\n&quot;</span> \</span><br><span class="line">	<span class="comment">//..</span></span><br><span class="line">	:::<span class="string">&quot;ax&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>在进程0的TSS中，设置了eflags中的IOPL位为0，代码见P68，后续进程如果没有改动的话也是0，即IOPL=0。因此，通过设置IOPL，可以限制3特权级进程代码使用cli指令。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\fork.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">copy_process</span><span class="params">(<span class="keyword">int</span> nr,<span class="keyword">long</span> ebp,<span class="keyword">long</span> edi,<span class="keyword">long</span> esi,<span class="keyword">long</span> gs,<span class="keyword">long</span> none,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">long</span> ebx,<span class="keyword">long</span> ecx,<span class="keyword">long</span> edx,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">long</span> fs,<span class="keyword">long</span> es,<span class="keyword">long</span> ds,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">long</span> eip,<span class="keyword">long</span> cs,<span class="keyword">long</span> eflags,<span class="keyword">long</span> esp,<span class="keyword">long</span> ss)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	p-&gt;tss.eip = eip;</span><br><span class="line">	p-&gt;tss.eflags = eflags;</span><br><span class="line">	p-&gt;tss.eax = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	<span class="keyword">return</span> last_pid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="在system-h里-见下-读懂代码-这里中断门-陷阱门-系统调用都是通过-set-gate设置的-用的是同一个嵌入汇编代码-比较明显的差别是dpl一个是3-另外两个是0-这是为什么？说明理由-p55">在system.h里（见下），读懂代码。这里中断门、陷阱门、系统调用都是通过_set_gate设置的，用的是同一个嵌入汇编代码，比较明显的差别是dpl一个是3，另外两个是0，这是为什么？说明理由。(P55)</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define _set_gate(gate_addr,type,dpl,addr) \</span><br><span class="line">__asm__ (&quot;movw %%dx,%%ax\n\t&quot; \</span><br><span class="line">    &quot;movw %0,%%dx\n\t&quot; \</span><br><span class="line">    &quot;movl %%eax,%1\n\t&quot; \</span><br><span class="line">    &quot;movl %%edx,%2&quot; \</span><br><span class="line">    : \</span><br><span class="line">    : &quot;i&quot; ((short) (0x8000+(dpl&lt;&lt;13)+(type&lt;&lt;8))), \</span><br><span class="line">    &quot;o&quot; (*((char *) (gate_addr))), \</span><br><span class="line">    &quot;o&quot; (*(4+(char *) (gate_addr))), \</span><br><span class="line">    &quot;d&quot; ((char *) (addr)),&quot;a&quot; (0x00080000))</span><br><span class="line">#define set_intr_gate(n,addr) \</span><br><span class="line">    _set_gate(&amp;idt[n],14,0,addr)</span><br><span class="line">#define set_trap_gate(n,addr) \</span><br><span class="line">    _set_gate(&amp;idt[n],15,0,addr)</span><br><span class="line">#define set_system_gate(n,addr) \</span><br><span class="line">    _set_gate(&amp;idt[n],15,3,addr)</span><br></pre></td></tr></table></figure>
<p>1）dpl机制：dpl表示的是特权级，0和3分别表示0特权级和3特权级。异常处理是由内核来完成，Linux处于对内核的保护，不允许用户进程直接访问内核。但是有些情况下，用户进程又需要内核代码的支持，因此就需要系统调用，它是用户进程与内核打交道的接口，是由用户进程直接调用的，因此其在3特权级下。<br>
2）题目中：set_trap_gate 和set_intr_gate的dpl是0，set_system_gate的dpl是3。dpl为0表示只能在内核态下允许，dpl为3表示系统调用可以由3特权级调用。<br>
当用户程序产生系统调用软中断后， 系统都通过system_call总入口找到具体的系统调用函数。set_system_gate设置系统调用，须将DPL设置为3，允许在用户特权级3的进程调用，否则会引发General Protection异常。set_trap_gate及set_intr_gate设置陷阱和中断为内核使用，需禁止用户进程调用，所以DPL为0。</p>
<h2 id="进程0-fork进程1之前-为什么先调用move-to-user-mode-？用的是什么方法？解释其中的道理-p78-80">进程0 fork进程1之前，为什么先调用move_to_user_mode()？用的是什么方法？解释其中的道理。（P78+80）</h2>
<p>1）因为在Linux-011中，规定除了进程0以外的所有进程，都必须在特权级为3下创建。所以进程0 fork进程1之前，要调用move_to_user_mode将0特权级翻转到3特权级。<br>
2）move_to_user_mode()用的方法是模仿中断硬件压栈，顺序是ss、esp、eflags、cs、eip。然后执行iret，出栈恢复现场，翻转0特权级到3特权级。<br>
3）CPU响应中断的时候，根据DPL的设置，可以实现指定的特权级之间的翻转。所以模拟中断硬件压栈可以实现特权级的翻转。</p>
<h2 id="在linux操作系统中大量使用了中断-异常类的处理-究竟有什么好处？-p56">在Linux操作系统中大量使用了中断、异常类的处理，究竟有什么好处？（P56）</h2>
<p>在未引入中断、异常处理类处理的概念之前，CPU每隔一段时间就要对所有硬件进行轮询，以检测它的工作是否完成，如果没有完成就继续轮询，这样消耗了CPU处理用户程序的时间，降低了系统的综合效率。可见，CPU以“主动轮询”的方式来处理信号是非常不划算的。采用了这种中断方式，以“被动响应”模式代替“主动轮询”模式来处理主机与外设的I/O问题，只有在发生异常的时候CPU才停下正在进行的运算进行处理，其他时候都在做自己的事情。这大大提高了操作系统的综合效率。是计算机历史上的一大进步。</p>
<h2 id="copy-process函数的参数最后五项是：long-eip-long-cs-long-eflags-long-esp-long-ss-查看栈结构确实有这五个参数-奇怪的是其他参数的压栈代码都能找得到-确找不到这五个参数的压栈代码-反汇编代码中也查不到-请解释原因-p89">copy_process函数的参数最后五项是：long eip,long cs,long eflags,long esp,long ss。查看栈结构确实有这五个参数，奇怪的是其他参数的压栈代码都能找得到，确找不到这五个参数的压栈代码，反汇编代码中也查不到，请解释原因。（P89）</h2>
<p>copy_process执行时因为进程调用了fork函数，fork是一个系统调用，会导致中断，int 0x80中断导致CPU硬件自动将SS、ESP、EFLAGS、CS、EIP的值按照顺序压入进程0内核栈，又因为函数专递参数是使用栈的，所以刚好可以做为copy_process的最后五项参数。</p>
<h2 id="分析get-free-page-函数的代码-叙述在主内存中获取一个空闲页的技术路线-p90">分析get_free_page()函数的代码，叙述在主内存中获取一个空闲页的技术路线。（P90）</h2>
<p>代码见P90  get_free_page函数</p>
<p>遍历mem_map[]，找到内存中（从高地址开始）第一个空闲（字节为0）页面，将其置为1。ecx左移12位加LOW_MEM得到该页的物理地址，并将页面清零。最后返回空闲页面物理内存的起始地址。<br>
即：<br>
(1)将EAX 设置为0，EDI设置指向mem_map的最后一项（mem_map+PAGING_PAGES-1），std设置扫描是从高地址向低地址。遍历mem_map[]，从mem_map的最后一项反向扫描，找出引用次数为0(AL)的页，如果没有则退出；如果找到，则将找到的页设引用数为1；<br>
(2) ECX左移12位得到页的相对地址，加LOW_MEM得到物理地址，将此页最后一个字节的地址赋值给EDI（LOW_MEM+4092）；<br>
(3) stosl将EAX的值设置到ES:EDI所指内存，即反向清零1024*32bit，将此页清空；<br>
(4) 将页的地址（存放在EAX）返回。<br>
注意!本函数只是指出在主内存区的一页空闲页面，但并没有映射到某个进程的线性地址去。后面的put_page()函数就是用来作映射的。</p>
<h2 id="分析copy-page-tables-函数的代码-叙述父进程如何为子进程复制页表-p97">分析copy_page_tables（）函数的代码，叙述父进程如何为子进程复制页表。(P97)</h2>
<p>先为新的页表申请一个空闲页面，并把进程0中第一个页表里面前160个页表项复制到这个页面中进程0和进程1页表暂时都指向了相同的页面，意味着进程1可以控制进程0的页面，之后对进程1的页目录表进行设置。最后重置CR3，刷新页变换高速缓存。设置完毕。</p>
<h2 id="进程0创建进程1时-为进程1建立了task-struct及内核栈-第一个页表-分别位于物理内存16mb顶端倒数第一页-第二页-请问-这两个页究竟占用的是谁的线性地址空间-内核-进程0-进程1-还是没有占用任何线性地址空间？说明理由-可以图示-并给出代码证据-p99">进程0创建进程1时，为进程1建立了task_struct及内核栈，第一个页表，分别位于物理内存16MB顶端倒数第一页、第二页。请问，这两个页究竟占用的是谁的线性地址空间，内核、进程0、进程1、还是没有占用任何线性地址空间？说明理由（可以图示）并给出代码证据。P99</h2>
<p>这两个页占用的是内核的线性地址空间。<br>
依据在setup_paging（文件head.s）中，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\linux0.11\boot\head.s</span><br><span class="line">setup_paging:</span><br><span class="line">	&#x2F;&#x2F;…</span><br><span class="line">	movl $pg3+4092,%edi</span><br><span class="line">	movl $0xfff007,%eax		&#x2F;*  16Mb - 4096 + 7 (r&#x2F;w user,p) *&#x2F;</span><br><span class="line">	std</span><br><span class="line">1:	stosl			&#x2F;* fill pages backwards - more efficient :-) *&#x2F;</span><br><span class="line">	subl $0x1000,%eax</span><br><span class="line">	&#x2F;&#x2F;…</span><br><span class="line">上面的代码，指明了内核的线性地址空间为0x000000 ~ 0xffffff（即前16M），且线性地址与物理地址呈现一一对应的关系。</span><br><span class="line">进程0的局部描述符如下include&#x2F;linux&#x2F;sched.h&#x2F;INIT_TASK：</span><br><span class="line">&#x2F;*ldt*&#x2F; </span><br><span class="line">&#123;0x9f,0xc0fa00&#125;.\</span><br><span class="line">&#123;0x9f,0xc0f200&#125;,\</span><br></pre></td></tr></table></figure>
<p>为进程1分配的这两个页，在16MB的顶端倒数第一页、第二页，因此占用内核的线性地址空间。进程0的线性地址空间是内存前640KB，因为进程0的LDT中的limit属性限制了进程0能够访问的地址空间。进程1拷贝了进程0的页表（160项），而这160个页表项即为内核第一个页表的前160项，指向的是物理内存前640KB，因此无法访问到16MB的顶端倒数的两个页。</p>
<h2 id="假设：经过一段时间的运行-操作系统中已经有5个进程在运行-且内核分别为进程4-进程5分别创建了第一个页表-这两个页表在谁的线性地址空间？用图表示这两个页表在线性地址空间和物理地址空间的映射关系-p266-p270">假设：经过一段时间的运行，操作系统中已经有5个进程在运行，且内核分别为进程4、进程5分别创建了第一个页表，这两个页表在谁的线性地址空间？用图表示这两个页表在线性地址空间和物理地址空间的映射关系。(P266、P270)</h2>
<p>这两个页面均占用内核的线性地址空间。既然是内核线性地址空间，则与物理地址空间为一一对应关系。根据每个进程占用16个页目录表项，则进程4占用从第65～81项（即64-80项）的页目录表项。同理，进程5占用第81～96项（即80-95项）的页目录表项。由于目前只分配了一个页面（用做进程的第一个页表），则分别只需要使用第一个页目录表项即可。</p>
<h2 id="下面代码中的-ljmp-0-n-t-很奇怪-按理说jmp指令跳转到得位置应该是一条指令的地址-可是这行代码却跳到了-m-tmp-a-这明明是一个数据的地址-更奇怪的-这行代码竟然能正确执行-请论述其中的道理-p107">下面代码中的&quot;ljmp %0\n\t&quot; 很奇怪，按理说jmp指令跳转到得位置应该是一条指令的地址，可是这行代码却跳到了&quot;m&quot; (*&amp;__tmp.a)，这明明是一个数据的地址，更奇怪的，这行代码竟然能正确执行。请论述其中的道理。P107</h2>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#define switch_to(n) &#123;\</span><br><span class="line">struct &#123;long a,b;&#125; __tmp; \</span><br><span class="line">__asm__(&quot;cmpl %%ecx,_current\n\t&quot; \</span><br><span class="line">    &quot;je 1f\n\t&quot; \</span><br><span class="line">    &quot;movw %%dx,%1\n\t&quot; \</span><br><span class="line">    &quot;xchgl %%ecx,_current\n\t&quot; \</span><br><span class="line">    &quot;ljmp %0\n\t&quot; \</span><br><span class="line">    &quot;cmpl %%ecx,_last_task_used_math\n\t&quot; \</span><br><span class="line">    &quot;jne 1f\n\t&quot; \</span><br><span class="line">    &quot;clts\n&quot; \</span><br><span class="line">    &quot;1:&quot; \</span><br><span class="line">    ::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \</span><br><span class="line">    &quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>a对应EIP、b对应CS，ljmp通过CPU中的电路进行硬件切换，进程由当前进程切换到进程n。CPU将当前寄存器的值保存到当前进程的TSS中，将进程n的TSS数据和LDT的代码段和数据段描述符恢复给CPU的各个寄存器，实现任务切换。</p>
<p>进程0-&gt;1：ljmp %0\n\t通过任务门机制并未实际使用任务门，将CPU的各个寄存器值保存在进程0的TSS中，将进程1的TSS数据以LDT的代码段、数据段描述符数据恢复给CPU的各个寄存器，实现从0特权级的内核代码切换到3特权级的进程1代码执行。其中tss.eip也自然恢复给了CPU，此时EIP指向的就是fork中的if(__res &gt;= 0)语句。</p>
<h2 id="进程0开始创建进程1-调用fork-跟踪代码时我们发现-fork代码执行了两次-第一次-执行fork代码后-跳过init-直接执行了for-pause-第二次执行fork代码后-执行了init-奇怪的是-我们在代码中并没有看到向转向fork的goto语句-也没有看到循环语句-是什么原因导致fork反复执行？请说明理由-可以图示-并给出代码证据-p107">进程0开始创建进程1，调用fork（），跟踪代码时我们发现，fork代码执行了两次，第一次，执行fork代码后，跳过init（）直接执行了for(;;) pause()，第二次执行fork代码后，执行了init（）。奇怪的是，我们在代码中并没有看到向转向fork的goto语句，也没有看到循环语句，是什么原因导致fork反复执行？请说明理由（可以图示），并给出代码证据。P107</h2>
<p>首先在copy_process()函数中，设置TSS“p-&gt;tss.eip = eip;”指向的是if (__res &gt;= 0); 而“p-&gt;tss.eax = 0;”决定main()中if (!fork())后面的分支走向。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\fork.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">copy_process</span><span class="params">(<span class="keyword">int</span> nr,<span class="keyword">long</span> ebp,<span class="keyword">long</span> edi,<span class="keyword">long</span> esi,<span class="keyword">long</span> gs,<span class="keyword">long</span> none,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">long</span> ebx,<span class="keyword">long</span> ecx,<span class="keyword">long</span> edx,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">long</span> fs,<span class="keyword">long</span> es,<span class="keyword">long</span> ds,</span></span></span><br><span class="line"><span class="function"><span class="params">		<span class="keyword">long</span> eip,<span class="keyword">long</span> cs,<span class="keyword">long</span> eflags,<span class="keyword">long</span> esp,<span class="keyword">long</span> ss)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	*p = *current;	<span class="comment">/* NOTE! this doesn&#x27;t copy the supervisor stack */</span></span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	p-&gt;start_time = jiffies;</span><br><span class="line">	p-&gt;tss.back_link = <span class="number">0</span>;</span><br><span class="line">	p-&gt;tss.esp0 = PAGE_SIZE + (<span class="keyword">long</span>) p;</span><br><span class="line">	p-&gt;tss.ss0 = <span class="number">0x10</span>;</span><br><span class="line">	p-&gt;tss.eip = eip;</span><br><span class="line">	p-&gt;tss.eflags = eflags;</span><br><span class="line">	p-&gt;tss.eax = <span class="number">0</span>;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	<span class="keyword">return</span> last_pid;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着，copy_process()函数返回后，通过“pushl %eax”将函数返回值，也就是进程1的进程号压栈。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\system_call.s</span><br><span class="line">_system_call:</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	call _sys_call_table(,%eax,<span class="number">4</span>)</span><br><span class="line">	pushl %eax</span><br></pre></td></tr></table></figure>
<p>“: “=a” (__res) \”将eax的值赋值给__res，所以“if (__res &gt;= 0) \”实际上是看此时的eax时多少，由上可知，eax＝1。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\init\main.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _syscall0(type,name) \</span></span><br><span class="line">type name(void) \</span><br><span class="line">&#123; \</span><br><span class="line"><span class="keyword">long</span> __res; \</span><br><span class="line"><span class="function">__asm__ <span class="title">volatile</span> <span class="params">(<span class="string">&quot;int $0x80&quot;</span> \</span></span></span><br><span class="line"><span class="function"><span class="params">	: <span class="string">&quot;=a&quot;</span> (__res) \</span></span></span><br><span class="line"><span class="function"><span class="params">	: <span class="string">&quot;0&quot;</span> (__NR_##name))</span></span>; \</span><br><span class="line"><span class="keyword">if</span> (__res &gt;= <span class="number">0</span>) \</span><br><span class="line">	<span class="keyword">return</span> (type) __res; \</span><br><span class="line">errno = -__res; \</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>; \</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到if (!fork())处执行，!1为“假”，不会执行init()，直接执行“for(;; ) pause();”。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\sched.c</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span>		<span class="comment">/* This really IS void, no error here. */</span></span></span><br><span class="line"><span class="function"></span>&#123;			<span class="comment">/* The startup routine assumes (well, ...) this */</span></span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	move_to_user_mode();</span><br><span class="line">	<span class="keyword">if</span> (!fork()) &#123;		<span class="comment">/* we count on this going ok */</span></span><br><span class="line">		init();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span>(;;) pause();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由pause()函数进入“schedule();”开始调度，然后通过“switch_to(next);”准备切换进程。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\sched.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sys_pause</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	current-&gt;state = TASK_INTERRUPTIBLE;</span><br><span class="line">	schedule();</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\sched.c</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">schedule</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	switch_to(next);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行switch_to()函数中，当程序执行到“ljmp %0\n\t”这行时，ljmp通过CPU任务门机制自动将进程1的TSS值恢复给CPU，自然也将其中的tss.eip恢复给CPU，这时EIP指向fork的if(__res &gt;= 0)这行。而此时的__res值就是进程1中TSS的eax的值，这个值在前面被写死为0，即“p-&gt;tss.eax = 0;”所以执行到“return (type)__res;”这行时，返回值为0。返回后，执行到if(!fork())这一行，!0为“真”，调用init()函数！</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\fs\buffer.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> switch_to(n) &#123;\</span></span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	<span class="string">&quot;ljmp %0\n\t&quot;</span> \</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>总结：主要是利用两个系统调用sys_fork和sys_pause对进程状态的设置，以及利用了进程调度机制。</p>
<h2 id="打开保护模式-分页后-线性地址到物理地址是如何转换的？p97">打开保护模式、分页后，线性地址到物理地址是如何转换的？P97</h2>
<p>打开保护模式、分页后，线性地址需要通过MMU进行解析，以页目录表、页表、页面三级映射模式映射到物理地址。具体转换过程是这样的：“每个线性地址值是32位，MMU按照10-10-12的长度来识别地址值，分别解析为页目录项号、页表项号、页面内偏移。CR3中存放着页目录表的基址，通过CR3找到页目录表，再找到页目录项，进而找到对应页表，寻取页表项，然后找到页面物理地址，最后加上12位页内偏移形成的地址，才为最终物理地址”。<br>
总结：CR3-&gt;页目录表-&gt;页目录项-&gt;页表-&gt;页表项-&gt;页面-&gt;物理地址</p>
<h2 id="getblk函数中-申请空闲缓冲块的标准就是b-count为0-而申请到之后-为什么在wait-on-buffer-bh-后又执行if-bh-b-count-来判断b-count是否为0？p115">getblk函数中，申请空闲缓冲块的标准就是b_count为0，而申请到之后，为什么在wait_on_buffer(bh)后又执行if（bh-&gt;b_count）来判断b_count是否为0？P115</h2>
<p>字段b_count：用来标记“每个缓冲块有多少个进程在共享”。只有当b_count=0时，该缓冲块才能被再次分配。<br>
举个引发异常例子：每个缓冲块有一个进程等待队列，假设此时B、C两进程在队列中，当该缓冲块被解锁时，进程C被唤醒（它开始使用缓冲区之前需先唤醒进程B，使进程B从挂起进入就绪状态），将缓冲区加锁，一段时间后，进程C又被挂起，但此时缓冲区进程C仍在使用。这时候，进程B被调度，“if (bh-&gt;b_count)”该缓冲区任是加锁状态，进程B重新选择缓冲区…如果不执行该判断，将造成进程B操作一个被加锁的缓冲区，引发异常。<br>
总结：等待缓冲区解锁这段时间，缓冲块可能会被别的进程占用，因此需要再次判断一下b_count是否为0，如果不为0，则还得继续等。</p>
<h2 id="b-dirt已经被置为1的缓冲块-同步前能够被进程继续读-写？给出代码证据-p331">b_dirt已经被置为1的缓冲块，同步前能够被进程继续读、写？给出代码证据。(P331)</h2>
<p>同步前可以被进程读写，但不能挪为它用（即关联其它物理块）。b_dirt是针对硬盘方向的，进程与缓冲块方向由b_uptodate标识。只要b_uptodate为1，缓冲块就能被进程读写。读操作不会改变缓冲块中数据的内容，写操作后，改变了缓冲区内容，需要将b_dirt置1。由于此前缓冲块中的数据已经用硬盘数据块更新了，所以后续同步过程中缓冲块没有写入新数据的部分和原来硬盘对应的部分相同，所有的数据都是进程希望同步到硬盘数据块上的，不会把垃圾数据同步到硬盘数据库上去，所以b_uptodate仍为1。<br>
所以，b_dirt为1，进程仍能对缓冲区进行读写。</p>
<p>1）读写文件均与b_dirt无关：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\fs\file_dev.c</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">file_write</span><span class="params">(struct m_inode * inode, struct file * filp, <span class="keyword">char</span> * buf, <span class="keyword">int</span> count)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	<span class="keyword">if</span> (filp-&gt;f_flags &amp; O_APPEND)</span><br><span class="line">		pos = inode-&gt;i_size;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		pos = filp-&gt;f_pos;</span><br><span class="line">	<span class="keyword">while</span> (i&lt;count) &#123;</span><br><span class="line">		<span class="keyword">if</span> (!(block = create_block(inode,pos/BLOCK_SIZE)))</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">if</span> (!(bh=bread(inode-&gt;i_dev,block)))</span><br><span class="line">			<span class="keyword">break</span>;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">file_read</span><span class="params">(struct m_inode * inode, struct file * filp, <span class="keyword">char</span> * buf, <span class="keyword">int</span> count)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	<span class="keyword">if</span> ((left=count)&lt;=<span class="number">0</span>)</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">while</span> (left) &#123;</span><br><span class="line">		<span class="keyword">if</span> (nr = bmap(inode,(filp-&gt;f_pos)/BLOCK_SIZE)) &#123;</span><br><span class="line">			<span class="keyword">if</span> (!(bh=bread(inode-&gt;i_dev,nr)))</span><br><span class="line">				<span class="keyword">break</span>;</span><br><span class="line">		&#125; </span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2）在获取缓冲块时，亦与b_dirt无任何关系：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\fs\buffer.c</span><br><span class="line"><span class="function">struct buffer_head * <span class="title">bread</span><span class="params">(<span class="keyword">int</span> dev,<span class="keyword">int</span> block)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">buffer_head</span> * <span class="title">bh</span>;</span></span><br><span class="line">	<span class="keyword">if</span> (!(bh=getblk(dev,block)))</span><br><span class="line">		panic(<span class="string">&quot;bread: getblk returned NULL\n&quot;</span>);</span><br><span class="line">	<span class="keyword">if</span> (bh-&gt;b_uptodate)</span><br><span class="line">		<span class="keyword">return</span> bh;</span><br><span class="line">	ll_rw_block(READ,bh);</span><br><span class="line">	wait_on_buffer(bh);</span><br><span class="line">	<span class="keyword">if</span> (bh-&gt;b_uptodate)</span><br><span class="line">		<span class="keyword">return</span> bh;</span><br><span class="line">	brelse(bh);</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\fs\buffer.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BADNESS(bh) (((bh)-&gt;b_dirt<span class="meta-string">&lt;&lt;1)+(bh)-&gt;b_lock)</span></span></span><br><span class="line"><span class="function">struct buffer_head * <span class="title">getblk</span><span class="params">(<span class="keyword">int</span> dev,<span class="keyword">int</span> block)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">buffer_head</span> * <span class="title">tmp</span>, * <span class="title">bh</span>;</span></span><br><span class="line"></span><br><span class="line">repeat:</span><br><span class="line">	<span class="keyword">if</span> (bh = get_hash_table(dev,block))</span><br><span class="line">		<span class="keyword">return</span> bh;</span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="分析panic函数的源代码-根据你学过的操作系统知识-完整-准确的判断panic函数所起的作用-假如操作系统设计为支持内核进程-始终运行在0特权级的进程-你将如何改进panic函数？">分析panic函数的源代码，根据你学过的操作系统知识，完整、准确的判断panic函数所起的作用。假如操作系统设计为支持内核进程（始终运行在0特权级的进程），你将如何改进panic函数？</h2>
<p>1）panic函数是当系统发现无法继续运行下去的故障时调用它，会导致程序终止，由系统显示错误号。如果出现错误的函数不是进程0，则进行数据同步，把缓冲区的数据尽量同步到硬盘上去。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\panic.c</span><br><span class="line"><span class="function"><span class="keyword">volatile</span> <span class="keyword">void</span> <span class="title">panic</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> * s)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	printk(<span class="string">&quot;Kernel panic: %s\n\r&quot;</span>,s);</span><br><span class="line">	<span class="keyword">if</span> (current == task[<span class="number">0</span>])</span><br><span class="line">		printk(<span class="string">&quot;In swapper task - not syncing\n\r&quot;</span>);</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		sys_sync();</span><br><span class="line">	<span class="keyword">for</span>(;;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>panic()函数的执行分为两种情况，如果是0进程调用了panic（）说明在创建进程1过程中出现了严重错误不可继续执行（copy_page_table()中from没有按照4M对齐）且此时不涉及与硬盘中数据的交互，所以这时直接让系统执行死循环for（；；），且这个时候系统中也不存在可调度的进程，整个电脑死机。如果是其他进程调用了panic（）则说明是某个用户进程出现严重错误，这个过程中可能涉及缓冲区数据没有写回硬盘的情况，所以在死循环之前，需要将缓冲区中为写回的数据写回硬盘，保证程序执行后硬盘中数据的一致性，所以需要调用sys_sync()写回数据，而且这个时候系统也能够完成次工作。<br>
2）改进：将死循环改成跳到的内核进程（始终运行在0特权级的进程），让内核继续执行。</p>
<h2 id="详细分析进程调度的全过程-考虑所有可能-signal-alarm除外-p105">详细分析进程调度的全过程。考虑所有可能（signal、alarm除外）P105</h2>
<p>首先依据task[64]这个结构，从后往前遍历，寻找进程状态为“就绪态”且时间片最大的进程作为下一个要执行的进程。通过调用switch_to函数跳转到指定进程。在此过程中，如果发现存在状态为就绪态的进程，但没有时间片，则从后往前重新分配时间片。然后重新执行上述过程。寻找状态为就绪态，时间片最大的进程作为下一个要执行的进程。如果没有就绪态，就跳转到进程0。</p>
<p>答2（具体）：<br>
schedule()函数的主要过程为，首先依据task[64]这个结构，第一次遍历所有进程，只要地址指针不为空，就要针对它的signal、alarm分析，这里先不考虑。第二次遍历所有进程，比较进程的状态和时间片，找出处在就绪态且counter最大的进程。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\kernel\sched.<span class="function">cvoid <span class="title">schedule</span><span class="params">(<span class="keyword">void</span>)</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i,next,c;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">task_struct</span> ** <span class="title">p</span>;</span><span class="comment">/* check alarm, wake up any interruptible tasks that have got a signal */</span></span><br><span class="line">	<span class="keyword">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line">		<span class="keyword">if</span> (*p) &#123;</span><br><span class="line">			<span class="keyword">if</span> ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123;</span><br><span class="line">					(*p)-&gt;signal |= (<span class="number">1</span>&lt;&lt;(SIGALRM<span class="number">-1</span>));</span><br><span class="line">					(*p)-&gt;alarm = <span class="number">0</span>;</span><br><span class="line">				&#125;</span><br><span class="line">			<span class="keyword">if</span> (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp;</span><br><span class="line">			(*p)-&gt;state==TASK_INTERRUPTIBLE)</span><br><span class="line">				(*p)-&gt;state=TASK_RUNNING;</span><br><span class="line">		&#125;<span class="comment">/* this is the scheduler proper: */</span></span><br><span class="line">	<span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">		c = <span class="number">-1</span>;</span><br><span class="line">		next = <span class="number">0</span>;</span><br><span class="line">		i = NR_TASKS;</span><br><span class="line">		p = &amp;task[NR_TASKS];</span><br><span class="line">		<span class="keyword">while</span> (--i) &#123;</span><br><span class="line">			<span class="keyword">if</span> (!*--p)</span><br><span class="line">				<span class="keyword">continue</span>;</span><br><span class="line">			<span class="keyword">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)</span><br><span class="line">				c = (*p)-&gt;counter, next = i;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> (c) <span class="keyword">break</span>;</span><br><span class="line">		<span class="keyword">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)</span><br><span class="line">			<span class="keyword">if</span> (*p)</span><br><span class="line">				(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; <span class="number">1</span>) +</span><br><span class="line">						(*p)-&gt;priority;</span><br><span class="line">	&#125;</span><br><span class="line">	switch_to(next);&#125;</span><br></pre></td></tr></table></figure>
<p>执行switch_to()函数中，ljmp %0\n\t通过任务门机制并未实际使用任务门，将CPU的各个寄存器值保存在进程0的TSS中，将进程1的TSS数据以LDT的代码段、数据段描述符数据恢复给CPU的各个寄存器，实现从0特权级的内核代码切换到3特权级的进程1代码执行。其中tss.eip也自然恢复给了CPU，此时EIP指向的就是fork中的if(__res &gt;= 0)语句。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\fs\buffer.c<span class="meta">#<span class="meta-keyword">define</span> switch_to(n) &#123;\</span></span><br><span class="line">	<span class="comment">//…</span></span><br><span class="line">	<span class="string">&quot;ljmp %0\n\t&quot;</span> \</span><br><span class="line">	<span class="comment">//…&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="wait-on-buffer函数中为什么不用if-而是用while-？p125">wait_on_buffer函数中为什么不用if（）而是用while（）？P125</h2>
<p>有可能很多进程都在等待一个缓冲块。在缓冲块同步完毕后，唤醒等待进程到轮转到某一进程的过程中，很有可能之前等的缓冲块被别的进程占用并加锁。如果使用if，则该进程被唤醒以后回来不会再判断缓冲块是否被占用，而直接使用就会导致出错。使用while，就会再判断一下缓冲块是否被占用，确认未被占用后使用，就不会发生之前的错误。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">\linux0<span class="number">.11</span>\fs\buffer.<span class="function">cstatic <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">wait_on_buffer</span><span class="params">(struct buffer_head * bh)</span></span>&#123;</span><br><span class="line">	cli();</span><br><span class="line">	<span class="keyword">while</span> (bh-&gt;b_lock)</span><br><span class="line">		sleep_on(&amp;bh-&gt;b_wait);</span><br><span class="line">	sti();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="操作系统如何利用b-uptodate保证缓冲块数据的正确性？new-block-int-dev-函数新申请一个缓冲块后-并没有读盘-b-uptodate却被置1-是否会引起数据混乱？详细分析理由-p325-329">操作系统如何利用b_uptodate保证缓冲块数据的正确性？new_block (int dev)函数新申请一个缓冲块后，并没有读盘，b_uptodate却被置1，是否会引起数据混乱？详细分析理由。P325+329</h2>
<p>答1：只要缓冲块的b_uptodate字段被设置为1，缓冲块的数据已经是数据块最新的，就可以放心的支持进程共享缓冲块的数据。反之，如果b_uptodate为0，就提醒内核缓冲块并没有用绑定的数据块中的数据更新，不支持进程共享该缓冲块。值得注意的是b_uptodate被设置为1，是告诉内核，缓冲块中的数据已经用数据块中的数据更新过了，但并不等于两者的数据就完全一致。<br>
如题中的，申请一个缓冲块后，并没有读盘，b_uptodate却被置1，这并不会引起数据混乱。这时因为只要为新建的数据块新申请了缓冲块，不管这个缓冲块将来用做什么，反正进程现在不需要里面的数据，干脆全部清零。这样不管与之绑定的数据块用来存储什么信息，都无所谓，将该缓冲块的b_uptodate置为1，更新问题“等效于”以解决。</p>
<p>答2：<br>
b_uptodate：是缓冲块中针对进程方向的标志位，它的作用是告诉内核，缓冲块的数据是否已是数据块中最新的。当b_update置1时，就说明缓冲块中的数据是基于硬盘数据块的，内核可以放心地支持进程与缓冲块进行数据交互；如果b_uptodate为0，就提醒内核缓冲块并没有用绑定的数据块中的数据更新，不支持进程共享该缓冲块。<br>
①当为文件创建新数据块，新建一个缓冲块时，b_uptodate被置1，但并不会引起数据混乱。此时，新建的数据块只可能有两个用途，一个是存储文件内容，一个是存储文件的i_zone的间接块管理信息。<br>
②如果是存储文件内容，由于新建数据块和新建硬盘数据块，此时都是垃圾数据，都不是硬盘所需要的，无所谓数据是否更新，结果“等效于”更新问题已经解决。<br>
③如果是存储文件的间接块管理信息，必须清零，表示没有索引间接数据块，否则垃圾数据会导致索引错误，破坏文件操作的正确性。虽然缓冲块与硬盘数据块的数据不一致，但同样将b_uptodate置1不会有问题。</p>
<h2 id="分析add-reques-函数中下列代码">分析add_reques（）函数中下列代码</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!(tmp = dev-&gt;current_request)) &#123;</span><br><span class="line">    dev-&gt;current_request = req;</span><br><span class="line">    sti();</span><br><span class="line">    (dev-&gt;request_fn)();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>其中的</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (!(tmp = dev-&gt;current_request)) &#123;</span><br><span class="line">    dev-&gt;current_request = req;</span><br></pre></td></tr></table></figure>
<p><strong>是什么意思？P121</strong><br>
查看指定设备是否有当前请求项，即查看设备是否忙。<br>
if判断首先将当前设备的请求队列的队首赋值给tmp，队列为空的情况下if条件成立，则说明当前没有需要处理的请求项（现在是第一次使用缓冲区，第一次申请空闲请求项与其挂接，当前请求项一定为空）。将当前请求项req作为请求队列的队首（dev-&gt;current_request = req;）。req是此前在make_request中申请的一个空闲请求项，与对应缓冲块挂接。（如果该设备的请求队列不为空，后面代码会将req直接挂在请求队列的队尾。）</p>
<h2 id="do-hd-request-函数中dev的含义始终一样吗？-p318">do_hd_request()函数中dev的含义始终一样吗？(P318)</h2>
<p>do_hd_request()函数主要用于处理当前硬盘请求项。但其中的dev含义并不一致。<br>
①含义1-逻辑设备号：“dev = MINOR(CURRENT-&gt;dev);”MINOR函数会取CURRENT-&gt;dev的低8位赋值给dev，低8位表示的含义是逻辑设备号。此时dev的值表示的是当前的逻辑设备号，目的是判断设备号是否合法。dev&gt;=5*NR_HD 是判断设备号是否超出了0-4或5-9的范围。block+2 &gt;hd[dev].nr_sects判断是否还有空闲盘块。<br>
②含义2-硬盘号：“dev /= 5;”dev代表硬盘号（硬盘0还是硬盘1）：改变了dev的值，若原来在0-4的范围，此时则变成了0，若原来在5-9的范围此时则变成了1。目的是为了确定是第0块还是第一块物理盘。</p>
<h2 id="read-intr-函数中-下列代码是什么意思？为什么这样做？-p323">read_intr（）函数中，下列代码是什么意思？为什么这样做？(P323)</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (--CURRENT-&gt;nr_sectors) &#123;</span><br><span class="line">    do_hd = &amp;read_intr;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于Linux0.1.1是PIO模式，PIO模式的做法是一次读一个扇区，读完以后发送中断告诉CPU当前已经读完了，此时CPU进行处理，将数据读到缓冲区。以引导块为例，需要进行两次PIO，相当于执行了两次中断。<br>
该代码是为了判断请求项的缓冲块数据是否已经读完，“—CURRENT-&gt;nr_sectors”将递减请求项所需读取的扇区数值，如果没有读完则if条件成立。内核将再次把read_intr()绑定在硬盘中断服务程序上，以待下次使用，之后中断服务程序返回。<br>
当所需要硬盘上的数据已经读完，硬盘产生中断，读盘中断服务程序再次响应这个中断，进入read_intr()函数后，仍然会判断请求项对应的缓存块数据是否已经读完，如果读完则不进入这个if 里。</p>
<h2 id="bread-函数代码中为什么要做第二次if-bh-b-uptodate-判断？">bread（）函数代码中为什么要做第二次if (bh-&gt;b_uptodate)判断？</h2>
<pre><code>if (bh-&gt;b_uptodate)
    return bh;
ll_rw_block(READ,bh);
wait_on_buffer(bh);
if (bh-&gt;b_uptodate)
    return bh;
</code></pre>
<p>答1：bread()函数主要是从块设备上读取数据。调用底层ll_rw_block()函数，产生读设备请求。然后等待指定数据块读入，并等待缓冲块解锁。在睡眠醒来之后，如果缓冲块已更新“if (bh-&gt;b_uptodate)”，则返回缓冲块指针。否则，表明读设备操作失败，于是释放该缓冲块返回NULL。</p>
<p>答2：第一次从缓冲区取出设备号块号一致的缓冲块，判断缓冲块是否有效，有效则使用；无效则发出读设备数据库请求。<br>
第二次等待指定数据块读入，等缓冲块解锁以后，唤醒进程后，要重新判断缓冲块是否有效，如果缓冲区中数据有效，则返回缓冲区头指针退出，否则释放该缓冲区返回Null。<br>
在等待过程中，数据可能发生了变化，所以要二次判断。</p>
<h2 id="getblk-函数中-两次调用wait-on-buffer-函数-两次的意思一样吗？-p372">getblk（）函数中，两次调用wait_on_buffer（）函数，两次的意思一样吗？(P372)</h2>
<p>这里都是等待缓冲块解锁，但是此时缓冲区情况不一样：<br>
第一次：已经找到一个比较合适的空闲缓冲块，但可能是加锁的，等待该缓冲块解锁；<br>
第二次：如果该缓冲区已被修改，则将数据写盘，并再次等待缓冲块解锁。</p>
<p>执行到第一次wait_on_buffer时，意味着前面已经找到了空闲的缓冲块，但是这个缓冲块可能是是已经被加锁（其他进程在操作该空闲缓冲块），也可能是脏的，同样也可能是没有被别人占用的缓冲块。所以此时调用wait_on_buffer是检查是否该缓冲块被加锁，若加锁则阻塞当前进程。<br>
执行到第二次wait_on_buffer时，会检查缓冲块的内容是否为脏（是否被修改过），若为脏，需要同步逻辑设备（写回设备）。写回设备是一个漫长的过程，不能保证在这个过程中没有其他进程对缓冲块进行加锁。当写回设备后发现该缓冲块被其他进程加锁，同样需要阻塞当前进程。</p>
<h2 id="getblk-函数中-说明什么情况下执行continue-break-p372">getblk（）函数中，说明什么情况下执行continue、break。P372</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (tmp-&gt;b_count)</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        <span class="keyword">if</span> (!bh || BADNESS(tmp)&lt;BADNESS(bh)) &#123;</span><br><span class="line">            bh = tmp;</span><br><span class="line">            <span class="keyword">if</span> (!BADNESS(tmp))</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">/* and repeat until we find something good */</span></span><br><span class="line">    &#125; <span class="keyword">while</span> ((tmp = tmp-&gt;b_next_free) != free_list);</span><br></pre></td></tr></table></figure>
<p>getblk()函数主要是获取高速缓冲中的指定缓冲块。下面的宏用于判断缓冲块的修改标志，并定义修改标志的权重比锁定标志大。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//BADNESS定义</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BADNESS(bh) (((bh)-&gt;b_dirt<span class="meta-string">&lt;&lt;1)+(bh)-&gt;b_lock)</span></span></span><br></pre></td></tr></table></figure>
<p>continue：tmp指向的是空闲链表的第一个空闲缓冲块头“tmp = free_list;”。如果该缓冲块正在被使用，引用计数“tmp-&gt;b_count”不等于0，则continue，继续遍历直到找到一个count为0的空闲块。<br>
break：接下来，如果缓冲头指针bh为空，或者tmp所指的缓冲头标志（修改、锁定）权重小于bh头标志的权重，则让bh指向tmp缓冲块头。如果BADNESS为0，该tmp缓冲块头表明缓冲块既没有修改也没有锁定标志位，即这个块既没加锁，也没被写过，则说明已为指定设备上的块取得对应的高速缓冲块。然后break跳出循环。（也只有在系统运行初期才会存在这样的块）</p>
<h2 id="make-request-函数中-其中的sleep-on-wait-for-request-是谁在等？等什么？">make_request（）函数中，其中的sleep_on(&amp;wait_for_request)是谁在等？等什么？</h2>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (req &lt; request) &#123;</span><br><span class="line">    <span class="keyword">if</span> (rw_ahead) &#123;</span><br><span class="line">        unlock_buffer(bh);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sleep_on(&amp;wait_for_request);</span><br><span class="line">    <span class="keyword">goto</span> repeat;</span><br></pre></td></tr></table></figure>
<p>此时wait_for_request指的是：当前进程等待request请求队列腾出空闲项。</p>
<p>make_request()函数主要功能为创建请求项并插入请求队列。根据具体读写操作，如果request[32]中没有一项是空闲的，则查看此次请求是不是提前读写，如果是则立即放弃此次请求操作。否则让本次请求先睡眠“sleep_on(&amp;wait_for_request);”以等待request请求队列腾出空闲项，一段时间后再次搜索请求队列。</p>
]]></content>
      <categories>
        <category>国科大课程笔记</category>
        <category>操作系统高级教程</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>Linux Kernel</tag>
      </tags>
  </entry>
</search>
