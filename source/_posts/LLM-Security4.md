---
title: LLM for Security 论文记录 1114
tags:
  - 大模型
  - 网络安全
  - 大模型安全
  - 生成式人工智能
categories:
  - [大模型,大模型&安全]
  - [大模型,论文阅读]
  - [大模型,Agent]
description: LLM for Security 论文记录 1114
cover: 'https://s3.bmp.ovh/imgs/2024/04/08/2368e73f30658fe8.png'
date: 2024-11-14 10:57:54
---
> 更新一下论文阅读记录，一直写在了本地的编辑器上，现在更新到博客中（持续更新ing，打算以月为单位更新博客了）
# Agent in Security
<!-- {% asset_img p1.png p1 %} -->
<!-- <img src="p1.png"  style="zoom:55%;" /> -->

## PentestGPT（USENIX）
PentestGPT: An LLM-empowered Automatic Penetration Testing Tool

> 论文：https://arxiv.org/abs/2308.06782
> 代码：https://github.com/binarybrain-009/AUTOATTACKER （核心代码放的是一个注释，差评）

**研究内容**
研究**大模型的自动化渗透测试能力**（比较早的一个工作）。

<img src="pentestgpt.png"  style="zoom:80%;" />

**研究动机/挑战**
针对渗透测试领域引入了独特的挑战，包括：
1）现今的渗透测试较依赖人工操作和专业知识，限制了高效安全评估的进化需求；
2）现有的渗透测试基准测试不够全面，无法全面评估渗透测试进展。

动机: 鉴于渗透测试当前限制和LLMs的能力，作者希望探究LLMs在渗透测试任务中的应用价值，提高自动化渗透测试的效率和有效性。

**贡献**
1）针对LLM+渗透测试进行了一些先验研究：
- RQ1(Capability): 法学硕士可以在多大程度上执行渗透测试任务？
  - Finding 1: LLM熟练执行端到端渗透测试任务，但难以应对更困难的目标；
  - Finding 2: LLMs可以有效地使用渗透测试工具，识别常见漏洞，并解释源代码以识别漏洞。
- RQ2(Comparative Analysis): 人类渗透测试员和法学硕士的问题解决策略有何不同？
  - Finding 3: LLMs很难维持长期记忆，而这对有效链接漏洞和制定利用策略至关重要；
  - Finding 4: LLMs倾向最近的任务和深度优先搜索，这会导致过度关注某一任务并忘记之前的发现；
  - Finding 5: LLMs可能会产生不准确的操作或命令。

2）设计了交互式的PentestGPT。一方面优化LLMs在渗透测试中的使用（<mark>prompt设计，渗透计划树记录规划</mark>），另一方面利用LLMs的优势提高自动渗透测试的效率和有效性（给人提供指导）。

3）构建了一个渗透测试任务的基准测试（HackTheBox中的夺旗任务）

**方法**
首先，作者设计了一个全面的全自动渗透测试工具MALISM（**PentestGPT模块是该框架中的一部分**）。这个网络安全认知引擎（没有开源代码，可能只是设计）主要包括以下三个模块：
- EXPLOITFLOW：通过捕获每个离散动作后的系统状态来生成安全开发路线(利用流)；
- **PENTESTGPT：利用LLMs为每个给定的离散状态启发式生成测试指导；**
- PENTESTPERF：一个综合渗透测试基准，用于评估渗透测试器和自动化工具在广泛的测试目标上的性能。

针对先验研究发现的：**LLMs具有一定的渗透测试能力，但难以保持长期记忆和解决复杂问题**，作者设计了交互式的PentestGPT。一方面优化LLMs在渗透测试中的使用（设计prompt，渗透计划树等），另一方面利用LLMs的优势提高自动渗透测试的效率和有效性（给人指导）。

<img src="pentestgpt1.png"  style="zoom:80%;" />

在推理模块中对于渗透流程的规划，通过渗透计划树：

<img src="pentestgpt2.png"  style="zoom:80%;" />

**思考**
<mark>思考：提供了LLM应用到渗透测试的一个思路，比如**渗透计划树的方式记录规划**（后面的AutoAttack也是在PentestGPT基础上改的），但是缺点也很明显，PentestGPT本质上还是一个针对渗透测试提供建议的问答模型，其中人工干预较多，不是一个真正意义上的Agent，所以说后面的一些工作会弥补掉这个Gap，能够直接执行一些渗透命令，并反馈继续</mark>

## AUTOATTACKER

AUTOATTACKER: A Large Language Model Guided System to Implement Automatic Cyber-attacks

> 论文：https://arxiv.org/abs/2403.01038
> 代码：https://github.com/binarybrain-009/AUTOATTACKER （核心代码放的是一个注释，差评）

<img src="autoattack.png"  style="zoom:80%;" />

**研究内容**
利用基于 LLM 的系统来模拟在各种攻击技术和环境下通常为人为操作或“手动键盘”攻击的攻击后阶段。

**研究意义**
- 首先，基于 LLM 的自动化漏洞后利用框架可以**帮助分析师快速测试**并持续改进其组织的网络安全态势，以抵御以前未曾见过的攻击。
- 其次，基于LLM的渗透测试系统可以通过有限数量的分析师来**扩展红队的有效性**。
- 最后，这项研究可以帮助防御系统和团队在实际使用之前学会**先发制人地检测新的攻击行为**。

**研究动机/挑战**
基于问题引入了独特的挑战，包括：
1）**复杂的攻击任务链**：高级攻击可能需要许多子任务，甚至一个失败的子任务会破坏整个链； 
2）**动作空间的高密度可变性**：bash或Metasploit中的命令具有许多参数，其中一些参数与系统信息或文件夹路径密切相关，其中一个拼写错误可能会破坏攻击命令。

**贡献**
1）提出了一种**模块化** Agent 设计，以在不同点利用LLM的不同功能，例如规划、总结和代码生成，即使在生成单个攻击命令时也是如此。通过这种设计，我们可以更好地利用 LLM 来得出精确的答案。 
2）借用**检索增强生成（RAG）**的想法，在生成下一个动作之前用先前攻击动作（称为经验）的知识库来增强LLM，因此成功攻击的机会会增加，因为它们的组合子任务可以重复使用。

**方法**
设计了 4 个模块，即**总结器**、**规划器**、**导航器**和**经验管理器**，以与 LLM 迭代交互。还精心设计了每个模块的**提示**模板，因此LLM的回答具有高度可控性。

**思考**
<mark>创新点：完成了渗透的闭环，与pentestGpt仅仅给人提供指导相比，AutoAttack能够推理后执行指令，而无需人的参与。其中为了更好地进行计划的决策，引入了基于RAG的经验管理。缺点就是核心代码不全。</mark>